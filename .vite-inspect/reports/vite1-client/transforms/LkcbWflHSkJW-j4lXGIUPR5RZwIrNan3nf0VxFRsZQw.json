{
  "resolvedId": "/Users/stevenhill/gce_git_tutorial/node_modules/mermaid/dist/chunks/mermaid.esm/chunk-R4WPHL2B.mjs",
  "transforms": [
    {
      "name": "vite:load-fallback",
      "result": "import {\n  assign_default,\n  clone_default,\n  compact_default,\n  defaults_default,\n  difference_default,\n  dropRight_default,\n  drop_default,\n  every_default,\n  filter_default,\n  find_default,\n  flatMap_default,\n  flatten_default,\n  forEach_default,\n  groupBy_default,\n  has_default,\n  head_default,\n  includes_default,\n  indexOf_default,\n  isRegExp_default,\n  isString_default,\n  isUndefined_default,\n  keys_default,\n  last_default,\n  map_default,\n  min_default,\n  noop_default,\n  pickBy_default,\n  reduce_default,\n  reject_default,\n  some_default,\n  uniqBy_default,\n  uniq_default,\n  values_default\n} from \"./chunk-TGZYFRKZ.mjs\";\nimport {\n  isEmpty_default\n} from \"./chunk-GRZAG2UZ.mjs\";\nimport {\n  identity_default,\n  isArray_default,\n  isFunction_default,\n  isObject_default\n} from \"./chunk-HD3LK5B5.mjs\";\nimport {\n  __commonJS,\n  __export,\n  __name,\n  __reExport,\n  __toESM\n} from \"./chunk-DLQEHMXD.mjs\";\n\n// ../../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/ral.js\nvar require_ral = __commonJS({\n  \"../../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/ral.js\"(exports) {\n    \"use strict\";\n    Object.defineProperty(exports, \"__esModule\", { value: true });\n    var _ral;\n    function RAL() {\n      if (_ral === void 0) {\n        throw new Error(`No runtime abstraction layer installed`);\n      }\n      return _ral;\n    }\n    __name(RAL, \"RAL\");\n    (function(RAL2) {\n      function install(ral) {\n        if (ral === void 0) {\n          throw new Error(`No runtime abstraction layer provided`);\n        }\n        _ral = ral;\n      }\n      __name(install, \"install\");\n      RAL2.install = install;\n    })(RAL || (RAL = {}));\n    exports.default = RAL;\n  }\n});\n\n// ../../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/is.js\nvar require_is = __commonJS({\n  \"../../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/is.js\"(exports) {\n    \"use strict\";\n    Object.defineProperty(exports, \"__esModule\", { value: true });\n    exports.stringArray = exports.array = exports.func = exports.error = exports.number = exports.string = exports.boolean = void 0;\n    function boolean(value) {\n      return value === true || value === false;\n    }\n    __name(boolean, \"boolean\");\n    exports.boolean = boolean;\n    function string(value) {\n      return typeof value === \"string\" || value instanceof String;\n    }\n    __name(string, \"string\");\n    exports.string = string;\n    function number(value) {\n      return typeof value === \"number\" || value instanceof Number;\n    }\n    __name(number, \"number\");\n    exports.number = number;\n    function error(value) {\n      return value instanceof Error;\n    }\n    __name(error, \"error\");\n    exports.error = error;\n    function func(value) {\n      return typeof value === \"function\";\n    }\n    __name(func, \"func\");\n    exports.func = func;\n    function array(value) {\n      return Array.isArray(value);\n    }\n    __name(array, \"array\");\n    exports.array = array;\n    function stringArray(value) {\n      return array(value) && value.every((elem) => string(elem));\n    }\n    __name(stringArray, \"stringArray\");\n    exports.stringArray = stringArray;\n  }\n});\n\n// ../../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/events.js\nvar require_events = __commonJS({\n  \"../../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/events.js\"(exports) {\n    \"use strict\";\n    Object.defineProperty(exports, \"__esModule\", { value: true });\n    exports.Emitter = exports.Event = void 0;\n    var ral_1 = require_ral();\n    var Event;\n    (function(Event2) {\n      const _disposable = { dispose() {\n      } };\n      Event2.None = function() {\n        return _disposable;\n      };\n    })(Event || (exports.Event = Event = {}));\n    var CallbackList = class {\n      static {\n        __name(this, \"CallbackList\");\n      }\n      add(callback, context = null, bucket) {\n        if (!this._callbacks) {\n          this._callbacks = [];\n          this._contexts = [];\n        }\n        this._callbacks.push(callback);\n        this._contexts.push(context);\n        if (Array.isArray(bucket)) {\n          bucket.push({ dispose: /* @__PURE__ */ __name(() => this.remove(callback, context), \"dispose\") });\n        }\n      }\n      remove(callback, context = null) {\n        if (!this._callbacks) {\n          return;\n        }\n        let foundCallbackWithDifferentContext = false;\n        for (let i = 0, len = this._callbacks.length; i < len; i++) {\n          if (this._callbacks[i] === callback) {\n            if (this._contexts[i] === context) {\n              this._callbacks.splice(i, 1);\n              this._contexts.splice(i, 1);\n              return;\n            } else {\n              foundCallbackWithDifferentContext = true;\n            }\n          }\n        }\n        if (foundCallbackWithDifferentContext) {\n          throw new Error(\"When adding a listener with a context, you should remove it with the same context\");\n        }\n      }\n      invoke(...args) {\n        if (!this._callbacks) {\n          return [];\n        }\n        const ret = [], callbacks = this._callbacks.slice(0), contexts = this._contexts.slice(0);\n        for (let i = 0, len = callbacks.length; i < len; i++) {\n          try {\n            ret.push(callbacks[i].apply(contexts[i], args));\n          } catch (e) {\n            (0, ral_1.default)().console.error(e);\n          }\n        }\n        return ret;\n      }\n      isEmpty() {\n        return !this._callbacks || this._callbacks.length === 0;\n      }\n      dispose() {\n        this._callbacks = void 0;\n        this._contexts = void 0;\n      }\n    };\n    var Emitter3 = class _Emitter {\n      static {\n        __name(this, \"Emitter\");\n      }\n      constructor(_options) {\n        this._options = _options;\n      }\n      /**\n       * For the public to allow to subscribe\n       * to events from this Emitter\n       */\n      get event() {\n        if (!this._event) {\n          this._event = (listener, thisArgs, disposables) => {\n            if (!this._callbacks) {\n              this._callbacks = new CallbackList();\n            }\n            if (this._options && this._options.onFirstListenerAdd && this._callbacks.isEmpty()) {\n              this._options.onFirstListenerAdd(this);\n            }\n            this._callbacks.add(listener, thisArgs);\n            const result = {\n              dispose: /* @__PURE__ */ __name(() => {\n                if (!this._callbacks) {\n                  return;\n                }\n                this._callbacks.remove(listener, thisArgs);\n                result.dispose = _Emitter._noop;\n                if (this._options && this._options.onLastListenerRemove && this._callbacks.isEmpty()) {\n                  this._options.onLastListenerRemove(this);\n                }\n              }, \"dispose\")\n            };\n            if (Array.isArray(disposables)) {\n              disposables.push(result);\n            }\n            return result;\n          };\n        }\n        return this._event;\n      }\n      /**\n       * To be kept private to fire an event to\n       * subscribers\n       */\n      fire(event) {\n        if (this._callbacks) {\n          this._callbacks.invoke.call(this._callbacks, event);\n        }\n      }\n      dispose() {\n        if (this._callbacks) {\n          this._callbacks.dispose();\n          this._callbacks = void 0;\n        }\n      }\n    };\n    exports.Emitter = Emitter3;\n    Emitter3._noop = function() {\n    };\n  }\n});\n\n// ../../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/cancellation.js\nvar require_cancellation = __commonJS({\n  \"../../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/cancellation.js\"(exports) {\n    \"use strict\";\n    Object.defineProperty(exports, \"__esModule\", { value: true });\n    exports.CancellationTokenSource = exports.CancellationToken = void 0;\n    var ral_1 = require_ral();\n    var Is2 = require_is();\n    var events_1 = require_events();\n    var CancellationToken11;\n    (function(CancellationToken12) {\n      CancellationToken12.None = Object.freeze({\n        isCancellationRequested: false,\n        onCancellationRequested: events_1.Event.None\n      });\n      CancellationToken12.Cancelled = Object.freeze({\n        isCancellationRequested: true,\n        onCancellationRequested: events_1.Event.None\n      });\n      function is(value) {\n        const candidate = value;\n        return candidate && (candidate === CancellationToken12.None || candidate === CancellationToken12.Cancelled || Is2.boolean(candidate.isCancellationRequested) && !!candidate.onCancellationRequested);\n      }\n      __name(is, \"is\");\n      CancellationToken12.is = is;\n    })(CancellationToken11 || (exports.CancellationToken = CancellationToken11 = {}));\n    var shortcutEvent = Object.freeze(function(callback, context) {\n      const handle = (0, ral_1.default)().timer.setTimeout(callback.bind(context), 0);\n      return { dispose() {\n        handle.dispose();\n      } };\n    });\n    var MutableToken = class {\n      static {\n        __name(this, \"MutableToken\");\n      }\n      constructor() {\n        this._isCancelled = false;\n      }\n      cancel() {\n        if (!this._isCancelled) {\n          this._isCancelled = true;\n          if (this._emitter) {\n            this._emitter.fire(void 0);\n            this.dispose();\n          }\n        }\n      }\n      get isCancellationRequested() {\n        return this._isCancelled;\n      }\n      get onCancellationRequested() {\n        if (this._isCancelled) {\n          return shortcutEvent;\n        }\n        if (!this._emitter) {\n          this._emitter = new events_1.Emitter();\n        }\n        return this._emitter.event;\n      }\n      dispose() {\n        if (this._emitter) {\n          this._emitter.dispose();\n          this._emitter = void 0;\n        }\n      }\n    };\n    var CancellationTokenSource3 = class {\n      static {\n        __name(this, \"CancellationTokenSource\");\n      }\n      get token() {\n        if (!this._token) {\n          this._token = new MutableToken();\n        }\n        return this._token;\n      }\n      cancel() {\n        if (!this._token) {\n          this._token = CancellationToken11.Cancelled;\n        } else {\n          this._token.cancel();\n        }\n      }\n      dispose() {\n        if (!this._token) {\n          this._token = CancellationToken11.None;\n        } else if (this._token instanceof MutableToken) {\n          this._token.dispose();\n        }\n      }\n    };\n    exports.CancellationTokenSource = CancellationTokenSource3;\n  }\n});\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/index.js\nvar lib_exports = {};\n__export(lib_exports, {\n  AbstractAstReflection: () => AbstractAstReflection,\n  AbstractCstNode: () => AbstractCstNode,\n  AbstractLangiumParser: () => AbstractLangiumParser,\n  AbstractParserErrorMessageProvider: () => AbstractParserErrorMessageProvider,\n  AbstractThreadedAsyncParser: () => AbstractThreadedAsyncParser,\n  AstUtils: () => ast_utils_exports,\n  BiMap: () => BiMap,\n  Cancellation: () => cancellation_exports,\n  CompositeCstNodeImpl: () => CompositeCstNodeImpl,\n  ContextCache: () => ContextCache,\n  CstNodeBuilder: () => CstNodeBuilder,\n  CstUtils: () => cst_utils_exports,\n  DEFAULT_TOKENIZE_OPTIONS: () => DEFAULT_TOKENIZE_OPTIONS,\n  DONE_RESULT: () => DONE_RESULT,\n  DatatypeSymbol: () => DatatypeSymbol,\n  DefaultAstNodeDescriptionProvider: () => DefaultAstNodeDescriptionProvider,\n  DefaultAstNodeLocator: () => DefaultAstNodeLocator,\n  DefaultAsyncParser: () => DefaultAsyncParser,\n  DefaultCommentProvider: () => DefaultCommentProvider,\n  DefaultConfigurationProvider: () => DefaultConfigurationProvider,\n  DefaultDocumentBuilder: () => DefaultDocumentBuilder,\n  DefaultDocumentValidator: () => DefaultDocumentValidator,\n  DefaultHydrator: () => DefaultHydrator,\n  DefaultIndexManager: () => DefaultIndexManager,\n  DefaultJsonSerializer: () => DefaultJsonSerializer,\n  DefaultLangiumDocumentFactory: () => DefaultLangiumDocumentFactory,\n  DefaultLangiumDocuments: () => DefaultLangiumDocuments,\n  DefaultLexer: () => DefaultLexer,\n  DefaultLexerErrorMessageProvider: () => DefaultLexerErrorMessageProvider,\n  DefaultLinker: () => DefaultLinker,\n  DefaultNameProvider: () => DefaultNameProvider,\n  DefaultReferenceDescriptionProvider: () => DefaultReferenceDescriptionProvider,\n  DefaultReferences: () => DefaultReferences,\n  DefaultScopeComputation: () => DefaultScopeComputation,\n  DefaultScopeProvider: () => DefaultScopeProvider,\n  DefaultServiceRegistry: () => DefaultServiceRegistry,\n  DefaultTokenBuilder: () => DefaultTokenBuilder,\n  DefaultValueConverter: () => DefaultValueConverter,\n  DefaultWorkspaceLock: () => DefaultWorkspaceLock,\n  DefaultWorkspaceManager: () => DefaultWorkspaceManager,\n  Deferred: () => Deferred,\n  Disposable: () => Disposable,\n  DisposableCache: () => DisposableCache,\n  DocumentCache: () => DocumentCache,\n  DocumentState: () => DocumentState,\n  DocumentValidator: () => DocumentValidator,\n  EMPTY_SCOPE: () => EMPTY_SCOPE,\n  EMPTY_STREAM: () => EMPTY_STREAM,\n  EmptyFileSystem: () => EmptyFileSystem,\n  EmptyFileSystemProvider: () => EmptyFileSystemProvider,\n  ErrorWithLocation: () => ErrorWithLocation,\n  GrammarAST: () => ast_exports,\n  GrammarUtils: () => grammar_utils_exports,\n  IndentationAwareLexer: () => IndentationAwareLexer,\n  IndentationAwareTokenBuilder: () => IndentationAwareTokenBuilder,\n  JSDocDocumentationProvider: () => JSDocDocumentationProvider,\n  LangiumCompletionParser: () => LangiumCompletionParser,\n  LangiumParser: () => LangiumParser,\n  LangiumParserErrorMessageProvider: () => LangiumParserErrorMessageProvider,\n  LeafCstNodeImpl: () => LeafCstNodeImpl,\n  LexingMode: () => LexingMode,\n  MapScope: () => MapScope,\n  Module: () => Module,\n  MultiMap: () => MultiMap,\n  OperationCancelled: () => OperationCancelled,\n  ParserWorker: () => ParserWorker,\n  Reduction: () => Reduction,\n  RegExpUtils: () => regexp_utils_exports,\n  RootCstNodeImpl: () => RootCstNodeImpl,\n  SimpleCache: () => SimpleCache,\n  StreamImpl: () => StreamImpl,\n  StreamScope: () => StreamScope,\n  TextDocument: () => TextDocument2,\n  TreeStreamImpl: () => TreeStreamImpl,\n  URI: () => URI2,\n  UriUtils: () => UriUtils,\n  ValidationCategory: () => ValidationCategory,\n  ValidationRegistry: () => ValidationRegistry,\n  ValueConverter: () => ValueConverter,\n  WorkspaceCache: () => WorkspaceCache,\n  assertUnreachable: () => assertUnreachable,\n  createCompletionParser: () => createCompletionParser,\n  createDefaultCoreModule: () => createDefaultCoreModule,\n  createDefaultSharedCoreModule: () => createDefaultSharedCoreModule,\n  createGrammarConfig: () => createGrammarConfig,\n  createLangiumParser: () => createLangiumParser,\n  createParser: () => createParser,\n  delayNextTick: () => delayNextTick,\n  diagnosticData: () => diagnosticData,\n  eagerLoad: () => eagerLoad,\n  getDiagnosticRange: () => getDiagnosticRange,\n  indentationBuilderDefaultOptions: () => indentationBuilderDefaultOptions,\n  inject: () => inject,\n  interruptAndCheck: () => interruptAndCheck,\n  isAstNode: () => isAstNode,\n  isAstNodeDescription: () => isAstNodeDescription,\n  isAstNodeWithComment: () => isAstNodeWithComment,\n  isCompositeCstNode: () => isCompositeCstNode,\n  isIMultiModeLexerDefinition: () => isIMultiModeLexerDefinition,\n  isJSDoc: () => isJSDoc,\n  isLeafCstNode: () => isLeafCstNode,\n  isLinkingError: () => isLinkingError,\n  isNamed: () => isNamed,\n  isOperationCancelled: () => isOperationCancelled,\n  isReference: () => isReference,\n  isRootCstNode: () => isRootCstNode,\n  isTokenTypeArray: () => isTokenTypeArray,\n  isTokenTypeDictionary: () => isTokenTypeDictionary,\n  loadGrammarFromJson: () => loadGrammarFromJson,\n  parseJSDoc: () => parseJSDoc,\n  prepareLangiumParser: () => prepareLangiumParser,\n  setInterruptionPeriod: () => setInterruptionPeriod,\n  startCancelableOperation: () => startCancelableOperation,\n  stream: () => stream,\n  toDiagnosticData: () => toDiagnosticData,\n  toDiagnosticSeverity: () => toDiagnosticSeverity\n});\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/cst-utils.js\nvar cst_utils_exports = {};\n__export(cst_utils_exports, {\n  DefaultNameRegexp: () => DefaultNameRegexp,\n  RangeComparison: () => RangeComparison,\n  compareRange: () => compareRange,\n  findCommentNode: () => findCommentNode,\n  findDeclarationNodeAtOffset: () => findDeclarationNodeAtOffset,\n  findLeafNodeAtOffset: () => findLeafNodeAtOffset,\n  findLeafNodeBeforeOffset: () => findLeafNodeBeforeOffset,\n  flattenCst: () => flattenCst,\n  getInteriorNodes: () => getInteriorNodes,\n  getNextNode: () => getNextNode,\n  getPreviousNode: () => getPreviousNode,\n  getStartlineNode: () => getStartlineNode,\n  inRange: () => inRange,\n  isChildNode: () => isChildNode,\n  isCommentNode: () => isCommentNode,\n  streamCst: () => streamCst,\n  toDocumentSegment: () => toDocumentSegment,\n  tokenToRange: () => tokenToRange\n});\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/syntax-tree.js\nfunction isAstNode(obj) {\n  return typeof obj === \"object\" && obj !== null && typeof obj.$type === \"string\";\n}\n__name(isAstNode, \"isAstNode\");\nfunction isReference(obj) {\n  return typeof obj === \"object\" && obj !== null && typeof obj.$refText === \"string\";\n}\n__name(isReference, \"isReference\");\nfunction isAstNodeDescription(obj) {\n  return typeof obj === \"object\" && obj !== null && typeof obj.name === \"string\" && typeof obj.type === \"string\" && typeof obj.path === \"string\";\n}\n__name(isAstNodeDescription, \"isAstNodeDescription\");\nfunction isLinkingError(obj) {\n  return typeof obj === \"object\" && obj !== null && isAstNode(obj.container) && isReference(obj.reference) && typeof obj.message === \"string\";\n}\n__name(isLinkingError, \"isLinkingError\");\nvar AbstractAstReflection = class {\n  static {\n    __name(this, \"AbstractAstReflection\");\n  }\n  constructor() {\n    this.subtypes = {};\n    this.allSubtypes = {};\n  }\n  isInstance(node, type) {\n    return isAstNode(node) && this.isSubtype(node.$type, type);\n  }\n  isSubtype(subtype, supertype) {\n    if (subtype === supertype) {\n      return true;\n    }\n    let nested = this.subtypes[subtype];\n    if (!nested) {\n      nested = this.subtypes[subtype] = {};\n    }\n    const existing = nested[supertype];\n    if (existing !== void 0) {\n      return existing;\n    } else {\n      const result = this.computeIsSubtype(subtype, supertype);\n      nested[supertype] = result;\n      return result;\n    }\n  }\n  getAllSubTypes(type) {\n    const existing = this.allSubtypes[type];\n    if (existing) {\n      return existing;\n    } else {\n      const allTypes = this.getAllTypes();\n      const types = [];\n      for (const possibleSubType of allTypes) {\n        if (this.isSubtype(possibleSubType, type)) {\n          types.push(possibleSubType);\n        }\n      }\n      this.allSubtypes[type] = types;\n      return types;\n    }\n  }\n};\nfunction isCompositeCstNode(node) {\n  return typeof node === \"object\" && node !== null && Array.isArray(node.content);\n}\n__name(isCompositeCstNode, \"isCompositeCstNode\");\nfunction isLeafCstNode(node) {\n  return typeof node === \"object\" && node !== null && typeof node.tokenType === \"object\";\n}\n__name(isLeafCstNode, \"isLeafCstNode\");\nfunction isRootCstNode(node) {\n  return isCompositeCstNode(node) && typeof node.fullText === \"string\";\n}\n__name(isRootCstNode, \"isRootCstNode\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/stream.js\nvar StreamImpl = class _StreamImpl {\n  static {\n    __name(this, \"StreamImpl\");\n  }\n  constructor(startFn, nextFn) {\n    this.startFn = startFn;\n    this.nextFn = nextFn;\n  }\n  iterator() {\n    const iterator = {\n      state: this.startFn(),\n      next: /* @__PURE__ */ __name(() => this.nextFn(iterator.state), \"next\"),\n      [Symbol.iterator]: () => iterator\n    };\n    return iterator;\n  }\n  [Symbol.iterator]() {\n    return this.iterator();\n  }\n  isEmpty() {\n    const iterator = this.iterator();\n    return Boolean(iterator.next().done);\n  }\n  count() {\n    const iterator = this.iterator();\n    let count = 0;\n    let next = iterator.next();\n    while (!next.done) {\n      count++;\n      next = iterator.next();\n    }\n    return count;\n  }\n  toArray() {\n    const result = [];\n    const iterator = this.iterator();\n    let next;\n    do {\n      next = iterator.next();\n      if (next.value !== void 0) {\n        result.push(next.value);\n      }\n    } while (!next.done);\n    return result;\n  }\n  toSet() {\n    return new Set(this);\n  }\n  toMap(keyFn, valueFn) {\n    const entryStream = this.map((element) => [\n      keyFn ? keyFn(element) : element,\n      valueFn ? valueFn(element) : element\n    ]);\n    return new Map(entryStream);\n  }\n  toString() {\n    return this.join();\n  }\n  concat(other) {\n    return new _StreamImpl(() => ({ first: this.startFn(), firstDone: false, iterator: other[Symbol.iterator]() }), (state) => {\n      let result;\n      if (!state.firstDone) {\n        do {\n          result = this.nextFn(state.first);\n          if (!result.done) {\n            return result;\n          }\n        } while (!result.done);\n        state.firstDone = true;\n      }\n      do {\n        result = state.iterator.next();\n        if (!result.done) {\n          return result;\n        }\n      } while (!result.done);\n      return DONE_RESULT;\n    });\n  }\n  join(separator = \",\") {\n    const iterator = this.iterator();\n    let value = \"\";\n    let result;\n    let addSeparator = false;\n    do {\n      result = iterator.next();\n      if (!result.done) {\n        if (addSeparator) {\n          value += separator;\n        }\n        value += toString(result.value);\n      }\n      addSeparator = true;\n    } while (!result.done);\n    return value;\n  }\n  indexOf(searchElement, fromIndex = 0) {\n    const iterator = this.iterator();\n    let index = 0;\n    let next = iterator.next();\n    while (!next.done) {\n      if (index >= fromIndex && next.value === searchElement) {\n        return index;\n      }\n      next = iterator.next();\n      index++;\n    }\n    return -1;\n  }\n  every(predicate) {\n    const iterator = this.iterator();\n    let next = iterator.next();\n    while (!next.done) {\n      if (!predicate(next.value)) {\n        return false;\n      }\n      next = iterator.next();\n    }\n    return true;\n  }\n  some(predicate) {\n    const iterator = this.iterator();\n    let next = iterator.next();\n    while (!next.done) {\n      if (predicate(next.value)) {\n        return true;\n      }\n      next = iterator.next();\n    }\n    return false;\n  }\n  forEach(callbackfn) {\n    const iterator = this.iterator();\n    let index = 0;\n    let next = iterator.next();\n    while (!next.done) {\n      callbackfn(next.value, index);\n      next = iterator.next();\n      index++;\n    }\n  }\n  map(callbackfn) {\n    return new _StreamImpl(this.startFn, (state) => {\n      const { done, value } = this.nextFn(state);\n      if (done) {\n        return DONE_RESULT;\n      } else {\n        return { done: false, value: callbackfn(value) };\n      }\n    });\n  }\n  filter(predicate) {\n    return new _StreamImpl(this.startFn, (state) => {\n      let result;\n      do {\n        result = this.nextFn(state);\n        if (!result.done && predicate(result.value)) {\n          return result;\n        }\n      } while (!result.done);\n      return DONE_RESULT;\n    });\n  }\n  nonNullable() {\n    return this.filter((e) => e !== void 0 && e !== null);\n  }\n  reduce(callbackfn, initialValue) {\n    const iterator = this.iterator();\n    let previousValue = initialValue;\n    let next = iterator.next();\n    while (!next.done) {\n      if (previousValue === void 0) {\n        previousValue = next.value;\n      } else {\n        previousValue = callbackfn(previousValue, next.value);\n      }\n      next = iterator.next();\n    }\n    return previousValue;\n  }\n  reduceRight(callbackfn, initialValue) {\n    return this.recursiveReduce(this.iterator(), callbackfn, initialValue);\n  }\n  recursiveReduce(iterator, callbackfn, initialValue) {\n    const next = iterator.next();\n    if (next.done) {\n      return initialValue;\n    }\n    const previousValue = this.recursiveReduce(iterator, callbackfn, initialValue);\n    if (previousValue === void 0) {\n      return next.value;\n    }\n    return callbackfn(previousValue, next.value);\n  }\n  find(predicate) {\n    const iterator = this.iterator();\n    let next = iterator.next();\n    while (!next.done) {\n      if (predicate(next.value)) {\n        return next.value;\n      }\n      next = iterator.next();\n    }\n    return void 0;\n  }\n  findIndex(predicate) {\n    const iterator = this.iterator();\n    let index = 0;\n    let next = iterator.next();\n    while (!next.done) {\n      if (predicate(next.value)) {\n        return index;\n      }\n      next = iterator.next();\n      index++;\n    }\n    return -1;\n  }\n  includes(searchElement) {\n    const iterator = this.iterator();\n    let next = iterator.next();\n    while (!next.done) {\n      if (next.value === searchElement) {\n        return true;\n      }\n      next = iterator.next();\n    }\n    return false;\n  }\n  flatMap(callbackfn) {\n    return new _StreamImpl(() => ({ this: this.startFn() }), (state) => {\n      do {\n        if (state.iterator) {\n          const next = state.iterator.next();\n          if (next.done) {\n            state.iterator = void 0;\n          } else {\n            return next;\n          }\n        }\n        const { done, value } = this.nextFn(state.this);\n        if (!done) {\n          const mapped = callbackfn(value);\n          if (isIterable(mapped)) {\n            state.iterator = mapped[Symbol.iterator]();\n          } else {\n            return { done: false, value: mapped };\n          }\n        }\n      } while (state.iterator);\n      return DONE_RESULT;\n    });\n  }\n  flat(depth) {\n    if (depth === void 0) {\n      depth = 1;\n    }\n    if (depth <= 0) {\n      return this;\n    }\n    const stream2 = depth > 1 ? this.flat(depth - 1) : this;\n    return new _StreamImpl(() => ({ this: stream2.startFn() }), (state) => {\n      do {\n        if (state.iterator) {\n          const next = state.iterator.next();\n          if (next.done) {\n            state.iterator = void 0;\n          } else {\n            return next;\n          }\n        }\n        const { done, value } = stream2.nextFn(state.this);\n        if (!done) {\n          if (isIterable(value)) {\n            state.iterator = value[Symbol.iterator]();\n          } else {\n            return { done: false, value };\n          }\n        }\n      } while (state.iterator);\n      return DONE_RESULT;\n    });\n  }\n  head() {\n    const iterator = this.iterator();\n    const result = iterator.next();\n    if (result.done) {\n      return void 0;\n    }\n    return result.value;\n  }\n  tail(skipCount = 1) {\n    return new _StreamImpl(() => {\n      const state = this.startFn();\n      for (let i = 0; i < skipCount; i++) {\n        const next = this.nextFn(state);\n        if (next.done) {\n          return state;\n        }\n      }\n      return state;\n    }, this.nextFn);\n  }\n  limit(maxSize) {\n    return new _StreamImpl(() => ({ size: 0, state: this.startFn() }), (state) => {\n      state.size++;\n      if (state.size > maxSize) {\n        return DONE_RESULT;\n      }\n      return this.nextFn(state.state);\n    });\n  }\n  distinct(by) {\n    return new _StreamImpl(() => ({ set: /* @__PURE__ */ new Set(), internalState: this.startFn() }), (state) => {\n      let result;\n      do {\n        result = this.nextFn(state.internalState);\n        if (!result.done) {\n          const value = by ? by(result.value) : result.value;\n          if (!state.set.has(value)) {\n            state.set.add(value);\n            return result;\n          }\n        }\n      } while (!result.done);\n      return DONE_RESULT;\n    });\n  }\n  exclude(other, key) {\n    const otherKeySet = /* @__PURE__ */ new Set();\n    for (const item of other) {\n      const value = key ? key(item) : item;\n      otherKeySet.add(value);\n    }\n    return this.filter((e) => {\n      const ownKey = key ? key(e) : e;\n      return !otherKeySet.has(ownKey);\n    });\n  }\n};\nfunction toString(item) {\n  if (typeof item === \"string\") {\n    return item;\n  }\n  if (typeof item === \"undefined\") {\n    return \"undefined\";\n  }\n  if (typeof item.toString === \"function\") {\n    return item.toString();\n  }\n  return Object.prototype.toString.call(item);\n}\n__name(toString, \"toString\");\nfunction isIterable(obj) {\n  return !!obj && typeof obj[Symbol.iterator] === \"function\";\n}\n__name(isIterable, \"isIterable\");\nvar EMPTY_STREAM = new StreamImpl(() => void 0, () => DONE_RESULT);\nvar DONE_RESULT = Object.freeze({ done: true, value: void 0 });\nfunction stream(...collections) {\n  if (collections.length === 1) {\n    const collection = collections[0];\n    if (collection instanceof StreamImpl) {\n      return collection;\n    }\n    if (isIterable(collection)) {\n      return new StreamImpl(() => collection[Symbol.iterator](), (iterator) => iterator.next());\n    }\n    if (typeof collection.length === \"number\") {\n      return new StreamImpl(() => ({ index: 0 }), (state) => {\n        if (state.index < collection.length) {\n          return { done: false, value: collection[state.index++] };\n        } else {\n          return DONE_RESULT;\n        }\n      });\n    }\n  }\n  if (collections.length > 1) {\n    return new StreamImpl(() => ({ collIndex: 0, arrIndex: 0 }), (state) => {\n      do {\n        if (state.iterator) {\n          const next = state.iterator.next();\n          if (!next.done) {\n            return next;\n          }\n          state.iterator = void 0;\n        }\n        if (state.array) {\n          if (state.arrIndex < state.array.length) {\n            return { done: false, value: state.array[state.arrIndex++] };\n          }\n          state.array = void 0;\n          state.arrIndex = 0;\n        }\n        if (state.collIndex < collections.length) {\n          const collection = collections[state.collIndex++];\n          if (isIterable(collection)) {\n            state.iterator = collection[Symbol.iterator]();\n          } else if (collection && typeof collection.length === \"number\") {\n            state.array = collection;\n          }\n        }\n      } while (state.iterator || state.array || state.collIndex < collections.length);\n      return DONE_RESULT;\n    });\n  }\n  return EMPTY_STREAM;\n}\n__name(stream, \"stream\");\nvar TreeStreamImpl = class extends StreamImpl {\n  static {\n    __name(this, \"TreeStreamImpl\");\n  }\n  constructor(root, children, options) {\n    super(() => ({\n      iterators: (options === null || options === void 0 ? void 0 : options.includeRoot) ? [[root][Symbol.iterator]()] : [children(root)[Symbol.iterator]()],\n      pruned: false\n    }), (state) => {\n      if (state.pruned) {\n        state.iterators.pop();\n        state.pruned = false;\n      }\n      while (state.iterators.length > 0) {\n        const iterator = state.iterators[state.iterators.length - 1];\n        const next = iterator.next();\n        if (next.done) {\n          state.iterators.pop();\n        } else {\n          state.iterators.push(children(next.value)[Symbol.iterator]());\n          return next;\n        }\n      }\n      return DONE_RESULT;\n    });\n  }\n  iterator() {\n    const iterator = {\n      state: this.startFn(),\n      next: /* @__PURE__ */ __name(() => this.nextFn(iterator.state), \"next\"),\n      prune: /* @__PURE__ */ __name(() => {\n        iterator.state.pruned = true;\n      }, \"prune\"),\n      [Symbol.iterator]: () => iterator\n    };\n    return iterator;\n  }\n};\nvar Reduction;\n(function(Reduction2) {\n  function sum(stream2) {\n    return stream2.reduce((a, b) => a + b, 0);\n  }\n  __name(sum, \"sum\");\n  Reduction2.sum = sum;\n  function product(stream2) {\n    return stream2.reduce((a, b) => a * b, 0);\n  }\n  __name(product, \"product\");\n  Reduction2.product = product;\n  function min(stream2) {\n    return stream2.reduce((a, b) => Math.min(a, b));\n  }\n  __name(min, \"min\");\n  Reduction2.min = min;\n  function max(stream2) {\n    return stream2.reduce((a, b) => Math.max(a, b));\n  }\n  __name(max, \"max\");\n  Reduction2.max = max;\n})(Reduction || (Reduction = {}));\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/cst-utils.js\nfunction streamCst(node) {\n  return new TreeStreamImpl(node, (element) => {\n    if (isCompositeCstNode(element)) {\n      return element.content;\n    } else {\n      return [];\n    }\n  }, { includeRoot: true });\n}\n__name(streamCst, \"streamCst\");\nfunction flattenCst(node) {\n  return streamCst(node).filter(isLeafCstNode);\n}\n__name(flattenCst, \"flattenCst\");\nfunction isChildNode(child, parent) {\n  while (child.container) {\n    child = child.container;\n    if (child === parent) {\n      return true;\n    }\n  }\n  return false;\n}\n__name(isChildNode, \"isChildNode\");\nfunction tokenToRange(token) {\n  return {\n    start: {\n      character: token.startColumn - 1,\n      line: token.startLine - 1\n    },\n    end: {\n      character: token.endColumn,\n      // endColumn uses the correct index\n      line: token.endLine - 1\n    }\n  };\n}\n__name(tokenToRange, \"tokenToRange\");\nfunction toDocumentSegment(node) {\n  if (!node) {\n    return void 0;\n  }\n  const { offset, end, range } = node;\n  return {\n    range,\n    offset,\n    end,\n    length: end - offset\n  };\n}\n__name(toDocumentSegment, \"toDocumentSegment\");\nvar RangeComparison;\n(function(RangeComparison2) {\n  RangeComparison2[RangeComparison2[\"Before\"] = 0] = \"Before\";\n  RangeComparison2[RangeComparison2[\"After\"] = 1] = \"After\";\n  RangeComparison2[RangeComparison2[\"OverlapFront\"] = 2] = \"OverlapFront\";\n  RangeComparison2[RangeComparison2[\"OverlapBack\"] = 3] = \"OverlapBack\";\n  RangeComparison2[RangeComparison2[\"Inside\"] = 4] = \"Inside\";\n  RangeComparison2[RangeComparison2[\"Outside\"] = 5] = \"Outside\";\n})(RangeComparison || (RangeComparison = {}));\nfunction compareRange(range, to) {\n  if (range.end.line < to.start.line || range.end.line === to.start.line && range.end.character <= to.start.character) {\n    return RangeComparison.Before;\n  } else if (range.start.line > to.end.line || range.start.line === to.end.line && range.start.character >= to.end.character) {\n    return RangeComparison.After;\n  }\n  const startInside = range.start.line > to.start.line || range.start.line === to.start.line && range.start.character >= to.start.character;\n  const endInside = range.end.line < to.end.line || range.end.line === to.end.line && range.end.character <= to.end.character;\n  if (startInside && endInside) {\n    return RangeComparison.Inside;\n  } else if (startInside) {\n    return RangeComparison.OverlapBack;\n  } else if (endInside) {\n    return RangeComparison.OverlapFront;\n  } else {\n    return RangeComparison.Outside;\n  }\n}\n__name(compareRange, \"compareRange\");\nfunction inRange(range, to) {\n  const comparison = compareRange(range, to);\n  return comparison > RangeComparison.After;\n}\n__name(inRange, \"inRange\");\nvar DefaultNameRegexp = /^[\\w\\p{L}]$/u;\nfunction findDeclarationNodeAtOffset(cstNode, offset, nameRegexp = DefaultNameRegexp) {\n  if (cstNode) {\n    if (offset > 0) {\n      const localOffset = offset - cstNode.offset;\n      const textAtOffset = cstNode.text.charAt(localOffset);\n      if (!nameRegexp.test(textAtOffset)) {\n        offset--;\n      }\n    }\n    return findLeafNodeAtOffset(cstNode, offset);\n  }\n  return void 0;\n}\n__name(findDeclarationNodeAtOffset, \"findDeclarationNodeAtOffset\");\nfunction findCommentNode(cstNode, commentNames) {\n  if (cstNode) {\n    const previous = getPreviousNode(cstNode, true);\n    if (previous && isCommentNode(previous, commentNames)) {\n      return previous;\n    }\n    if (isRootCstNode(cstNode)) {\n      const endIndex = cstNode.content.findIndex((e) => !e.hidden);\n      for (let i = endIndex - 1; i >= 0; i--) {\n        const child = cstNode.content[i];\n        if (isCommentNode(child, commentNames)) {\n          return child;\n        }\n      }\n    }\n  }\n  return void 0;\n}\n__name(findCommentNode, \"findCommentNode\");\nfunction isCommentNode(cstNode, commentNames) {\n  return isLeafCstNode(cstNode) && commentNames.includes(cstNode.tokenType.name);\n}\n__name(isCommentNode, \"isCommentNode\");\nfunction findLeafNodeAtOffset(node, offset) {\n  if (isLeafCstNode(node)) {\n    return node;\n  } else if (isCompositeCstNode(node)) {\n    const searchResult = binarySearch(node, offset, false);\n    if (searchResult) {\n      return findLeafNodeAtOffset(searchResult, offset);\n    }\n  }\n  return void 0;\n}\n__name(findLeafNodeAtOffset, \"findLeafNodeAtOffset\");\nfunction findLeafNodeBeforeOffset(node, offset) {\n  if (isLeafCstNode(node)) {\n    return node;\n  } else if (isCompositeCstNode(node)) {\n    const searchResult = binarySearch(node, offset, true);\n    if (searchResult) {\n      return findLeafNodeBeforeOffset(searchResult, offset);\n    }\n  }\n  return void 0;\n}\n__name(findLeafNodeBeforeOffset, \"findLeafNodeBeforeOffset\");\nfunction binarySearch(node, offset, closest) {\n  let left = 0;\n  let right = node.content.length - 1;\n  let closestNode = void 0;\n  while (left <= right) {\n    const middle = Math.floor((left + right) / 2);\n    const middleNode = node.content[middle];\n    if (middleNode.offset <= offset && middleNode.end > offset) {\n      return middleNode;\n    }\n    if (middleNode.end <= offset) {\n      closestNode = closest ? middleNode : void 0;\n      left = middle + 1;\n    } else {\n      right = middle - 1;\n    }\n  }\n  return closestNode;\n}\n__name(binarySearch, \"binarySearch\");\nfunction getPreviousNode(node, hidden = true) {\n  while (node.container) {\n    const parent = node.container;\n    let index = parent.content.indexOf(node);\n    while (index > 0) {\n      index--;\n      const previous = parent.content[index];\n      if (hidden || !previous.hidden) {\n        return previous;\n      }\n    }\n    node = parent;\n  }\n  return void 0;\n}\n__name(getPreviousNode, \"getPreviousNode\");\nfunction getNextNode(node, hidden = true) {\n  while (node.container) {\n    const parent = node.container;\n    let index = parent.content.indexOf(node);\n    const last = parent.content.length - 1;\n    while (index < last) {\n      index++;\n      const next = parent.content[index];\n      if (hidden || !next.hidden) {\n        return next;\n      }\n    }\n    node = parent;\n  }\n  return void 0;\n}\n__name(getNextNode, \"getNextNode\");\nfunction getStartlineNode(node) {\n  if (node.range.start.character === 0) {\n    return node;\n  }\n  const line = node.range.start.line;\n  let last = node;\n  let index;\n  while (node.container) {\n    const parent = node.container;\n    const selfIndex = index !== null && index !== void 0 ? index : parent.content.indexOf(node);\n    if (selfIndex === 0) {\n      node = parent;\n      index = void 0;\n    } else {\n      index = selfIndex - 1;\n      node = parent.content[index];\n    }\n    if (node.range.start.line !== line) {\n      break;\n    }\n    last = node;\n  }\n  return last;\n}\n__name(getStartlineNode, \"getStartlineNode\");\nfunction getInteriorNodes(start, end) {\n  const commonParent = getCommonParent(start, end);\n  if (!commonParent) {\n    return [];\n  }\n  return commonParent.parent.content.slice(commonParent.a + 1, commonParent.b);\n}\n__name(getInteriorNodes, \"getInteriorNodes\");\nfunction getCommonParent(a, b) {\n  const aParents = getParentChain(a);\n  const bParents = getParentChain(b);\n  let current;\n  for (let i = 0; i < aParents.length && i < bParents.length; i++) {\n    const aParent = aParents[i];\n    const bParent = bParents[i];\n    if (aParent.parent === bParent.parent) {\n      current = {\n        parent: aParent.parent,\n        a: aParent.index,\n        b: bParent.index\n      };\n    } else {\n      break;\n    }\n  }\n  return current;\n}\n__name(getCommonParent, \"getCommonParent\");\nfunction getParentChain(node) {\n  const chain = [];\n  while (node.container) {\n    const parent = node.container;\n    const index = parent.content.indexOf(node);\n    chain.push({\n      parent,\n      index\n    });\n    node = parent;\n  }\n  return chain.reverse();\n}\n__name(getParentChain, \"getParentChain\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/grammar-utils.js\nvar grammar_utils_exports = {};\n__export(grammar_utils_exports, {\n  findAssignment: () => findAssignment,\n  findNameAssignment: () => findNameAssignment,\n  findNodeForKeyword: () => findNodeForKeyword,\n  findNodeForProperty: () => findNodeForProperty,\n  findNodesForKeyword: () => findNodesForKeyword,\n  findNodesForKeywordInternal: () => findNodesForKeywordInternal,\n  findNodesForProperty: () => findNodesForProperty,\n  getActionAtElement: () => getActionAtElement,\n  getActionType: () => getActionType,\n  getAllReachableRules: () => getAllReachableRules,\n  getCrossReferenceTerminal: () => getCrossReferenceTerminal,\n  getEntryRule: () => getEntryRule,\n  getExplicitRuleType: () => getExplicitRuleType,\n  getHiddenRules: () => getHiddenRules,\n  getRuleType: () => getRuleType,\n  getRuleTypeName: () => getRuleTypeName,\n  getTypeName: () => getTypeName,\n  isArrayCardinality: () => isArrayCardinality,\n  isArrayOperator: () => isArrayOperator,\n  isCommentTerminal: () => isCommentTerminal,\n  isDataType: () => isDataType,\n  isDataTypeRule: () => isDataTypeRule,\n  isOptionalCardinality: () => isOptionalCardinality,\n  terminalRegex: () => terminalRegex\n});\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/errors.js\nvar ErrorWithLocation = class extends Error {\n  static {\n    __name(this, \"ErrorWithLocation\");\n  }\n  constructor(node, message) {\n    super(node ? `${message} at ${node.range.start.line}:${node.range.start.character}` : message);\n  }\n};\nfunction assertUnreachable(_) {\n  throw new Error(\"Error! The input value was not handled.\");\n}\n__name(assertUnreachable, \"assertUnreachable\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/languages/generated/ast.js\nvar ast_exports = {};\n__export(ast_exports, {\n  AbstractElement: () => AbstractElement,\n  AbstractRule: () => AbstractRule,\n  AbstractType: () => AbstractType,\n  Action: () => Action,\n  Alternatives: () => Alternatives,\n  ArrayLiteral: () => ArrayLiteral,\n  ArrayType: () => ArrayType,\n  Assignment: () => Assignment,\n  BooleanLiteral: () => BooleanLiteral,\n  CharacterRange: () => CharacterRange,\n  Condition: () => Condition,\n  Conjunction: () => Conjunction,\n  CrossReference: () => CrossReference,\n  Disjunction: () => Disjunction,\n  EndOfFile: () => EndOfFile,\n  Grammar: () => Grammar,\n  GrammarImport: () => GrammarImport,\n  Group: () => Group,\n  InferredType: () => InferredType,\n  Interface: () => Interface,\n  Keyword: () => Keyword,\n  LangiumGrammarAstReflection: () => LangiumGrammarAstReflection,\n  LangiumGrammarTerminals: () => LangiumGrammarTerminals,\n  NamedArgument: () => NamedArgument,\n  NegatedToken: () => NegatedToken,\n  Negation: () => Negation,\n  NumberLiteral: () => NumberLiteral,\n  Parameter: () => Parameter,\n  ParameterReference: () => ParameterReference,\n  ParserRule: () => ParserRule,\n  ReferenceType: () => ReferenceType,\n  RegexToken: () => RegexToken,\n  ReturnType: () => ReturnType,\n  RuleCall: () => RuleCall,\n  SimpleType: () => SimpleType,\n  StringLiteral: () => StringLiteral,\n  TerminalAlternatives: () => TerminalAlternatives,\n  TerminalGroup: () => TerminalGroup,\n  TerminalRule: () => TerminalRule,\n  TerminalRuleCall: () => TerminalRuleCall,\n  Type: () => Type,\n  TypeAttribute: () => TypeAttribute,\n  TypeDefinition: () => TypeDefinition,\n  UnionType: () => UnionType,\n  UnorderedGroup: () => UnorderedGroup,\n  UntilToken: () => UntilToken,\n  ValueLiteral: () => ValueLiteral,\n  Wildcard: () => Wildcard,\n  isAbstractElement: () => isAbstractElement,\n  isAbstractRule: () => isAbstractRule,\n  isAbstractType: () => isAbstractType,\n  isAction: () => isAction,\n  isAlternatives: () => isAlternatives,\n  isArrayLiteral: () => isArrayLiteral,\n  isArrayType: () => isArrayType,\n  isAssignment: () => isAssignment,\n  isBooleanLiteral: () => isBooleanLiteral,\n  isCharacterRange: () => isCharacterRange,\n  isCondition: () => isCondition,\n  isConjunction: () => isConjunction,\n  isCrossReference: () => isCrossReference,\n  isDisjunction: () => isDisjunction,\n  isEndOfFile: () => isEndOfFile,\n  isFeatureName: () => isFeatureName,\n  isGrammar: () => isGrammar,\n  isGrammarImport: () => isGrammarImport,\n  isGroup: () => isGroup,\n  isInferredType: () => isInferredType,\n  isInterface: () => isInterface,\n  isKeyword: () => isKeyword,\n  isNamedArgument: () => isNamedArgument,\n  isNegatedToken: () => isNegatedToken,\n  isNegation: () => isNegation,\n  isNumberLiteral: () => isNumberLiteral,\n  isParameter: () => isParameter,\n  isParameterReference: () => isParameterReference,\n  isParserRule: () => isParserRule,\n  isPrimitiveType: () => isPrimitiveType,\n  isReferenceType: () => isReferenceType,\n  isRegexToken: () => isRegexToken,\n  isReturnType: () => isReturnType,\n  isRuleCall: () => isRuleCall,\n  isSimpleType: () => isSimpleType,\n  isStringLiteral: () => isStringLiteral,\n  isTerminalAlternatives: () => isTerminalAlternatives,\n  isTerminalGroup: () => isTerminalGroup,\n  isTerminalRule: () => isTerminalRule,\n  isTerminalRuleCall: () => isTerminalRuleCall,\n  isType: () => isType,\n  isTypeAttribute: () => isTypeAttribute,\n  isTypeDefinition: () => isTypeDefinition,\n  isUnionType: () => isUnionType,\n  isUnorderedGroup: () => isUnorderedGroup,\n  isUntilToken: () => isUntilToken,\n  isValueLiteral: () => isValueLiteral,\n  isWildcard: () => isWildcard,\n  reflection: () => reflection\n});\nvar LangiumGrammarTerminals = {\n  ID: /\\^?[_a-zA-Z][\\w_]*/,\n  STRING: /\"(\\\\.|[^\"\\\\])*\"|'(\\\\.|[^'\\\\])*'/,\n  NUMBER: /NaN|-?((\\d*\\.\\d+|\\d+)([Ee][+-]?\\d+)?|Infinity)/,\n  RegexLiteral: /\\/(?![*+?])(?:[^\\r\\n\\[/\\\\]|\\\\.|\\[(?:[^\\r\\n\\]\\\\]|\\\\.)*\\])+\\/[a-z]*/,\n  WS: /\\s+/,\n  ML_COMMENT: /\\/\\*[\\s\\S]*?\\*\\//,\n  SL_COMMENT: /\\/\\/[^\\n\\r]*/\n};\nvar AbstractRule = \"AbstractRule\";\nfunction isAbstractRule(item) {\n  return reflection.isInstance(item, AbstractRule);\n}\n__name(isAbstractRule, \"isAbstractRule\");\nvar AbstractType = \"AbstractType\";\nfunction isAbstractType(item) {\n  return reflection.isInstance(item, AbstractType);\n}\n__name(isAbstractType, \"isAbstractType\");\nvar Condition = \"Condition\";\nfunction isCondition(item) {\n  return reflection.isInstance(item, Condition);\n}\n__name(isCondition, \"isCondition\");\nfunction isFeatureName(item) {\n  return isPrimitiveType(item) || item === \"current\" || item === \"entry\" || item === \"extends\" || item === \"false\" || item === \"fragment\" || item === \"grammar\" || item === \"hidden\" || item === \"import\" || item === \"interface\" || item === \"returns\" || item === \"terminal\" || item === \"true\" || item === \"type\" || item === \"infer\" || item === \"infers\" || item === \"with\" || typeof item === \"string\" && /\\^?[_a-zA-Z][\\w_]*/.test(item);\n}\n__name(isFeatureName, \"isFeatureName\");\nfunction isPrimitiveType(item) {\n  return item === \"string\" || item === \"number\" || item === \"boolean\" || item === \"Date\" || item === \"bigint\";\n}\n__name(isPrimitiveType, \"isPrimitiveType\");\nvar TypeDefinition = \"TypeDefinition\";\nfunction isTypeDefinition(item) {\n  return reflection.isInstance(item, TypeDefinition);\n}\n__name(isTypeDefinition, \"isTypeDefinition\");\nvar ValueLiteral = \"ValueLiteral\";\nfunction isValueLiteral(item) {\n  return reflection.isInstance(item, ValueLiteral);\n}\n__name(isValueLiteral, \"isValueLiteral\");\nvar AbstractElement = \"AbstractElement\";\nfunction isAbstractElement(item) {\n  return reflection.isInstance(item, AbstractElement);\n}\n__name(isAbstractElement, \"isAbstractElement\");\nvar ArrayLiteral = \"ArrayLiteral\";\nfunction isArrayLiteral(item) {\n  return reflection.isInstance(item, ArrayLiteral);\n}\n__name(isArrayLiteral, \"isArrayLiteral\");\nvar ArrayType = \"ArrayType\";\nfunction isArrayType(item) {\n  return reflection.isInstance(item, ArrayType);\n}\n__name(isArrayType, \"isArrayType\");\nvar BooleanLiteral = \"BooleanLiteral\";\nfunction isBooleanLiteral(item) {\n  return reflection.isInstance(item, BooleanLiteral);\n}\n__name(isBooleanLiteral, \"isBooleanLiteral\");\nvar Conjunction = \"Conjunction\";\nfunction isConjunction(item) {\n  return reflection.isInstance(item, Conjunction);\n}\n__name(isConjunction, \"isConjunction\");\nvar Disjunction = \"Disjunction\";\nfunction isDisjunction(item) {\n  return reflection.isInstance(item, Disjunction);\n}\n__name(isDisjunction, \"isDisjunction\");\nvar Grammar = \"Grammar\";\nfunction isGrammar(item) {\n  return reflection.isInstance(item, Grammar);\n}\n__name(isGrammar, \"isGrammar\");\nvar GrammarImport = \"GrammarImport\";\nfunction isGrammarImport(item) {\n  return reflection.isInstance(item, GrammarImport);\n}\n__name(isGrammarImport, \"isGrammarImport\");\nvar InferredType = \"InferredType\";\nfunction isInferredType(item) {\n  return reflection.isInstance(item, InferredType);\n}\n__name(isInferredType, \"isInferredType\");\nvar Interface = \"Interface\";\nfunction isInterface(item) {\n  return reflection.isInstance(item, Interface);\n}\n__name(isInterface, \"isInterface\");\nvar NamedArgument = \"NamedArgument\";\nfunction isNamedArgument(item) {\n  return reflection.isInstance(item, NamedArgument);\n}\n__name(isNamedArgument, \"isNamedArgument\");\nvar Negation = \"Negation\";\nfunction isNegation(item) {\n  return reflection.isInstance(item, Negation);\n}\n__name(isNegation, \"isNegation\");\nvar NumberLiteral = \"NumberLiteral\";\nfunction isNumberLiteral(item) {\n  return reflection.isInstance(item, NumberLiteral);\n}\n__name(isNumberLiteral, \"isNumberLiteral\");\nvar Parameter = \"Parameter\";\nfunction isParameter(item) {\n  return reflection.isInstance(item, Parameter);\n}\n__name(isParameter, \"isParameter\");\nvar ParameterReference = \"ParameterReference\";\nfunction isParameterReference(item) {\n  return reflection.isInstance(item, ParameterReference);\n}\n__name(isParameterReference, \"isParameterReference\");\nvar ParserRule = \"ParserRule\";\nfunction isParserRule(item) {\n  return reflection.isInstance(item, ParserRule);\n}\n__name(isParserRule, \"isParserRule\");\nvar ReferenceType = \"ReferenceType\";\nfunction isReferenceType(item) {\n  return reflection.isInstance(item, ReferenceType);\n}\n__name(isReferenceType, \"isReferenceType\");\nvar ReturnType = \"ReturnType\";\nfunction isReturnType(item) {\n  return reflection.isInstance(item, ReturnType);\n}\n__name(isReturnType, \"isReturnType\");\nvar SimpleType = \"SimpleType\";\nfunction isSimpleType(item) {\n  return reflection.isInstance(item, SimpleType);\n}\n__name(isSimpleType, \"isSimpleType\");\nvar StringLiteral = \"StringLiteral\";\nfunction isStringLiteral(item) {\n  return reflection.isInstance(item, StringLiteral);\n}\n__name(isStringLiteral, \"isStringLiteral\");\nvar TerminalRule = \"TerminalRule\";\nfunction isTerminalRule(item) {\n  return reflection.isInstance(item, TerminalRule);\n}\n__name(isTerminalRule, \"isTerminalRule\");\nvar Type = \"Type\";\nfunction isType(item) {\n  return reflection.isInstance(item, Type);\n}\n__name(isType, \"isType\");\nvar TypeAttribute = \"TypeAttribute\";\nfunction isTypeAttribute(item) {\n  return reflection.isInstance(item, TypeAttribute);\n}\n__name(isTypeAttribute, \"isTypeAttribute\");\nvar UnionType = \"UnionType\";\nfunction isUnionType(item) {\n  return reflection.isInstance(item, UnionType);\n}\n__name(isUnionType, \"isUnionType\");\nvar Action = \"Action\";\nfunction isAction(item) {\n  return reflection.isInstance(item, Action);\n}\n__name(isAction, \"isAction\");\nvar Alternatives = \"Alternatives\";\nfunction isAlternatives(item) {\n  return reflection.isInstance(item, Alternatives);\n}\n__name(isAlternatives, \"isAlternatives\");\nvar Assignment = \"Assignment\";\nfunction isAssignment(item) {\n  return reflection.isInstance(item, Assignment);\n}\n__name(isAssignment, \"isAssignment\");\nvar CharacterRange = \"CharacterRange\";\nfunction isCharacterRange(item) {\n  return reflection.isInstance(item, CharacterRange);\n}\n__name(isCharacterRange, \"isCharacterRange\");\nvar CrossReference = \"CrossReference\";\nfunction isCrossReference(item) {\n  return reflection.isInstance(item, CrossReference);\n}\n__name(isCrossReference, \"isCrossReference\");\nvar EndOfFile = \"EndOfFile\";\nfunction isEndOfFile(item) {\n  return reflection.isInstance(item, EndOfFile);\n}\n__name(isEndOfFile, \"isEndOfFile\");\nvar Group = \"Group\";\nfunction isGroup(item) {\n  return reflection.isInstance(item, Group);\n}\n__name(isGroup, \"isGroup\");\nvar Keyword = \"Keyword\";\nfunction isKeyword(item) {\n  return reflection.isInstance(item, Keyword);\n}\n__name(isKeyword, \"isKeyword\");\nvar NegatedToken = \"NegatedToken\";\nfunction isNegatedToken(item) {\n  return reflection.isInstance(item, NegatedToken);\n}\n__name(isNegatedToken, \"isNegatedToken\");\nvar RegexToken = \"RegexToken\";\nfunction isRegexToken(item) {\n  return reflection.isInstance(item, RegexToken);\n}\n__name(isRegexToken, \"isRegexToken\");\nvar RuleCall = \"RuleCall\";\nfunction isRuleCall(item) {\n  return reflection.isInstance(item, RuleCall);\n}\n__name(isRuleCall, \"isRuleCall\");\nvar TerminalAlternatives = \"TerminalAlternatives\";\nfunction isTerminalAlternatives(item) {\n  return reflection.isInstance(item, TerminalAlternatives);\n}\n__name(isTerminalAlternatives, \"isTerminalAlternatives\");\nvar TerminalGroup = \"TerminalGroup\";\nfunction isTerminalGroup(item) {\n  return reflection.isInstance(item, TerminalGroup);\n}\n__name(isTerminalGroup, \"isTerminalGroup\");\nvar TerminalRuleCall = \"TerminalRuleCall\";\nfunction isTerminalRuleCall(item) {\n  return reflection.isInstance(item, TerminalRuleCall);\n}\n__name(isTerminalRuleCall, \"isTerminalRuleCall\");\nvar UnorderedGroup = \"UnorderedGroup\";\nfunction isUnorderedGroup(item) {\n  return reflection.isInstance(item, UnorderedGroup);\n}\n__name(isUnorderedGroup, \"isUnorderedGroup\");\nvar UntilToken = \"UntilToken\";\nfunction isUntilToken(item) {\n  return reflection.isInstance(item, UntilToken);\n}\n__name(isUntilToken, \"isUntilToken\");\nvar Wildcard = \"Wildcard\";\nfunction isWildcard(item) {\n  return reflection.isInstance(item, Wildcard);\n}\n__name(isWildcard, \"isWildcard\");\nvar LangiumGrammarAstReflection = class extends AbstractAstReflection {\n  static {\n    __name(this, \"LangiumGrammarAstReflection\");\n  }\n  getAllTypes() {\n    return [AbstractElement, AbstractRule, AbstractType, Action, Alternatives, ArrayLiteral, ArrayType, Assignment, BooleanLiteral, CharacterRange, Condition, Conjunction, CrossReference, Disjunction, EndOfFile, Grammar, GrammarImport, Group, InferredType, Interface, Keyword, NamedArgument, NegatedToken, Negation, NumberLiteral, Parameter, ParameterReference, ParserRule, ReferenceType, RegexToken, ReturnType, RuleCall, SimpleType, StringLiteral, TerminalAlternatives, TerminalGroup, TerminalRule, TerminalRuleCall, Type, TypeAttribute, TypeDefinition, UnionType, UnorderedGroup, UntilToken, ValueLiteral, Wildcard];\n  }\n  computeIsSubtype(subtype, supertype) {\n    switch (subtype) {\n      case Action:\n      case Alternatives:\n      case Assignment:\n      case CharacterRange:\n      case CrossReference:\n      case EndOfFile:\n      case Group:\n      case Keyword:\n      case NegatedToken:\n      case RegexToken:\n      case RuleCall:\n      case TerminalAlternatives:\n      case TerminalGroup:\n      case TerminalRuleCall:\n      case UnorderedGroup:\n      case UntilToken:\n      case Wildcard: {\n        return this.isSubtype(AbstractElement, supertype);\n      }\n      case ArrayLiteral:\n      case NumberLiteral:\n      case StringLiteral: {\n        return this.isSubtype(ValueLiteral, supertype);\n      }\n      case ArrayType:\n      case ReferenceType:\n      case SimpleType:\n      case UnionType: {\n        return this.isSubtype(TypeDefinition, supertype);\n      }\n      case BooleanLiteral: {\n        return this.isSubtype(Condition, supertype) || this.isSubtype(ValueLiteral, supertype);\n      }\n      case Conjunction:\n      case Disjunction:\n      case Negation:\n      case ParameterReference: {\n        return this.isSubtype(Condition, supertype);\n      }\n      case InferredType:\n      case Interface:\n      case Type: {\n        return this.isSubtype(AbstractType, supertype);\n      }\n      case ParserRule: {\n        return this.isSubtype(AbstractRule, supertype) || this.isSubtype(AbstractType, supertype);\n      }\n      case TerminalRule: {\n        return this.isSubtype(AbstractRule, supertype);\n      }\n      default: {\n        return false;\n      }\n    }\n  }\n  getReferenceType(refInfo) {\n    const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\n    switch (referenceId) {\n      case \"Action:type\":\n      case \"CrossReference:type\":\n      case \"Interface:superTypes\":\n      case \"ParserRule:returnType\":\n      case \"SimpleType:typeRef\": {\n        return AbstractType;\n      }\n      case \"Grammar:hiddenTokens\":\n      case \"ParserRule:hiddenTokens\":\n      case \"RuleCall:rule\": {\n        return AbstractRule;\n      }\n      case \"Grammar:usedGrammars\": {\n        return Grammar;\n      }\n      case \"NamedArgument:parameter\":\n      case \"ParameterReference:parameter\": {\n        return Parameter;\n      }\n      case \"TerminalRuleCall:rule\": {\n        return TerminalRule;\n      }\n      default: {\n        throw new Error(`${referenceId} is not a valid reference id.`);\n      }\n    }\n  }\n  getTypeMetaData(type) {\n    switch (type) {\n      case AbstractElement: {\n        return {\n          name: AbstractElement,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"lookahead\" }\n          ]\n        };\n      }\n      case ArrayLiteral: {\n        return {\n          name: ArrayLiteral,\n          properties: [\n            { name: \"elements\", defaultValue: [] }\n          ]\n        };\n      }\n      case ArrayType: {\n        return {\n          name: ArrayType,\n          properties: [\n            { name: \"elementType\" }\n          ]\n        };\n      }\n      case BooleanLiteral: {\n        return {\n          name: BooleanLiteral,\n          properties: [\n            { name: \"true\", defaultValue: false }\n          ]\n        };\n      }\n      case Conjunction: {\n        return {\n          name: Conjunction,\n          properties: [\n            { name: \"left\" },\n            { name: \"right\" }\n          ]\n        };\n      }\n      case Disjunction: {\n        return {\n          name: Disjunction,\n          properties: [\n            { name: \"left\" },\n            { name: \"right\" }\n          ]\n        };\n      }\n      case Grammar: {\n        return {\n          name: Grammar,\n          properties: [\n            { name: \"definesHiddenTokens\", defaultValue: false },\n            { name: \"hiddenTokens\", defaultValue: [] },\n            { name: \"imports\", defaultValue: [] },\n            { name: \"interfaces\", defaultValue: [] },\n            { name: \"isDeclared\", defaultValue: false },\n            { name: \"name\" },\n            { name: \"rules\", defaultValue: [] },\n            { name: \"types\", defaultValue: [] },\n            { name: \"usedGrammars\", defaultValue: [] }\n          ]\n        };\n      }\n      case GrammarImport: {\n        return {\n          name: GrammarImport,\n          properties: [\n            { name: \"path\" }\n          ]\n        };\n      }\n      case InferredType: {\n        return {\n          name: InferredType,\n          properties: [\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Interface: {\n        return {\n          name: Interface,\n          properties: [\n            { name: \"attributes\", defaultValue: [] },\n            { name: \"name\" },\n            { name: \"superTypes\", defaultValue: [] }\n          ]\n        };\n      }\n      case NamedArgument: {\n        return {\n          name: NamedArgument,\n          properties: [\n            { name: \"calledByName\", defaultValue: false },\n            { name: \"parameter\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case Negation: {\n        return {\n          name: Negation,\n          properties: [\n            { name: \"value\" }\n          ]\n        };\n      }\n      case NumberLiteral: {\n        return {\n          name: NumberLiteral,\n          properties: [\n            { name: \"value\" }\n          ]\n        };\n      }\n      case Parameter: {\n        return {\n          name: Parameter,\n          properties: [\n            { name: \"name\" }\n          ]\n        };\n      }\n      case ParameterReference: {\n        return {\n          name: ParameterReference,\n          properties: [\n            { name: \"parameter\" }\n          ]\n        };\n      }\n      case ParserRule: {\n        return {\n          name: ParserRule,\n          properties: [\n            { name: \"dataType\" },\n            { name: \"definesHiddenTokens\", defaultValue: false },\n            { name: \"definition\" },\n            { name: \"entry\", defaultValue: false },\n            { name: \"fragment\", defaultValue: false },\n            { name: \"hiddenTokens\", defaultValue: [] },\n            { name: \"inferredType\" },\n            { name: \"name\" },\n            { name: \"parameters\", defaultValue: [] },\n            { name: \"returnType\" },\n            { name: \"wildcard\", defaultValue: false }\n          ]\n        };\n      }\n      case ReferenceType: {\n        return {\n          name: ReferenceType,\n          properties: [\n            { name: \"referenceType\" }\n          ]\n        };\n      }\n      case ReturnType: {\n        return {\n          name: ReturnType,\n          properties: [\n            { name: \"name\" }\n          ]\n        };\n      }\n      case SimpleType: {\n        return {\n          name: SimpleType,\n          properties: [\n            { name: \"primitiveType\" },\n            { name: \"stringType\" },\n            { name: \"typeRef\" }\n          ]\n        };\n      }\n      case StringLiteral: {\n        return {\n          name: StringLiteral,\n          properties: [\n            { name: \"value\" }\n          ]\n        };\n      }\n      case TerminalRule: {\n        return {\n          name: TerminalRule,\n          properties: [\n            { name: \"definition\" },\n            { name: \"fragment\", defaultValue: false },\n            { name: \"hidden\", defaultValue: false },\n            { name: \"name\" },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Type: {\n        return {\n          name: Type,\n          properties: [\n            { name: \"name\" },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case TypeAttribute: {\n        return {\n          name: TypeAttribute,\n          properties: [\n            { name: \"defaultValue\" },\n            { name: \"isOptional\", defaultValue: false },\n            { name: \"name\" },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case UnionType: {\n        return {\n          name: UnionType,\n          properties: [\n            { name: \"types\", defaultValue: [] }\n          ]\n        };\n      }\n      case Action: {\n        return {\n          name: Action,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"feature\" },\n            { name: \"inferredType\" },\n            { name: \"lookahead\" },\n            { name: \"operator\" },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Alternatives: {\n        return {\n          name: Alternatives,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"elements\", defaultValue: [] },\n            { name: \"lookahead\" }\n          ]\n        };\n      }\n      case Assignment: {\n        return {\n          name: Assignment,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"feature\" },\n            { name: \"lookahead\" },\n            { name: \"operator\" },\n            { name: \"terminal\" }\n          ]\n        };\n      }\n      case CharacterRange: {\n        return {\n          name: CharacterRange,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"left\" },\n            { name: \"lookahead\" },\n            { name: \"right\" }\n          ]\n        };\n      }\n      case CrossReference: {\n        return {\n          name: CrossReference,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"deprecatedSyntax\", defaultValue: false },\n            { name: \"lookahead\" },\n            { name: \"terminal\" },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case EndOfFile: {\n        return {\n          name: EndOfFile,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"lookahead\" }\n          ]\n        };\n      }\n      case Group: {\n        return {\n          name: Group,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"elements\", defaultValue: [] },\n            { name: \"guardCondition\" },\n            { name: \"lookahead\" }\n          ]\n        };\n      }\n      case Keyword: {\n        return {\n          name: Keyword,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"lookahead\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case NegatedToken: {\n        return {\n          name: NegatedToken,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"lookahead\" },\n            { name: \"terminal\" }\n          ]\n        };\n      }\n      case RegexToken: {\n        return {\n          name: RegexToken,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"lookahead\" },\n            { name: \"regex\" }\n          ]\n        };\n      }\n      case RuleCall: {\n        return {\n          name: RuleCall,\n          properties: [\n            { name: \"arguments\", defaultValue: [] },\n            { name: \"cardinality\" },\n            { name: \"lookahead\" },\n            { name: \"rule\" }\n          ]\n        };\n      }\n      case TerminalAlternatives: {\n        return {\n          name: TerminalAlternatives,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"elements\", defaultValue: [] },\n            { name: \"lookahead\" }\n          ]\n        };\n      }\n      case TerminalGroup: {\n        return {\n          name: TerminalGroup,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"elements\", defaultValue: [] },\n            { name: \"lookahead\" }\n          ]\n        };\n      }\n      case TerminalRuleCall: {\n        return {\n          name: TerminalRuleCall,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"lookahead\" },\n            { name: \"rule\" }\n          ]\n        };\n      }\n      case UnorderedGroup: {\n        return {\n          name: UnorderedGroup,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"elements\", defaultValue: [] },\n            { name: \"lookahead\" }\n          ]\n        };\n      }\n      case UntilToken: {\n        return {\n          name: UntilToken,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"lookahead\" },\n            { name: \"terminal\" }\n          ]\n        };\n      }\n      case Wildcard: {\n        return {\n          name: Wildcard,\n          properties: [\n            { name: \"cardinality\" },\n            { name: \"lookahead\" }\n          ]\n        };\n      }\n      default: {\n        return {\n          name: type,\n          properties: []\n        };\n      }\n    }\n  }\n};\nvar reflection = new LangiumGrammarAstReflection();\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/ast-utils.js\nvar ast_utils_exports = {};\n__export(ast_utils_exports, {\n  assignMandatoryProperties: () => assignMandatoryProperties,\n  copyAstNode: () => copyAstNode,\n  findLocalReferences: () => findLocalReferences,\n  findRootNode: () => findRootNode,\n  getContainerOfType: () => getContainerOfType,\n  getDocument: () => getDocument,\n  hasContainerOfType: () => hasContainerOfType,\n  linkContentToContainer: () => linkContentToContainer,\n  streamAllContents: () => streamAllContents,\n  streamAst: () => streamAst,\n  streamContents: () => streamContents,\n  streamReferences: () => streamReferences\n});\nfunction linkContentToContainer(node) {\n  for (const [name, value] of Object.entries(node)) {\n    if (!name.startsWith(\"$\")) {\n      if (Array.isArray(value)) {\n        value.forEach((item, index) => {\n          if (isAstNode(item)) {\n            item.$container = node;\n            item.$containerProperty = name;\n            item.$containerIndex = index;\n          }\n        });\n      } else if (isAstNode(value)) {\n        value.$container = node;\n        value.$containerProperty = name;\n      }\n    }\n  }\n}\n__name(linkContentToContainer, \"linkContentToContainer\");\nfunction getContainerOfType(node, typePredicate) {\n  let item = node;\n  while (item) {\n    if (typePredicate(item)) {\n      return item;\n    }\n    item = item.$container;\n  }\n  return void 0;\n}\n__name(getContainerOfType, \"getContainerOfType\");\nfunction hasContainerOfType(node, predicate) {\n  let item = node;\n  while (item) {\n    if (predicate(item)) {\n      return true;\n    }\n    item = item.$container;\n  }\n  return false;\n}\n__name(hasContainerOfType, \"hasContainerOfType\");\nfunction getDocument(node) {\n  const rootNode = findRootNode(node);\n  const result = rootNode.$document;\n  if (!result) {\n    throw new Error(\"AST node has no document.\");\n  }\n  return result;\n}\n__name(getDocument, \"getDocument\");\nfunction findRootNode(node) {\n  while (node.$container) {\n    node = node.$container;\n  }\n  return node;\n}\n__name(findRootNode, \"findRootNode\");\nfunction streamContents(node, options) {\n  if (!node) {\n    throw new Error(\"Node must be an AstNode.\");\n  }\n  const range = options === null || options === void 0 ? void 0 : options.range;\n  return new StreamImpl(() => ({\n    keys: Object.keys(node),\n    keyIndex: 0,\n    arrayIndex: 0\n  }), (state) => {\n    while (state.keyIndex < state.keys.length) {\n      const property = state.keys[state.keyIndex];\n      if (!property.startsWith(\"$\")) {\n        const value = node[property];\n        if (isAstNode(value)) {\n          state.keyIndex++;\n          if (isAstNodeInRange(value, range)) {\n            return { done: false, value };\n          }\n        } else if (Array.isArray(value)) {\n          while (state.arrayIndex < value.length) {\n            const index = state.arrayIndex++;\n            const element = value[index];\n            if (isAstNode(element) && isAstNodeInRange(element, range)) {\n              return { done: false, value: element };\n            }\n          }\n          state.arrayIndex = 0;\n        }\n      }\n      state.keyIndex++;\n    }\n    return DONE_RESULT;\n  });\n}\n__name(streamContents, \"streamContents\");\nfunction streamAllContents(root, options) {\n  if (!root) {\n    throw new Error(\"Root node must be an AstNode.\");\n  }\n  return new TreeStreamImpl(root, (node) => streamContents(node, options));\n}\n__name(streamAllContents, \"streamAllContents\");\nfunction streamAst(root, options) {\n  if (!root) {\n    throw new Error(\"Root node must be an AstNode.\");\n  } else if ((options === null || options === void 0 ? void 0 : options.range) && !isAstNodeInRange(root, options.range)) {\n    return new TreeStreamImpl(root, () => []);\n  }\n  return new TreeStreamImpl(root, (node) => streamContents(node, options), { includeRoot: true });\n}\n__name(streamAst, \"streamAst\");\nfunction isAstNodeInRange(astNode, range) {\n  var _a;\n  if (!range) {\n    return true;\n  }\n  const nodeRange = (_a = astNode.$cstNode) === null || _a === void 0 ? void 0 : _a.range;\n  if (!nodeRange) {\n    return false;\n  }\n  return inRange(nodeRange, range);\n}\n__name(isAstNodeInRange, \"isAstNodeInRange\");\nfunction streamReferences(node) {\n  return new StreamImpl(() => ({\n    keys: Object.keys(node),\n    keyIndex: 0,\n    arrayIndex: 0\n  }), (state) => {\n    while (state.keyIndex < state.keys.length) {\n      const property = state.keys[state.keyIndex];\n      if (!property.startsWith(\"$\")) {\n        const value = node[property];\n        if (isReference(value)) {\n          state.keyIndex++;\n          return { done: false, value: { reference: value, container: node, property } };\n        } else if (Array.isArray(value)) {\n          while (state.arrayIndex < value.length) {\n            const index = state.arrayIndex++;\n            const element = value[index];\n            if (isReference(element)) {\n              return { done: false, value: { reference: element, container: node, property, index } };\n            }\n          }\n          state.arrayIndex = 0;\n        }\n      }\n      state.keyIndex++;\n    }\n    return DONE_RESULT;\n  });\n}\n__name(streamReferences, \"streamReferences\");\nfunction findLocalReferences(targetNode, lookup = getDocument(targetNode).parseResult.value) {\n  const refs = [];\n  streamAst(lookup).forEach((node) => {\n    streamReferences(node).forEach((refInfo) => {\n      if (refInfo.reference.ref === targetNode) {\n        refs.push(refInfo.reference);\n      }\n    });\n  });\n  return stream(refs);\n}\n__name(findLocalReferences, \"findLocalReferences\");\nfunction assignMandatoryProperties(reflection3, node) {\n  const typeMetaData = reflection3.getTypeMetaData(node.$type);\n  const genericNode = node;\n  for (const property of typeMetaData.properties) {\n    if (property.defaultValue !== void 0 && genericNode[property.name] === void 0) {\n      genericNode[property.name] = copyDefaultValue(property.defaultValue);\n    }\n  }\n}\n__name(assignMandatoryProperties, \"assignMandatoryProperties\");\nfunction copyDefaultValue(propertyType) {\n  if (Array.isArray(propertyType)) {\n    return [...propertyType.map(copyDefaultValue)];\n  } else {\n    return propertyType;\n  }\n}\n__name(copyDefaultValue, \"copyDefaultValue\");\nfunction copyAstNode(node, buildReference) {\n  const copy = { $type: node.$type };\n  for (const [name, value] of Object.entries(node)) {\n    if (!name.startsWith(\"$\")) {\n      if (isAstNode(value)) {\n        copy[name] = copyAstNode(value, buildReference);\n      } else if (isReference(value)) {\n        copy[name] = buildReference(copy, name, value.$refNode, value.$refText);\n      } else if (Array.isArray(value)) {\n        const copiedArray = [];\n        for (const element of value) {\n          if (isAstNode(element)) {\n            copiedArray.push(copyAstNode(element, buildReference));\n          } else if (isReference(element)) {\n            copiedArray.push(buildReference(copy, name, element.$refNode, element.$refText));\n          } else {\n            copiedArray.push(element);\n          }\n        }\n        copy[name] = copiedArray;\n      } else {\n        copy[name] = value;\n      }\n    }\n  }\n  linkContentToContainer(copy);\n  return copy;\n}\n__name(copyAstNode, \"copyAstNode\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/regexp-utils.js\nvar regexp_utils_exports = {};\n__export(regexp_utils_exports, {\n  NEWLINE_REGEXP: () => NEWLINE_REGEXP,\n  escapeRegExp: () => escapeRegExp,\n  getCaseInsensitivePattern: () => getCaseInsensitivePattern,\n  getTerminalParts: () => getTerminalParts,\n  isMultilineComment: () => isMultilineComment,\n  isWhitespace: () => isWhitespace,\n  partialMatches: () => partialMatches,\n  partialRegExp: () => partialRegExp,\n  whitespaceCharacters: () => whitespaceCharacters\n});\n\n// ../../node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/lib/src/utils.js\nfunction cc(char) {\n  return char.charCodeAt(0);\n}\n__name(cc, \"cc\");\nfunction insertToSet(item, set) {\n  if (Array.isArray(item)) {\n    item.forEach(function(subItem) {\n      set.push(subItem);\n    });\n  } else {\n    set.push(item);\n  }\n}\n__name(insertToSet, \"insertToSet\");\nfunction addFlag(flagObj, flagKey) {\n  if (flagObj[flagKey] === true) {\n    throw \"duplicate flag \" + flagKey;\n  }\n  const x = flagObj[flagKey];\n  flagObj[flagKey] = true;\n}\n__name(addFlag, \"addFlag\");\nfunction ASSERT_EXISTS(obj) {\n  if (obj === void 0) {\n    throw Error(\"Internal Error - Should never get here!\");\n  }\n  return true;\n}\n__name(ASSERT_EXISTS, \"ASSERT_EXISTS\");\nfunction ASSERT_NEVER_REACH_HERE() {\n  throw Error(\"Internal Error - Should never get here!\");\n}\n__name(ASSERT_NEVER_REACH_HERE, \"ASSERT_NEVER_REACH_HERE\");\nfunction isCharacter(obj) {\n  return obj[\"type\"] === \"Character\";\n}\n__name(isCharacter, \"isCharacter\");\n\n// ../../node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/lib/src/character-classes.js\nvar digitsCharCodes = [];\nfor (let i = cc(\"0\"); i <= cc(\"9\"); i++) {\n  digitsCharCodes.push(i);\n}\nvar wordCharCodes = [cc(\"_\")].concat(digitsCharCodes);\nfor (let i = cc(\"a\"); i <= cc(\"z\"); i++) {\n  wordCharCodes.push(i);\n}\nfor (let i = cc(\"A\"); i <= cc(\"Z\"); i++) {\n  wordCharCodes.push(i);\n}\nvar whitespaceCodes = [\n  cc(\" \"),\n  cc(\"\\f\"),\n  cc(\"\\n\"),\n  cc(\"\\r\"),\n  cc(\"\t\"),\n  cc(\"\\v\"),\n  cc(\"\t\"),\n  cc(\"\\xA0\"),\n  cc(\"\\u1680\"),\n  cc(\"\\u2000\"),\n  cc(\"\\u2001\"),\n  cc(\"\\u2002\"),\n  cc(\"\\u2003\"),\n  cc(\"\\u2004\"),\n  cc(\"\\u2005\"),\n  cc(\"\\u2006\"),\n  cc(\"\\u2007\"),\n  cc(\"\\u2008\"),\n  cc(\"\\u2009\"),\n  cc(\"\\u200A\"),\n  cc(\"\\u2028\"),\n  cc(\"\\u2029\"),\n  cc(\"\\u202F\"),\n  cc(\"\\u205F\"),\n  cc(\"\\u3000\"),\n  cc(\"\\uFEFF\")\n];\n\n// ../../node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/lib/src/regexp-parser.js\nvar hexDigitPattern = /[0-9a-fA-F]/;\nvar decimalPattern = /[0-9]/;\nvar decimalPatternNoZero = /[1-9]/;\nvar RegExpParser = class {\n  static {\n    __name(this, \"RegExpParser\");\n  }\n  constructor() {\n    this.idx = 0;\n    this.input = \"\";\n    this.groupIdx = 0;\n  }\n  saveState() {\n    return {\n      idx: this.idx,\n      input: this.input,\n      groupIdx: this.groupIdx\n    };\n  }\n  restoreState(newState2) {\n    this.idx = newState2.idx;\n    this.input = newState2.input;\n    this.groupIdx = newState2.groupIdx;\n  }\n  pattern(input) {\n    this.idx = 0;\n    this.input = input;\n    this.groupIdx = 0;\n    this.consumeChar(\"/\");\n    const value = this.disjunction();\n    this.consumeChar(\"/\");\n    const flags = {\n      type: \"Flags\",\n      loc: { begin: this.idx, end: input.length },\n      global: false,\n      ignoreCase: false,\n      multiLine: false,\n      unicode: false,\n      sticky: false\n    };\n    while (this.isRegExpFlag()) {\n      switch (this.popChar()) {\n        case \"g\":\n          addFlag(flags, \"global\");\n          break;\n        case \"i\":\n          addFlag(flags, \"ignoreCase\");\n          break;\n        case \"m\":\n          addFlag(flags, \"multiLine\");\n          break;\n        case \"u\":\n          addFlag(flags, \"unicode\");\n          break;\n        case \"y\":\n          addFlag(flags, \"sticky\");\n          break;\n      }\n    }\n    if (this.idx !== this.input.length) {\n      throw Error(\"Redundant input: \" + this.input.substring(this.idx));\n    }\n    return {\n      type: \"Pattern\",\n      flags,\n      value,\n      loc: this.loc(0)\n    };\n  }\n  disjunction() {\n    const alts = [];\n    const begin = this.idx;\n    alts.push(this.alternative());\n    while (this.peekChar() === \"|\") {\n      this.consumeChar(\"|\");\n      alts.push(this.alternative());\n    }\n    return { type: \"Disjunction\", value: alts, loc: this.loc(begin) };\n  }\n  alternative() {\n    const terms = [];\n    const begin = this.idx;\n    while (this.isTerm()) {\n      terms.push(this.term());\n    }\n    return { type: \"Alternative\", value: terms, loc: this.loc(begin) };\n  }\n  term() {\n    if (this.isAssertion()) {\n      return this.assertion();\n    } else {\n      return this.atom();\n    }\n  }\n  assertion() {\n    const begin = this.idx;\n    switch (this.popChar()) {\n      case \"^\":\n        return {\n          type: \"StartAnchor\",\n          loc: this.loc(begin)\n        };\n      case \"$\":\n        return { type: \"EndAnchor\", loc: this.loc(begin) };\n      // '\\b' or '\\B'\n      case \"\\\\\":\n        switch (this.popChar()) {\n          case \"b\":\n            return {\n              type: \"WordBoundary\",\n              loc: this.loc(begin)\n            };\n          case \"B\":\n            return {\n              type: \"NonWordBoundary\",\n              loc: this.loc(begin)\n            };\n        }\n        throw Error(\"Invalid Assertion Escape\");\n      // '(?=' or '(?!'\n      case \"(\":\n        this.consumeChar(\"?\");\n        let type;\n        switch (this.popChar()) {\n          case \"=\":\n            type = \"Lookahead\";\n            break;\n          case \"!\":\n            type = \"NegativeLookahead\";\n            break;\n        }\n        ASSERT_EXISTS(type);\n        const disjunction = this.disjunction();\n        this.consumeChar(\")\");\n        return {\n          type,\n          value: disjunction,\n          loc: this.loc(begin)\n        };\n    }\n    return ASSERT_NEVER_REACH_HERE();\n  }\n  quantifier(isBacktracking = false) {\n    let range = void 0;\n    const begin = this.idx;\n    switch (this.popChar()) {\n      case \"*\":\n        range = {\n          atLeast: 0,\n          atMost: Infinity\n        };\n        break;\n      case \"+\":\n        range = {\n          atLeast: 1,\n          atMost: Infinity\n        };\n        break;\n      case \"?\":\n        range = {\n          atLeast: 0,\n          atMost: 1\n        };\n        break;\n      case \"{\":\n        const atLeast = this.integerIncludingZero();\n        switch (this.popChar()) {\n          case \"}\":\n            range = {\n              atLeast,\n              atMost: atLeast\n            };\n            break;\n          case \",\":\n            let atMost;\n            if (this.isDigit()) {\n              atMost = this.integerIncludingZero();\n              range = {\n                atLeast,\n                atMost\n              };\n            } else {\n              range = {\n                atLeast,\n                atMost: Infinity\n              };\n            }\n            this.consumeChar(\"}\");\n            break;\n        }\n        if (isBacktracking === true && range === void 0) {\n          return void 0;\n        }\n        ASSERT_EXISTS(range);\n        break;\n    }\n    if (isBacktracking === true && range === void 0) {\n      return void 0;\n    }\n    if (ASSERT_EXISTS(range)) {\n      if (this.peekChar(0) === \"?\") {\n        this.consumeChar(\"?\");\n        range.greedy = false;\n      } else {\n        range.greedy = true;\n      }\n      range.type = \"Quantifier\";\n      range.loc = this.loc(begin);\n      return range;\n    }\n  }\n  atom() {\n    let atom2;\n    const begin = this.idx;\n    switch (this.peekChar()) {\n      case \".\":\n        atom2 = this.dotAll();\n        break;\n      case \"\\\\\":\n        atom2 = this.atomEscape();\n        break;\n      case \"[\":\n        atom2 = this.characterClass();\n        break;\n      case \"(\":\n        atom2 = this.group();\n        break;\n    }\n    if (atom2 === void 0 && this.isPatternCharacter()) {\n      atom2 = this.patternCharacter();\n    }\n    if (ASSERT_EXISTS(atom2)) {\n      atom2.loc = this.loc(begin);\n      if (this.isQuantifier()) {\n        atom2.quantifier = this.quantifier();\n      }\n      return atom2;\n    }\n    return ASSERT_NEVER_REACH_HERE();\n  }\n  dotAll() {\n    this.consumeChar(\".\");\n    return {\n      type: \"Set\",\n      complement: true,\n      value: [cc(\"\\n\"), cc(\"\\r\"), cc(\"\\u2028\"), cc(\"\\u2029\")]\n    };\n  }\n  atomEscape() {\n    this.consumeChar(\"\\\\\");\n    switch (this.peekChar()) {\n      case \"1\":\n      case \"2\":\n      case \"3\":\n      case \"4\":\n      case \"5\":\n      case \"6\":\n      case \"7\":\n      case \"8\":\n      case \"9\":\n        return this.decimalEscapeAtom();\n      case \"d\":\n      case \"D\":\n      case \"s\":\n      case \"S\":\n      case \"w\":\n      case \"W\":\n        return this.characterClassEscape();\n      case \"f\":\n      case \"n\":\n      case \"r\":\n      case \"t\":\n      case \"v\":\n        return this.controlEscapeAtom();\n      case \"c\":\n        return this.controlLetterEscapeAtom();\n      case \"0\":\n        return this.nulCharacterAtom();\n      case \"x\":\n        return this.hexEscapeSequenceAtom();\n      case \"u\":\n        return this.regExpUnicodeEscapeSequenceAtom();\n      default:\n        return this.identityEscapeAtom();\n    }\n  }\n  decimalEscapeAtom() {\n    const value = this.positiveInteger();\n    return { type: \"GroupBackReference\", value };\n  }\n  characterClassEscape() {\n    let set;\n    let complement = false;\n    switch (this.popChar()) {\n      case \"d\":\n        set = digitsCharCodes;\n        break;\n      case \"D\":\n        set = digitsCharCodes;\n        complement = true;\n        break;\n      case \"s\":\n        set = whitespaceCodes;\n        break;\n      case \"S\":\n        set = whitespaceCodes;\n        complement = true;\n        break;\n      case \"w\":\n        set = wordCharCodes;\n        break;\n      case \"W\":\n        set = wordCharCodes;\n        complement = true;\n        break;\n    }\n    if (ASSERT_EXISTS(set)) {\n      return { type: \"Set\", value: set, complement };\n    }\n    return ASSERT_NEVER_REACH_HERE();\n  }\n  controlEscapeAtom() {\n    let escapeCode;\n    switch (this.popChar()) {\n      case \"f\":\n        escapeCode = cc(\"\\f\");\n        break;\n      case \"n\":\n        escapeCode = cc(\"\\n\");\n        break;\n      case \"r\":\n        escapeCode = cc(\"\\r\");\n        break;\n      case \"t\":\n        escapeCode = cc(\"\t\");\n        break;\n      case \"v\":\n        escapeCode = cc(\"\\v\");\n        break;\n    }\n    if (ASSERT_EXISTS(escapeCode)) {\n      return { type: \"Character\", value: escapeCode };\n    }\n    return ASSERT_NEVER_REACH_HERE();\n  }\n  controlLetterEscapeAtom() {\n    this.consumeChar(\"c\");\n    const letter = this.popChar();\n    if (/[a-zA-Z]/.test(letter) === false) {\n      throw Error(\"Invalid \");\n    }\n    const letterCode = letter.toUpperCase().charCodeAt(0) - 64;\n    return { type: \"Character\", value: letterCode };\n  }\n  nulCharacterAtom() {\n    this.consumeChar(\"0\");\n    return { type: \"Character\", value: cc(\"\\0\") };\n  }\n  hexEscapeSequenceAtom() {\n    this.consumeChar(\"x\");\n    return this.parseHexDigits(2);\n  }\n  regExpUnicodeEscapeSequenceAtom() {\n    this.consumeChar(\"u\");\n    return this.parseHexDigits(4);\n  }\n  identityEscapeAtom() {\n    const escapedChar = this.popChar();\n    return { type: \"Character\", value: cc(escapedChar) };\n  }\n  classPatternCharacterAtom() {\n    switch (this.peekChar()) {\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n      // istanbul ignore next\n      case \"\\\\\":\n      // istanbul ignore next\n      case \"]\":\n        throw Error(\"TBD\");\n      default:\n        const nextChar = this.popChar();\n        return { type: \"Character\", value: cc(nextChar) };\n    }\n  }\n  characterClass() {\n    const set = [];\n    let complement = false;\n    this.consumeChar(\"[\");\n    if (this.peekChar(0) === \"^\") {\n      this.consumeChar(\"^\");\n      complement = true;\n    }\n    while (this.isClassAtom()) {\n      const from = this.classAtom();\n      const isFromSingleChar = from.type === \"Character\";\n      if (isCharacter(from) && this.isRangeDash()) {\n        this.consumeChar(\"-\");\n        const to = this.classAtom();\n        const isToSingleChar = to.type === \"Character\";\n        if (isCharacter(to)) {\n          if (to.value < from.value) {\n            throw Error(\"Range out of order in character class\");\n          }\n          set.push({ from: from.value, to: to.value });\n        } else {\n          insertToSet(from.value, set);\n          set.push(cc(\"-\"));\n          insertToSet(to.value, set);\n        }\n      } else {\n        insertToSet(from.value, set);\n      }\n    }\n    this.consumeChar(\"]\");\n    return { type: \"Set\", complement, value: set };\n  }\n  classAtom() {\n    switch (this.peekChar()) {\n      // istanbul ignore next\n      case \"]\":\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n        throw Error(\"TBD\");\n      case \"\\\\\":\n        return this.classEscape();\n      default:\n        return this.classPatternCharacterAtom();\n    }\n  }\n  classEscape() {\n    this.consumeChar(\"\\\\\");\n    switch (this.peekChar()) {\n      // Matches a backspace.\n      // (Not to be confused with \\b word boundary outside characterClass)\n      case \"b\":\n        this.consumeChar(\"b\");\n        return { type: \"Character\", value: cc(\"\\b\") };\n      case \"d\":\n      case \"D\":\n      case \"s\":\n      case \"S\":\n      case \"w\":\n      case \"W\":\n        return this.characterClassEscape();\n      case \"f\":\n      case \"n\":\n      case \"r\":\n      case \"t\":\n      case \"v\":\n        return this.controlEscapeAtom();\n      case \"c\":\n        return this.controlLetterEscapeAtom();\n      case \"0\":\n        return this.nulCharacterAtom();\n      case \"x\":\n        return this.hexEscapeSequenceAtom();\n      case \"u\":\n        return this.regExpUnicodeEscapeSequenceAtom();\n      default:\n        return this.identityEscapeAtom();\n    }\n  }\n  group() {\n    let capturing = true;\n    this.consumeChar(\"(\");\n    switch (this.peekChar(0)) {\n      case \"?\":\n        this.consumeChar(\"?\");\n        this.consumeChar(\":\");\n        capturing = false;\n        break;\n      default:\n        this.groupIdx++;\n        break;\n    }\n    const value = this.disjunction();\n    this.consumeChar(\")\");\n    const groupAst = {\n      type: \"Group\",\n      capturing,\n      value\n    };\n    if (capturing) {\n      groupAst[\"idx\"] = this.groupIdx;\n    }\n    return groupAst;\n  }\n  positiveInteger() {\n    let number = this.popChar();\n    if (decimalPatternNoZero.test(number) === false) {\n      throw Error(\"Expecting a positive integer\");\n    }\n    while (decimalPattern.test(this.peekChar(0))) {\n      number += this.popChar();\n    }\n    return parseInt(number, 10);\n  }\n  integerIncludingZero() {\n    let number = this.popChar();\n    if (decimalPattern.test(number) === false) {\n      throw Error(\"Expecting an integer\");\n    }\n    while (decimalPattern.test(this.peekChar(0))) {\n      number += this.popChar();\n    }\n    return parseInt(number, 10);\n  }\n  patternCharacter() {\n    const nextChar = this.popChar();\n    switch (nextChar) {\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n      // istanbul ignore next\n      case \"^\":\n      // istanbul ignore next\n      case \"$\":\n      // istanbul ignore next\n      case \"\\\\\":\n      // istanbul ignore next\n      case \".\":\n      // istanbul ignore next\n      case \"*\":\n      // istanbul ignore next\n      case \"+\":\n      // istanbul ignore next\n      case \"?\":\n      // istanbul ignore next\n      case \"(\":\n      // istanbul ignore next\n      case \")\":\n      // istanbul ignore next\n      case \"[\":\n      // istanbul ignore next\n      case \"|\":\n        throw Error(\"TBD\");\n      default:\n        return { type: \"Character\", value: cc(nextChar) };\n    }\n  }\n  isRegExpFlag() {\n    switch (this.peekChar(0)) {\n      case \"g\":\n      case \"i\":\n      case \"m\":\n      case \"u\":\n      case \"y\":\n        return true;\n      default:\n        return false;\n    }\n  }\n  isRangeDash() {\n    return this.peekChar() === \"-\" && this.isClassAtom(1);\n  }\n  isDigit() {\n    return decimalPattern.test(this.peekChar(0));\n  }\n  isClassAtom(howMuch = 0) {\n    switch (this.peekChar(howMuch)) {\n      case \"]\":\n      case \"\\n\":\n      case \"\\r\":\n      case \"\\u2028\":\n      case \"\\u2029\":\n        return false;\n      default:\n        return true;\n    }\n  }\n  isTerm() {\n    return this.isAtom() || this.isAssertion();\n  }\n  isAtom() {\n    if (this.isPatternCharacter()) {\n      return true;\n    }\n    switch (this.peekChar(0)) {\n      case \".\":\n      case \"\\\\\":\n      // atomEscape\n      case \"[\":\n      // characterClass\n      // TODO: isAtom must be called before isAssertion - disambiguate\n      case \"(\":\n        return true;\n      default:\n        return false;\n    }\n  }\n  isAssertion() {\n    switch (this.peekChar(0)) {\n      case \"^\":\n      case \"$\":\n        return true;\n      // '\\b' or '\\B'\n      case \"\\\\\":\n        switch (this.peekChar(1)) {\n          case \"b\":\n          case \"B\":\n            return true;\n          default:\n            return false;\n        }\n      // '(?=' or '(?!'\n      case \"(\":\n        return this.peekChar(1) === \"?\" && (this.peekChar(2) === \"=\" || this.peekChar(2) === \"!\");\n      default:\n        return false;\n    }\n  }\n  isQuantifier() {\n    const prevState = this.saveState();\n    try {\n      return this.quantifier(true) !== void 0;\n    } catch (e) {\n      return false;\n    } finally {\n      this.restoreState(prevState);\n    }\n  }\n  isPatternCharacter() {\n    switch (this.peekChar()) {\n      case \"^\":\n      case \"$\":\n      case \"\\\\\":\n      case \".\":\n      case \"*\":\n      case \"+\":\n      case \"?\":\n      case \"(\":\n      case \")\":\n      case \"[\":\n      case \"|\":\n      case \"/\":\n      case \"\\n\":\n      case \"\\r\":\n      case \"\\u2028\":\n      case \"\\u2029\":\n        return false;\n      default:\n        return true;\n    }\n  }\n  parseHexDigits(howMany) {\n    let hexString = \"\";\n    for (let i = 0; i < howMany; i++) {\n      const hexChar = this.popChar();\n      if (hexDigitPattern.test(hexChar) === false) {\n        throw Error(\"Expecting a HexDecimal digits\");\n      }\n      hexString += hexChar;\n    }\n    const charCode = parseInt(hexString, 16);\n    return { type: \"Character\", value: charCode };\n  }\n  peekChar(howMuch = 0) {\n    return this.input[this.idx + howMuch];\n  }\n  popChar() {\n    const nextChar = this.peekChar(0);\n    this.consumeChar(void 0);\n    return nextChar;\n  }\n  consumeChar(char) {\n    if (char !== void 0 && this.input[this.idx] !== char) {\n      throw Error(\"Expected: '\" + char + \"' but found: '\" + this.input[this.idx] + \"' at offset: \" + this.idx);\n    }\n    if (this.idx >= this.input.length) {\n      throw Error(\"Unexpected end of input\");\n    }\n    this.idx++;\n  }\n  loc(begin) {\n    return { begin, end: this.idx };\n  }\n};\n\n// ../../node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/lib/src/base-regexp-visitor.js\nvar BaseRegExpVisitor = class {\n  static {\n    __name(this, \"BaseRegExpVisitor\");\n  }\n  visitChildren(node) {\n    for (const key in node) {\n      const child = node[key];\n      if (node.hasOwnProperty(key)) {\n        if (child.type !== void 0) {\n          this.visit(child);\n        } else if (Array.isArray(child)) {\n          child.forEach((subChild) => {\n            this.visit(subChild);\n          }, this);\n        }\n      }\n    }\n  }\n  visit(node) {\n    switch (node.type) {\n      case \"Pattern\":\n        this.visitPattern(node);\n        break;\n      case \"Flags\":\n        this.visitFlags(node);\n        break;\n      case \"Disjunction\":\n        this.visitDisjunction(node);\n        break;\n      case \"Alternative\":\n        this.visitAlternative(node);\n        break;\n      case \"StartAnchor\":\n        this.visitStartAnchor(node);\n        break;\n      case \"EndAnchor\":\n        this.visitEndAnchor(node);\n        break;\n      case \"WordBoundary\":\n        this.visitWordBoundary(node);\n        break;\n      case \"NonWordBoundary\":\n        this.visitNonWordBoundary(node);\n        break;\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        break;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        break;\n      case \"Character\":\n        this.visitCharacter(node);\n        break;\n      case \"Set\":\n        this.visitSet(node);\n        break;\n      case \"Group\":\n        this.visitGroup(node);\n        break;\n      case \"GroupBackReference\":\n        this.visitGroupBackReference(node);\n        break;\n      case \"Quantifier\":\n        this.visitQuantifier(node);\n        break;\n    }\n    this.visitChildren(node);\n  }\n  visitPattern(node) {\n  }\n  visitFlags(node) {\n  }\n  visitDisjunction(node) {\n  }\n  visitAlternative(node) {\n  }\n  // Assertion\n  visitStartAnchor(node) {\n  }\n  visitEndAnchor(node) {\n  }\n  visitWordBoundary(node) {\n  }\n  visitNonWordBoundary(node) {\n  }\n  visitLookahead(node) {\n  }\n  visitNegativeLookahead(node) {\n  }\n  // atoms\n  visitCharacter(node) {\n  }\n  visitSet(node) {\n  }\n  visitGroup(node) {\n  }\n  visitGroupBackReference(node) {\n  }\n  visitQuantifier(node) {\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/regexp-utils.js\nvar NEWLINE_REGEXP = /\\r?\\n/gm;\nvar regexpParser = new RegExpParser();\nvar TerminalRegExpVisitor = class extends BaseRegExpVisitor {\n  static {\n    __name(this, \"TerminalRegExpVisitor\");\n  }\n  constructor() {\n    super(...arguments);\n    this.isStarting = true;\n    this.endRegexpStack = [];\n    this.multiline = false;\n  }\n  get endRegex() {\n    return this.endRegexpStack.join(\"\");\n  }\n  reset(regex) {\n    this.multiline = false;\n    this.regex = regex;\n    this.startRegexp = \"\";\n    this.isStarting = true;\n    this.endRegexpStack = [];\n  }\n  visitGroup(node) {\n    if (node.quantifier) {\n      this.isStarting = false;\n      this.endRegexpStack = [];\n    }\n  }\n  visitCharacter(node) {\n    const char = String.fromCharCode(node.value);\n    if (!this.multiline && char === \"\\n\") {\n      this.multiline = true;\n    }\n    if (node.quantifier) {\n      this.isStarting = false;\n      this.endRegexpStack = [];\n    } else {\n      const escapedChar = escapeRegExp(char);\n      this.endRegexpStack.push(escapedChar);\n      if (this.isStarting) {\n        this.startRegexp += escapedChar;\n      }\n    }\n  }\n  visitSet(node) {\n    if (!this.multiline) {\n      const set = this.regex.substring(node.loc.begin, node.loc.end);\n      const regex = new RegExp(set);\n      this.multiline = Boolean(\"\\n\".match(regex));\n    }\n    if (node.quantifier) {\n      this.isStarting = false;\n      this.endRegexpStack = [];\n    } else {\n      const set = this.regex.substring(node.loc.begin, node.loc.end);\n      this.endRegexpStack.push(set);\n      if (this.isStarting) {\n        this.startRegexp += set;\n      }\n    }\n  }\n  visitChildren(node) {\n    if (node.type === \"Group\") {\n      const group = node;\n      if (group.quantifier) {\n        return;\n      }\n    }\n    super.visitChildren(node);\n  }\n};\nvar visitor = new TerminalRegExpVisitor();\nfunction getTerminalParts(regexp) {\n  try {\n    if (typeof regexp !== \"string\") {\n      regexp = regexp.source;\n    }\n    regexp = `/${regexp}/`;\n    const pattern = regexpParser.pattern(regexp);\n    const parts = [];\n    for (const alternative of pattern.value.value) {\n      visitor.reset(regexp);\n      visitor.visit(alternative);\n      parts.push({\n        start: visitor.startRegexp,\n        end: visitor.endRegex\n      });\n    }\n    return parts;\n  } catch (_a) {\n    return [];\n  }\n}\n__name(getTerminalParts, \"getTerminalParts\");\nfunction isMultilineComment(regexp) {\n  try {\n    if (typeof regexp === \"string\") {\n      regexp = new RegExp(regexp);\n    }\n    regexp = regexp.toString();\n    visitor.reset(regexp);\n    visitor.visit(regexpParser.pattern(regexp));\n    return visitor.multiline;\n  } catch (_a) {\n    return false;\n  }\n}\n__name(isMultilineComment, \"isMultilineComment\");\nvar whitespaceCharacters = \"\\f\\n\\r\t\\v \\xA0\\u1680\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u2028\\u2029\\u202F\\u205F\\u3000\\uFEFF\".split(\"\");\nfunction isWhitespace(value) {\n  const regexp = typeof value === \"string\" ? new RegExp(value) : value;\n  return whitespaceCharacters.some((ws) => regexp.test(ws));\n}\n__name(isWhitespace, \"isWhitespace\");\nfunction escapeRegExp(value) {\n  return value.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\");\n}\n__name(escapeRegExp, \"escapeRegExp\");\nfunction getCaseInsensitivePattern(keyword) {\n  return Array.prototype.map.call(keyword, (letter) => /\\w/.test(letter) ? `[${letter.toLowerCase()}${letter.toUpperCase()}]` : escapeRegExp(letter)).join(\"\");\n}\n__name(getCaseInsensitivePattern, \"getCaseInsensitivePattern\");\nfunction partialMatches(regex, input) {\n  const partial = partialRegExp(regex);\n  const match = input.match(partial);\n  return !!match && match[0].length > 0;\n}\n__name(partialMatches, \"partialMatches\");\nfunction partialRegExp(regex) {\n  if (typeof regex === \"string\") {\n    regex = new RegExp(regex);\n  }\n  const re = regex, source = regex.source;\n  let i = 0;\n  function process2() {\n    let result = \"\", tmp;\n    function appendRaw(nbChars) {\n      result += source.substr(i, nbChars);\n      i += nbChars;\n    }\n    __name(appendRaw, \"appendRaw\");\n    function appendOptional(nbChars) {\n      result += \"(?:\" + source.substr(i, nbChars) + \"|$)\";\n      i += nbChars;\n    }\n    __name(appendOptional, \"appendOptional\");\n    while (i < source.length) {\n      switch (source[i]) {\n        case \"\\\\\":\n          switch (source[i + 1]) {\n            case \"c\":\n              appendOptional(3);\n              break;\n            case \"x\":\n              appendOptional(4);\n              break;\n            case \"u\":\n              if (re.unicode) {\n                if (source[i + 2] === \"{\") {\n                  appendOptional(source.indexOf(\"}\", i) - i + 1);\n                } else {\n                  appendOptional(6);\n                }\n              } else {\n                appendOptional(2);\n              }\n              break;\n            case \"p\":\n            case \"P\":\n              if (re.unicode) {\n                appendOptional(source.indexOf(\"}\", i) - i + 1);\n              } else {\n                appendOptional(2);\n              }\n              break;\n            case \"k\":\n              appendOptional(source.indexOf(\">\", i) - i + 1);\n              break;\n            default:\n              appendOptional(2);\n              break;\n          }\n          break;\n        case \"[\":\n          tmp = /\\[(?:\\\\.|.)*?\\]/g;\n          tmp.lastIndex = i;\n          tmp = tmp.exec(source) || [];\n          appendOptional(tmp[0].length);\n          break;\n        case \"|\":\n        case \"^\":\n        case \"$\":\n        case \"*\":\n        case \"+\":\n        case \"?\":\n          appendRaw(1);\n          break;\n        case \"{\":\n          tmp = /\\{\\d+,?\\d*\\}/g;\n          tmp.lastIndex = i;\n          tmp = tmp.exec(source);\n          if (tmp) {\n            appendRaw(tmp[0].length);\n          } else {\n            appendOptional(1);\n          }\n          break;\n        case \"(\":\n          if (source[i + 1] === \"?\") {\n            switch (source[i + 2]) {\n              case \":\":\n                result += \"(?:\";\n                i += 3;\n                result += process2() + \"|$)\";\n                break;\n              case \"=\":\n                result += \"(?=\";\n                i += 3;\n                result += process2() + \")\";\n                break;\n              case \"!\":\n                tmp = i;\n                i += 3;\n                process2();\n                result += source.substr(tmp, i - tmp);\n                break;\n              case \"<\":\n                switch (source[i + 3]) {\n                  case \"=\":\n                  case \"!\":\n                    tmp = i;\n                    i += 4;\n                    process2();\n                    result += source.substr(tmp, i - tmp);\n                    break;\n                  default:\n                    appendRaw(source.indexOf(\">\", i) - i + 1);\n                    result += process2() + \"|$)\";\n                    break;\n                }\n                break;\n            }\n          } else {\n            appendRaw(1);\n            result += process2() + \"|$)\";\n          }\n          break;\n        case \")\":\n          ++i;\n          return result;\n        default:\n          appendOptional(1);\n          break;\n      }\n    }\n    return result;\n  }\n  __name(process2, \"process\");\n  return new RegExp(process2(), regex.flags);\n}\n__name(partialRegExp, \"partialRegExp\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/grammar-utils.js\nfunction getEntryRule(grammar) {\n  return grammar.rules.find((e) => isParserRule(e) && e.entry);\n}\n__name(getEntryRule, \"getEntryRule\");\nfunction getHiddenRules(grammar) {\n  return grammar.rules.filter((e) => isTerminalRule(e) && e.hidden);\n}\n__name(getHiddenRules, \"getHiddenRules\");\nfunction getAllReachableRules(grammar, allTerminals) {\n  const ruleNames = /* @__PURE__ */ new Set();\n  const entryRule = getEntryRule(grammar);\n  if (!entryRule) {\n    return new Set(grammar.rules);\n  }\n  const topMostRules = [entryRule].concat(getHiddenRules(grammar));\n  for (const rule of topMostRules) {\n    ruleDfs(rule, ruleNames, allTerminals);\n  }\n  const rules = /* @__PURE__ */ new Set();\n  for (const rule of grammar.rules) {\n    if (ruleNames.has(rule.name) || isTerminalRule(rule) && rule.hidden) {\n      rules.add(rule);\n    }\n  }\n  return rules;\n}\n__name(getAllReachableRules, \"getAllReachableRules\");\nfunction ruleDfs(rule, visitedSet, allTerminals) {\n  visitedSet.add(rule.name);\n  streamAllContents(rule).forEach((node) => {\n    if (isRuleCall(node) || allTerminals && isTerminalRuleCall(node)) {\n      const refRule = node.rule.ref;\n      if (refRule && !visitedSet.has(refRule.name)) {\n        ruleDfs(refRule, visitedSet, allTerminals);\n      }\n    }\n  });\n}\n__name(ruleDfs, \"ruleDfs\");\nfunction getCrossReferenceTerminal(crossRef) {\n  if (crossRef.terminal) {\n    return crossRef.terminal;\n  } else if (crossRef.type.ref) {\n    const nameAssigment = findNameAssignment(crossRef.type.ref);\n    return nameAssigment === null || nameAssigment === void 0 ? void 0 : nameAssigment.terminal;\n  }\n  return void 0;\n}\n__name(getCrossReferenceTerminal, \"getCrossReferenceTerminal\");\nfunction isCommentTerminal(terminalRule) {\n  return terminalRule.hidden && !isWhitespace(terminalRegex(terminalRule));\n}\n__name(isCommentTerminal, \"isCommentTerminal\");\nfunction findNodesForProperty(node, property) {\n  if (!node || !property) {\n    return [];\n  }\n  return findNodesForPropertyInternal(node, property, node.astNode, true);\n}\n__name(findNodesForProperty, \"findNodesForProperty\");\nfunction findNodeForProperty(node, property, index) {\n  if (!node || !property) {\n    return void 0;\n  }\n  const nodes = findNodesForPropertyInternal(node, property, node.astNode, true);\n  if (nodes.length === 0) {\n    return void 0;\n  }\n  if (index !== void 0) {\n    index = Math.max(0, Math.min(index, nodes.length - 1));\n  } else {\n    index = 0;\n  }\n  return nodes[index];\n}\n__name(findNodeForProperty, \"findNodeForProperty\");\nfunction findNodesForPropertyInternal(node, property, element, first2) {\n  if (!first2) {\n    const nodeFeature = getContainerOfType(node.grammarSource, isAssignment);\n    if (nodeFeature && nodeFeature.feature === property) {\n      return [node];\n    }\n  }\n  if (isCompositeCstNode(node) && node.astNode === element) {\n    return node.content.flatMap((e) => findNodesForPropertyInternal(e, property, element, false));\n  }\n  return [];\n}\n__name(findNodesForPropertyInternal, \"findNodesForPropertyInternal\");\nfunction findNodesForKeyword(node, keyword) {\n  if (!node) {\n    return [];\n  }\n  return findNodesForKeywordInternal(node, keyword, node === null || node === void 0 ? void 0 : node.astNode);\n}\n__name(findNodesForKeyword, \"findNodesForKeyword\");\nfunction findNodeForKeyword(node, keyword, index) {\n  if (!node) {\n    return void 0;\n  }\n  const nodes = findNodesForKeywordInternal(node, keyword, node === null || node === void 0 ? void 0 : node.astNode);\n  if (nodes.length === 0) {\n    return void 0;\n  }\n  if (index !== void 0) {\n    index = Math.max(0, Math.min(index, nodes.length - 1));\n  } else {\n    index = 0;\n  }\n  return nodes[index];\n}\n__name(findNodeForKeyword, \"findNodeForKeyword\");\nfunction findNodesForKeywordInternal(node, keyword, element) {\n  if (node.astNode !== element) {\n    return [];\n  }\n  if (isKeyword(node.grammarSource) && node.grammarSource.value === keyword) {\n    return [node];\n  }\n  const treeIterator = streamCst(node).iterator();\n  let result;\n  const keywordNodes = [];\n  do {\n    result = treeIterator.next();\n    if (!result.done) {\n      const childNode = result.value;\n      if (childNode.astNode === element) {\n        if (isKeyword(childNode.grammarSource) && childNode.grammarSource.value === keyword) {\n          keywordNodes.push(childNode);\n        }\n      } else {\n        treeIterator.prune();\n      }\n    }\n  } while (!result.done);\n  return keywordNodes;\n}\n__name(findNodesForKeywordInternal, \"findNodesForKeywordInternal\");\nfunction findAssignment(cstNode) {\n  var _a;\n  const astNode = cstNode.astNode;\n  while (astNode === ((_a = cstNode.container) === null || _a === void 0 ? void 0 : _a.astNode)) {\n    const assignment = getContainerOfType(cstNode.grammarSource, isAssignment);\n    if (assignment) {\n      return assignment;\n    }\n    cstNode = cstNode.container;\n  }\n  return void 0;\n}\n__name(findAssignment, \"findAssignment\");\nfunction findNameAssignment(type) {\n  let startNode = type;\n  if (isInferredType(startNode)) {\n    if (isAction(startNode.$container)) {\n      startNode = startNode.$container.$container;\n    } else if (isParserRule(startNode.$container)) {\n      startNode = startNode.$container;\n    } else {\n      assertUnreachable(startNode.$container);\n    }\n  }\n  return findNameAssignmentInternal(type, startNode, /* @__PURE__ */ new Map());\n}\n__name(findNameAssignment, \"findNameAssignment\");\nfunction findNameAssignmentInternal(type, startNode, cache) {\n  var _a;\n  function go(node, refType) {\n    let childAssignment = void 0;\n    const parentAssignment = getContainerOfType(node, isAssignment);\n    if (!parentAssignment) {\n      childAssignment = findNameAssignmentInternal(refType, refType, cache);\n    }\n    cache.set(type, childAssignment);\n    return childAssignment;\n  }\n  __name(go, \"go\");\n  if (cache.has(type)) {\n    return cache.get(type);\n  }\n  cache.set(type, void 0);\n  for (const node of streamAllContents(startNode)) {\n    if (isAssignment(node) && node.feature.toLowerCase() === \"name\") {\n      cache.set(type, node);\n      return node;\n    } else if (isRuleCall(node) && isParserRule(node.rule.ref)) {\n      return go(node, node.rule.ref);\n    } else if (isSimpleType(node) && ((_a = node.typeRef) === null || _a === void 0 ? void 0 : _a.ref)) {\n      return go(node, node.typeRef.ref);\n    }\n  }\n  return void 0;\n}\n__name(findNameAssignmentInternal, \"findNameAssignmentInternal\");\nfunction getActionAtElement(element) {\n  const parent = element.$container;\n  if (isGroup(parent)) {\n    const elements = parent.elements;\n    const index = elements.indexOf(element);\n    for (let i = index - 1; i >= 0; i--) {\n      const item = elements[i];\n      if (isAction(item)) {\n        return item;\n      } else {\n        const action = streamAllContents(elements[i]).find(isAction);\n        if (action) {\n          return action;\n        }\n      }\n    }\n  }\n  if (isAbstractElement(parent)) {\n    return getActionAtElement(parent);\n  } else {\n    return void 0;\n  }\n}\n__name(getActionAtElement, \"getActionAtElement\");\nfunction isOptionalCardinality(cardinality, element) {\n  return cardinality === \"?\" || cardinality === \"*\" || isGroup(element) && Boolean(element.guardCondition);\n}\n__name(isOptionalCardinality, \"isOptionalCardinality\");\nfunction isArrayCardinality(cardinality) {\n  return cardinality === \"*\" || cardinality === \"+\";\n}\n__name(isArrayCardinality, \"isArrayCardinality\");\nfunction isArrayOperator(operator) {\n  return operator === \"+=\";\n}\n__name(isArrayOperator, \"isArrayOperator\");\nfunction isDataTypeRule(rule) {\n  return isDataTypeRuleInternal(rule, /* @__PURE__ */ new Set());\n}\n__name(isDataTypeRule, \"isDataTypeRule\");\nfunction isDataTypeRuleInternal(rule, visited) {\n  if (visited.has(rule)) {\n    return true;\n  } else {\n    visited.add(rule);\n  }\n  for (const node of streamAllContents(rule)) {\n    if (isRuleCall(node)) {\n      if (!node.rule.ref) {\n        return false;\n      }\n      if (isParserRule(node.rule.ref) && !isDataTypeRuleInternal(node.rule.ref, visited)) {\n        return false;\n      }\n    } else if (isAssignment(node)) {\n      return false;\n    } else if (isAction(node)) {\n      return false;\n    }\n  }\n  return Boolean(rule.definition);\n}\n__name(isDataTypeRuleInternal, \"isDataTypeRuleInternal\");\nfunction isDataType(type) {\n  return isDataTypeInternal(type.type, /* @__PURE__ */ new Set());\n}\n__name(isDataType, \"isDataType\");\nfunction isDataTypeInternal(type, visited) {\n  if (visited.has(type)) {\n    return true;\n  } else {\n    visited.add(type);\n  }\n  if (isArrayType(type)) {\n    return false;\n  } else if (isReferenceType(type)) {\n    return false;\n  } else if (isUnionType(type)) {\n    return type.types.every((e) => isDataTypeInternal(e, visited));\n  } else if (isSimpleType(type)) {\n    if (type.primitiveType !== void 0) {\n      return true;\n    } else if (type.stringType !== void 0) {\n      return true;\n    } else if (type.typeRef !== void 0) {\n      const ref = type.typeRef.ref;\n      if (isType(ref)) {\n        return isDataTypeInternal(ref.type, visited);\n      } else {\n        return false;\n      }\n    } else {\n      return false;\n    }\n  } else {\n    return false;\n  }\n}\n__name(isDataTypeInternal, \"isDataTypeInternal\");\nfunction getExplicitRuleType(rule) {\n  if (rule.inferredType) {\n    return rule.inferredType.name;\n  } else if (rule.dataType) {\n    return rule.dataType;\n  } else if (rule.returnType) {\n    const refType = rule.returnType.ref;\n    if (refType) {\n      if (isParserRule(refType)) {\n        return refType.name;\n      } else if (isInterface(refType) || isType(refType)) {\n        return refType.name;\n      }\n    }\n  }\n  return void 0;\n}\n__name(getExplicitRuleType, \"getExplicitRuleType\");\nfunction getTypeName(type) {\n  var _a;\n  if (isParserRule(type)) {\n    return isDataTypeRule(type) ? type.name : (_a = getExplicitRuleType(type)) !== null && _a !== void 0 ? _a : type.name;\n  } else if (isInterface(type) || isType(type) || isReturnType(type)) {\n    return type.name;\n  } else if (isAction(type)) {\n    const actionType = getActionType(type);\n    if (actionType) {\n      return actionType;\n    }\n  } else if (isInferredType(type)) {\n    return type.name;\n  }\n  throw new Error(\"Cannot get name of Unknown Type\");\n}\n__name(getTypeName, \"getTypeName\");\nfunction getActionType(action) {\n  var _a;\n  if (action.inferredType) {\n    return action.inferredType.name;\n  } else if ((_a = action.type) === null || _a === void 0 ? void 0 : _a.ref) {\n    return getTypeName(action.type.ref);\n  }\n  return void 0;\n}\n__name(getActionType, \"getActionType\");\nfunction getRuleTypeName(rule) {\n  var _a, _b, _c;\n  if (isTerminalRule(rule)) {\n    return (_b = (_a = rule.type) === null || _a === void 0 ? void 0 : _a.name) !== null && _b !== void 0 ? _b : \"string\";\n  } else {\n    return isDataTypeRule(rule) ? rule.name : (_c = getExplicitRuleType(rule)) !== null && _c !== void 0 ? _c : rule.name;\n  }\n}\n__name(getRuleTypeName, \"getRuleTypeName\");\nfunction getRuleType(rule) {\n  var _a, _b, _c;\n  if (isTerminalRule(rule)) {\n    return (_b = (_a = rule.type) === null || _a === void 0 ? void 0 : _a.name) !== null && _b !== void 0 ? _b : \"string\";\n  } else {\n    return (_c = getExplicitRuleType(rule)) !== null && _c !== void 0 ? _c : rule.name;\n  }\n}\n__name(getRuleType, \"getRuleType\");\nfunction terminalRegex(terminalRule) {\n  const flags = {\n    s: false,\n    i: false,\n    u: false\n  };\n  const source = abstractElementToRegex(terminalRule.definition, flags);\n  const flagText = Object.entries(flags).filter(([, value]) => value).map(([name]) => name).join(\"\");\n  return new RegExp(source, flagText);\n}\n__name(terminalRegex, \"terminalRegex\");\nvar WILDCARD = /[\\s\\S]/.source;\nfunction abstractElementToRegex(element, flags) {\n  if (isTerminalAlternatives(element)) {\n    return terminalAlternativesToRegex(element);\n  } else if (isTerminalGroup(element)) {\n    return terminalGroupToRegex(element);\n  } else if (isCharacterRange(element)) {\n    return characterRangeToRegex(element);\n  } else if (isTerminalRuleCall(element)) {\n    const rule = element.rule.ref;\n    if (!rule) {\n      throw new Error(\"Missing rule reference.\");\n    }\n    return withCardinality(abstractElementToRegex(rule.definition), {\n      cardinality: element.cardinality,\n      lookahead: element.lookahead\n    });\n  } else if (isNegatedToken(element)) {\n    return negateTokenToRegex(element);\n  } else if (isUntilToken(element)) {\n    return untilTokenToRegex(element);\n  } else if (isRegexToken(element)) {\n    const lastSlash = element.regex.lastIndexOf(\"/\");\n    const source = element.regex.substring(1, lastSlash);\n    const regexFlags = element.regex.substring(lastSlash + 1);\n    if (flags) {\n      flags.i = regexFlags.includes(\"i\");\n      flags.s = regexFlags.includes(\"s\");\n      flags.u = regexFlags.includes(\"u\");\n    }\n    return withCardinality(source, {\n      cardinality: element.cardinality,\n      lookahead: element.lookahead,\n      wrap: false\n    });\n  } else if (isWildcard(element)) {\n    return withCardinality(WILDCARD, {\n      cardinality: element.cardinality,\n      lookahead: element.lookahead\n    });\n  } else {\n    throw new Error(`Invalid terminal element: ${element === null || element === void 0 ? void 0 : element.$type}`);\n  }\n}\n__name(abstractElementToRegex, \"abstractElementToRegex\");\nfunction terminalAlternativesToRegex(alternatives) {\n  return withCardinality(alternatives.elements.map((e) => abstractElementToRegex(e)).join(\"|\"), {\n    cardinality: alternatives.cardinality,\n    lookahead: alternatives.lookahead\n  });\n}\n__name(terminalAlternativesToRegex, \"terminalAlternativesToRegex\");\nfunction terminalGroupToRegex(group) {\n  return withCardinality(group.elements.map((e) => abstractElementToRegex(e)).join(\"\"), {\n    cardinality: group.cardinality,\n    lookahead: group.lookahead\n  });\n}\n__name(terminalGroupToRegex, \"terminalGroupToRegex\");\nfunction untilTokenToRegex(until) {\n  return withCardinality(`${WILDCARD}*?${abstractElementToRegex(until.terminal)}`, {\n    cardinality: until.cardinality,\n    lookahead: until.lookahead\n  });\n}\n__name(untilTokenToRegex, \"untilTokenToRegex\");\nfunction negateTokenToRegex(negate) {\n  return withCardinality(`(?!${abstractElementToRegex(negate.terminal)})${WILDCARD}*?`, {\n    cardinality: negate.cardinality,\n    lookahead: negate.lookahead\n  });\n}\n__name(negateTokenToRegex, \"negateTokenToRegex\");\nfunction characterRangeToRegex(range) {\n  if (range.right) {\n    return withCardinality(`[${keywordToRegex(range.left)}-${keywordToRegex(range.right)}]`, {\n      cardinality: range.cardinality,\n      lookahead: range.lookahead,\n      wrap: false\n    });\n  }\n  return withCardinality(keywordToRegex(range.left), {\n    cardinality: range.cardinality,\n    lookahead: range.lookahead,\n    wrap: false\n  });\n}\n__name(characterRangeToRegex, \"characterRangeToRegex\");\nfunction keywordToRegex(keyword) {\n  return escapeRegExp(keyword.value);\n}\n__name(keywordToRegex, \"keywordToRegex\");\nfunction withCardinality(regex, options) {\n  var _a;\n  if (options.wrap !== false || options.lookahead) {\n    regex = `(${(_a = options.lookahead) !== null && _a !== void 0 ? _a : \"\"}${regex})`;\n  }\n  if (options.cardinality) {\n    return `${regex}${options.cardinality}`;\n  }\n  return regex;\n}\n__name(withCardinality, \"withCardinality\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/languages/grammar-config.js\nfunction createGrammarConfig(services) {\n  const rules = [];\n  const grammar = services.Grammar;\n  for (const rule of grammar.rules) {\n    if (isTerminalRule(rule) && isCommentTerminal(rule) && isMultilineComment(terminalRegex(rule))) {\n      rules.push(rule.name);\n    }\n  }\n  return {\n    multilineCommentRules: rules,\n    nameRegexp: DefaultNameRegexp\n  };\n}\n__name(createGrammarConfig, \"createGrammarConfig\");\n\n// ../../node_modules/.pnpm/@chevrotain+utils@11.0.3/node_modules/@chevrotain/utils/lib/src/print.js\nfunction PRINT_ERROR(msg) {\n  if (console && console.error) {\n    console.error(`Error: ${msg}`);\n  }\n}\n__name(PRINT_ERROR, \"PRINT_ERROR\");\nfunction PRINT_WARNING(msg) {\n  if (console && console.warn) {\n    console.warn(`Warning: ${msg}`);\n  }\n}\n__name(PRINT_WARNING, \"PRINT_WARNING\");\n\n// ../../node_modules/.pnpm/@chevrotain+utils@11.0.3/node_modules/@chevrotain/utils/lib/src/timer.js\nfunction timer(func) {\n  const start = (/* @__PURE__ */ new Date()).getTime();\n  const val = func();\n  const end = (/* @__PURE__ */ new Date()).getTime();\n  const total = end - start;\n  return { time: total, value: val };\n}\n__name(timer, \"timer\");\n\n// ../../node_modules/.pnpm/@chevrotain+utils@11.0.3/node_modules/@chevrotain/utils/lib/src/to-fast-properties.js\nfunction toFastProperties(toBecomeFast) {\n  function FakeConstructor() {\n  }\n  __name(FakeConstructor, \"FakeConstructor\");\n  FakeConstructor.prototype = toBecomeFast;\n  const fakeInstance = new FakeConstructor();\n  function fakeAccess() {\n    return typeof fakeInstance.bar;\n  }\n  __name(fakeAccess, \"fakeAccess\");\n  fakeAccess();\n  fakeAccess();\n  if (1)\n    return toBecomeFast;\n  (0, eval)(toBecomeFast);\n}\n__name(toFastProperties, \"toFastProperties\");\n\n// ../../node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/lib/src/model.js\nfunction tokenLabel(tokType) {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\n__name(tokenLabel, \"tokenLabel\");\nfunction hasTokenLabel(obj) {\n  return isString_default(obj.LABEL) && obj.LABEL !== \"\";\n}\n__name(hasTokenLabel, \"hasTokenLabel\");\nvar AbstractProduction = class {\n  static {\n    __name(this, \"AbstractProduction\");\n  }\n  get definition() {\n    return this._definition;\n  }\n  set definition(value) {\n    this._definition = value;\n  }\n  constructor(_definition) {\n    this._definition = _definition;\n  }\n  accept(visitor2) {\n    visitor2.visit(this);\n    forEach_default(this.definition, (prod) => {\n      prod.accept(visitor2);\n    });\n  }\n};\nvar NonTerminal = class extends AbstractProduction {\n  static {\n    __name(this, \"NonTerminal\");\n  }\n  constructor(options) {\n    super([]);\n    this.idx = 1;\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n  set definition(definition) {\n  }\n  get definition() {\n    if (this.referencedRule !== void 0) {\n      return this.referencedRule.definition;\n    }\n    return [];\n  }\n  accept(visitor2) {\n    visitor2.visit(this);\n  }\n};\nvar Rule = class extends AbstractProduction {\n  static {\n    __name(this, \"Rule\");\n  }\n  constructor(options) {\n    super(options.definition);\n    this.orgText = \"\";\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n};\nvar Alternative = class extends AbstractProduction {\n  static {\n    __name(this, \"Alternative\");\n  }\n  constructor(options) {\n    super(options.definition);\n    this.ignoreAmbiguities = false;\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n};\nvar Option = class extends AbstractProduction {\n  static {\n    __name(this, \"Option\");\n  }\n  constructor(options) {\n    super(options.definition);\n    this.idx = 1;\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n};\nvar RepetitionMandatory = class extends AbstractProduction {\n  static {\n    __name(this, \"RepetitionMandatory\");\n  }\n  constructor(options) {\n    super(options.definition);\n    this.idx = 1;\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n};\nvar RepetitionMandatoryWithSeparator = class extends AbstractProduction {\n  static {\n    __name(this, \"RepetitionMandatoryWithSeparator\");\n  }\n  constructor(options) {\n    super(options.definition);\n    this.idx = 1;\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n};\nvar Repetition = class extends AbstractProduction {\n  static {\n    __name(this, \"Repetition\");\n  }\n  constructor(options) {\n    super(options.definition);\n    this.idx = 1;\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n};\nvar RepetitionWithSeparator = class extends AbstractProduction {\n  static {\n    __name(this, \"RepetitionWithSeparator\");\n  }\n  constructor(options) {\n    super(options.definition);\n    this.idx = 1;\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n};\nvar Alternation = class extends AbstractProduction {\n  static {\n    __name(this, \"Alternation\");\n  }\n  get definition() {\n    return this._definition;\n  }\n  set definition(value) {\n    this._definition = value;\n  }\n  constructor(options) {\n    super(options.definition);\n    this.idx = 1;\n    this.ignoreAmbiguities = false;\n    this.hasPredicates = false;\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n};\nvar Terminal = class {\n  static {\n    __name(this, \"Terminal\");\n  }\n  constructor(options) {\n    this.idx = 1;\n    assign_default(this, pickBy_default(options, (v) => v !== void 0));\n  }\n  accept(visitor2) {\n    visitor2.visit(this);\n  }\n};\nfunction serializeGrammar(topRules) {\n  return map_default(topRules, serializeProduction);\n}\n__name(serializeGrammar, \"serializeGrammar\");\nfunction serializeProduction(node) {\n  function convertDefinition(definition) {\n    return map_default(definition, serializeProduction);\n  }\n  __name(convertDefinition, \"convertDefinition\");\n  if (node instanceof NonTerminal) {\n    const serializedNonTerminal = {\n      type: \"NonTerminal\",\n      name: node.nonTerminalName,\n      idx: node.idx\n    };\n    if (isString_default(node.label)) {\n      serializedNonTerminal.label = node.label;\n    }\n    return serializedNonTerminal;\n  } else if (node instanceof Alternative) {\n    return {\n      type: \"Alternative\",\n      definition: convertDefinition(node.definition)\n    };\n  } else if (node instanceof Option) {\n    return {\n      type: \"Option\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition)\n    };\n  } else if (node instanceof RepetitionMandatory) {\n    return {\n      type: \"RepetitionMandatory\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition)\n    };\n  } else if (node instanceof RepetitionMandatoryWithSeparator) {\n    return {\n      type: \"RepetitionMandatoryWithSeparator\",\n      idx: node.idx,\n      separator: serializeProduction(new Terminal({ terminalType: node.separator })),\n      definition: convertDefinition(node.definition)\n    };\n  } else if (node instanceof RepetitionWithSeparator) {\n    return {\n      type: \"RepetitionWithSeparator\",\n      idx: node.idx,\n      separator: serializeProduction(new Terminal({ terminalType: node.separator })),\n      definition: convertDefinition(node.definition)\n    };\n  } else if (node instanceof Repetition) {\n    return {\n      type: \"Repetition\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition)\n    };\n  } else if (node instanceof Alternation) {\n    return {\n      type: \"Alternation\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition)\n    };\n  } else if (node instanceof Terminal) {\n    const serializedTerminal = {\n      type: \"Terminal\",\n      name: node.terminalType.name,\n      label: tokenLabel(node.terminalType),\n      idx: node.idx\n    };\n    if (isString_default(node.label)) {\n      serializedTerminal.terminalLabel = node.label;\n    }\n    const pattern = node.terminalType.PATTERN;\n    if (node.terminalType.PATTERN) {\n      serializedTerminal.pattern = isRegExp_default(pattern) ? pattern.source : pattern;\n    }\n    return serializedTerminal;\n  } else if (node instanceof Rule) {\n    return {\n      type: \"Rule\",\n      name: node.name,\n      orgText: node.orgText,\n      definition: convertDefinition(node.definition)\n    };\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n__name(serializeProduction, \"serializeProduction\");\n\n// ../../node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/lib/src/visitor.js\nvar GAstVisitor = class {\n  static {\n    __name(this, \"GAstVisitor\");\n  }\n  visit(node) {\n    const nodeAny = node;\n    switch (nodeAny.constructor) {\n      case NonTerminal:\n        return this.visitNonTerminal(nodeAny);\n      case Alternative:\n        return this.visitAlternative(nodeAny);\n      case Option:\n        return this.visitOption(nodeAny);\n      case RepetitionMandatory:\n        return this.visitRepetitionMandatory(nodeAny);\n      case RepetitionMandatoryWithSeparator:\n        return this.visitRepetitionMandatoryWithSeparator(nodeAny);\n      case RepetitionWithSeparator:\n        return this.visitRepetitionWithSeparator(nodeAny);\n      case Repetition:\n        return this.visitRepetition(nodeAny);\n      case Alternation:\n        return this.visitAlternation(nodeAny);\n      case Terminal:\n        return this.visitTerminal(nodeAny);\n      case Rule:\n        return this.visitRule(nodeAny);\n      /* c8 ignore next 2 */\n      default:\n        throw Error(\"non exhaustive match\");\n    }\n  }\n  /* c8 ignore next */\n  visitNonTerminal(node) {\n  }\n  /* c8 ignore next */\n  visitAlternative(node) {\n  }\n  /* c8 ignore next */\n  visitOption(node) {\n  }\n  /* c8 ignore next */\n  visitRepetition(node) {\n  }\n  /* c8 ignore next */\n  visitRepetitionMandatory(node) {\n  }\n  /* c8 ignore next 3 */\n  visitRepetitionMandatoryWithSeparator(node) {\n  }\n  /* c8 ignore next */\n  visitRepetitionWithSeparator(node) {\n  }\n  /* c8 ignore next */\n  visitAlternation(node) {\n  }\n  /* c8 ignore next */\n  visitTerminal(node) {\n  }\n  /* c8 ignore next */\n  visitRule(node) {\n  }\n};\n\n// ../../node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/lib/src/helpers.js\nfunction isSequenceProd(prod) {\n  return prod instanceof Alternative || prod instanceof Option || prod instanceof Repetition || prod instanceof RepetitionMandatory || prod instanceof RepetitionMandatoryWithSeparator || prod instanceof RepetitionWithSeparator || prod instanceof Terminal || prod instanceof Rule;\n}\n__name(isSequenceProd, \"isSequenceProd\");\nfunction isOptionalProd(prod, alreadyVisited = []) {\n  const isDirectlyOptional = prod instanceof Option || prod instanceof Repetition || prod instanceof RepetitionWithSeparator;\n  if (isDirectlyOptional) {\n    return true;\n  }\n  if (prod instanceof Alternation) {\n    return some_default(prod.definition, (subProd) => {\n      return isOptionalProd(subProd, alreadyVisited);\n    });\n  } else if (prod instanceof NonTerminal && includes_default(alreadyVisited, prod)) {\n    return false;\n  } else if (prod instanceof AbstractProduction) {\n    if (prod instanceof NonTerminal) {\n      alreadyVisited.push(prod);\n    }\n    return every_default(prod.definition, (subProd) => {\n      return isOptionalProd(subProd, alreadyVisited);\n    });\n  } else {\n    return false;\n  }\n}\n__name(isOptionalProd, \"isOptionalProd\");\nfunction isBranchingProd(prod) {\n  return prod instanceof Alternation;\n}\n__name(isBranchingProd, \"isBranchingProd\");\nfunction getProductionDslName(prod) {\n  if (prod instanceof NonTerminal) {\n    return \"SUBRULE\";\n  } else if (prod instanceof Option) {\n    return \"OPTION\";\n  } else if (prod instanceof Alternation) {\n    return \"OR\";\n  } else if (prod instanceof RepetitionMandatory) {\n    return \"AT_LEAST_ONE\";\n  } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n    return \"AT_LEAST_ONE_SEP\";\n  } else if (prod instanceof RepetitionWithSeparator) {\n    return \"MANY_SEP\";\n  } else if (prod instanceof Repetition) {\n    return \"MANY\";\n  } else if (prod instanceof Terminal) {\n    return \"CONSUME\";\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n__name(getProductionDslName, \"getProductionDslName\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/rest.js\nvar RestWalker = class {\n  static {\n    __name(this, \"RestWalker\");\n  }\n  walk(prod, prevRest = []) {\n    forEach_default(prod.definition, (subProd, index) => {\n      const currRest = drop_default(prod.definition, index + 1);\n      if (subProd instanceof NonTerminal) {\n        this.walkProdRef(subProd, currRest, prevRest);\n      } else if (subProd instanceof Terminal) {\n        this.walkTerminal(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternative) {\n        this.walkFlat(subProd, currRest, prevRest);\n      } else if (subProd instanceof Option) {\n        this.walkOption(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatory) {\n        this.walkAtLeastOne(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatoryWithSeparator) {\n        this.walkAtLeastOneSep(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionWithSeparator) {\n        this.walkManySep(subProd, currRest, prevRest);\n      } else if (subProd instanceof Repetition) {\n        this.walkMany(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternation) {\n        this.walkOr(subProd, currRest, prevRest);\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  }\n  walkTerminal(terminal, currRest, prevRest) {\n  }\n  walkProdRef(refProd, currRest, prevRest) {\n  }\n  walkFlat(flatProd, currRest, prevRest) {\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(flatProd, fullOrRest);\n  }\n  walkOption(optionProd, currRest, prevRest) {\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(optionProd, fullOrRest);\n  }\n  walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n    const fullAtLeastOneRest = [\n      new Option({ definition: atLeastOneProd.definition })\n    ].concat(currRest, prevRest);\n    this.walk(atLeastOneProd, fullAtLeastOneRest);\n  }\n  walkAtLeastOneSep(atLeastOneSepProd, currRest, prevRest) {\n    const fullAtLeastOneSepRest = restForRepetitionWithSeparator(atLeastOneSepProd, currRest, prevRest);\n    this.walk(atLeastOneSepProd, fullAtLeastOneSepRest);\n  }\n  walkMany(manyProd, currRest, prevRest) {\n    const fullManyRest = [\n      new Option({ definition: manyProd.definition })\n    ].concat(currRest, prevRest);\n    this.walk(manyProd, fullManyRest);\n  }\n  walkManySep(manySepProd, currRest, prevRest) {\n    const fullManySepRest = restForRepetitionWithSeparator(manySepProd, currRest, prevRest);\n    this.walk(manySepProd, fullManySepRest);\n  }\n  walkOr(orProd, currRest, prevRest) {\n    const fullOrRest = currRest.concat(prevRest);\n    forEach_default(orProd.definition, (alt) => {\n      const prodWrapper = new Alternative({ definition: [alt] });\n      this.walk(prodWrapper, fullOrRest);\n    });\n  }\n};\nfunction restForRepetitionWithSeparator(repSepProd, currRest, prevRest) {\n  const repSepRest = [\n    new Option({\n      definition: [\n        new Terminal({ terminalType: repSepProd.separator })\n      ].concat(repSepProd.definition)\n    })\n  ];\n  const fullRepSepRest = repSepRest.concat(currRest, prevRest);\n  return fullRepSepRest;\n}\n__name(restForRepetitionWithSeparator, \"restForRepetitionWithSeparator\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/first.js\nfunction first(prod) {\n  if (prod instanceof NonTerminal) {\n    return first(prod.referencedRule);\n  } else if (prod instanceof Terminal) {\n    return firstForTerminal(prod);\n  } else if (isSequenceProd(prod)) {\n    return firstForSequence(prod);\n  } else if (isBranchingProd(prod)) {\n    return firstForBranching(prod);\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n__name(first, \"first\");\nfunction firstForSequence(prod) {\n  let firstSet = [];\n  const seq = prod.definition;\n  let nextSubProdIdx = 0;\n  let hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  let currSubProd;\n  let isLastInnerProdOptional = true;\n  while (hasInnerProdsRemaining && isLastInnerProdOptional) {\n    currSubProd = seq[nextSubProdIdx];\n    isLastInnerProdOptional = isOptionalProd(currSubProd);\n    firstSet = firstSet.concat(first(currSubProd));\n    nextSubProdIdx = nextSubProdIdx + 1;\n    hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  }\n  return uniq_default(firstSet);\n}\n__name(firstForSequence, \"firstForSequence\");\nfunction firstForBranching(prod) {\n  const allAlternativesFirsts = map_default(prod.definition, (innerProd) => {\n    return first(innerProd);\n  });\n  return uniq_default(flatten_default(allAlternativesFirsts));\n}\n__name(firstForBranching, \"firstForBranching\");\nfunction firstForTerminal(terminal) {\n  return [terminal.terminalType];\n}\n__name(firstForTerminal, \"firstForTerminal\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/constants.js\nvar IN = \"_~IN~_\";\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/follow.js\nvar ResyncFollowsWalker = class extends RestWalker {\n  static {\n    __name(this, \"ResyncFollowsWalker\");\n  }\n  constructor(topProd) {\n    super();\n    this.topProd = topProd;\n    this.follows = {};\n  }\n  startWalking() {\n    this.walk(this.topProd);\n    return this.follows;\n  }\n  walkTerminal(terminal, currRest, prevRest) {\n  }\n  walkProdRef(refProd, currRest, prevRest) {\n    const followName = buildBetweenProdsFollowPrefix(refProd.referencedRule, refProd.idx) + this.topProd.name;\n    const fullRest = currRest.concat(prevRest);\n    const restProd = new Alternative({ definition: fullRest });\n    const t_in_topProd_follows = first(restProd);\n    this.follows[followName] = t_in_topProd_follows;\n  }\n};\nfunction computeAllProdsFollows(topProductions) {\n  const reSyncFollows = {};\n  forEach_default(topProductions, (topProd) => {\n    const currRefsFollow = new ResyncFollowsWalker(topProd).startWalking();\n    assign_default(reSyncFollows, currRefsFollow);\n  });\n  return reSyncFollows;\n}\n__name(computeAllProdsFollows, \"computeAllProdsFollows\");\nfunction buildBetweenProdsFollowPrefix(inner, occurenceInParent) {\n  return inner.name + occurenceInParent + IN;\n}\n__name(buildBetweenProdsFollowPrefix, \"buildBetweenProdsFollowPrefix\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/scan/reg_exp_parser.js\nvar regExpAstCache = {};\nvar regExpParser = new RegExpParser();\nfunction getRegExpAst(regExp) {\n  const regExpStr = regExp.toString();\n  if (regExpAstCache.hasOwnProperty(regExpStr)) {\n    return regExpAstCache[regExpStr];\n  } else {\n    const regExpAst = regExpParser.pattern(regExpStr);\n    regExpAstCache[regExpStr] = regExpAst;\n    return regExpAst;\n  }\n}\n__name(getRegExpAst, \"getRegExpAst\");\nfunction clearRegExpParserCache() {\n  regExpAstCache = {};\n}\n__name(clearRegExpParserCache, \"clearRegExpParserCache\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/scan/reg_exp.js\nvar complementErrorMessage = \"Complement Sets are not supported for first char optimization\";\nvar failedOptimizationPrefixMsg = 'Unable to use \"first char\" lexer optimizations:\\n';\nfunction getOptimizedStartCodesIndices(regExp, ensureOptimizations = false) {\n  try {\n    const ast = getRegExpAst(regExp);\n    const firstChars = firstCharOptimizedIndices(ast.value, {}, ast.flags.ignoreCase);\n    return firstChars;\n  } catch (e) {\n    if (e.message === complementErrorMessage) {\n      if (ensureOptimizations) {\n        PRINT_WARNING(`${failedOptimizationPrefixMsg}\tUnable to optimize: < ${regExp.toString()} >\n\tComplement Sets cannot be automatically optimized.\n\tThis will disable the lexer's first char optimizations.\n\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#COMPLEMENT for details.`);\n      }\n    } else {\n      let msgSuffix = \"\";\n      if (ensureOptimizations) {\n        msgSuffix = \"\\n\tThis will disable the lexer's first char optimizations.\\n\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#REGEXP_PARSING for details.\";\n      }\n      PRINT_ERROR(`${failedOptimizationPrefixMsg}\n\tFailed parsing: < ${regExp.toString()} >\n\tUsing the @chevrotain/regexp-to-ast library\n\tPlease open an issue at: https://github.com/chevrotain/chevrotain/issues` + msgSuffix);\n    }\n  }\n  return [];\n}\n__name(getOptimizedStartCodesIndices, \"getOptimizedStartCodesIndices\");\nfunction firstCharOptimizedIndices(ast, result, ignoreCase) {\n  switch (ast.type) {\n    case \"Disjunction\":\n      for (let i = 0; i < ast.value.length; i++) {\n        firstCharOptimizedIndices(ast.value[i], result, ignoreCase);\n      }\n      break;\n    case \"Alternative\":\n      const terms = ast.value;\n      for (let i = 0; i < terms.length; i++) {\n        const term = terms[i];\n        switch (term.type) {\n          case \"EndAnchor\":\n          // A group back reference cannot affect potential starting char.\n          // because if a back reference is the first production than automatically\n          // the group being referenced has had to come BEFORE so its codes have already been added\n          case \"GroupBackReference\":\n          // assertions do not affect potential starting codes\n          case \"Lookahead\":\n          case \"NegativeLookahead\":\n          case \"StartAnchor\":\n          case \"WordBoundary\":\n          case \"NonWordBoundary\":\n            continue;\n        }\n        const atom2 = term;\n        switch (atom2.type) {\n          case \"Character\":\n            addOptimizedIdxToResult(atom2.value, result, ignoreCase);\n            break;\n          case \"Set\":\n            if (atom2.complement === true) {\n              throw Error(complementErrorMessage);\n            }\n            forEach_default(atom2.value, (code) => {\n              if (typeof code === \"number\") {\n                addOptimizedIdxToResult(code, result, ignoreCase);\n              } else {\n                const range = code;\n                if (ignoreCase === true) {\n                  for (let rangeCode = range.from; rangeCode <= range.to; rangeCode++) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n                } else {\n                  for (let rangeCode = range.from; rangeCode <= range.to && rangeCode < minOptimizationVal; rangeCode++) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n                  if (range.to >= minOptimizationVal) {\n                    const minUnOptVal = range.from >= minOptimizationVal ? range.from : minOptimizationVal;\n                    const maxUnOptVal = range.to;\n                    const minOptIdx = charCodeToOptimizedIndex(minUnOptVal);\n                    const maxOptIdx = charCodeToOptimizedIndex(maxUnOptVal);\n                    for (let currOptIdx = minOptIdx; currOptIdx <= maxOptIdx; currOptIdx++) {\n                      result[currOptIdx] = currOptIdx;\n                    }\n                  }\n                }\n              }\n            });\n            break;\n          case \"Group\":\n            firstCharOptimizedIndices(atom2.value, result, ignoreCase);\n            break;\n          /* istanbul ignore next */\n          default:\n            throw Error(\"Non Exhaustive Match\");\n        }\n        const isOptionalQuantifier = atom2.quantifier !== void 0 && atom2.quantifier.atLeast === 0;\n        if (\n          // A group may be optional due to empty contents /(?:)/\n          // or if everything inside it is optional /((a)?)/\n          atom2.type === \"Group\" && isWholeOptional(atom2) === false || // If this term is not a group it may only be optional if it has an optional quantifier\n          atom2.type !== \"Group\" && isOptionalQuantifier === false\n        ) {\n          break;\n        }\n      }\n      break;\n    /* istanbul ignore next */\n    default:\n      throw Error(\"non exhaustive match!\");\n  }\n  return values_default(result);\n}\n__name(firstCharOptimizedIndices, \"firstCharOptimizedIndices\");\nfunction addOptimizedIdxToResult(code, result, ignoreCase) {\n  const optimizedCharIdx = charCodeToOptimizedIndex(code);\n  result[optimizedCharIdx] = optimizedCharIdx;\n  if (ignoreCase === true) {\n    handleIgnoreCase(code, result);\n  }\n}\n__name(addOptimizedIdxToResult, \"addOptimizedIdxToResult\");\nfunction handleIgnoreCase(code, result) {\n  const char = String.fromCharCode(code);\n  const upperChar = char.toUpperCase();\n  if (upperChar !== char) {\n    const optimizedCharIdx = charCodeToOptimizedIndex(upperChar.charCodeAt(0));\n    result[optimizedCharIdx] = optimizedCharIdx;\n  } else {\n    const lowerChar = char.toLowerCase();\n    if (lowerChar !== char) {\n      const optimizedCharIdx = charCodeToOptimizedIndex(lowerChar.charCodeAt(0));\n      result[optimizedCharIdx] = optimizedCharIdx;\n    }\n  }\n}\n__name(handleIgnoreCase, \"handleIgnoreCase\");\nfunction findCode(setNode, targetCharCodes) {\n  return find_default(setNode.value, (codeOrRange) => {\n    if (typeof codeOrRange === \"number\") {\n      return includes_default(targetCharCodes, codeOrRange);\n    } else {\n      const range = codeOrRange;\n      return find_default(targetCharCodes, (targetCode) => range.from <= targetCode && targetCode <= range.to) !== void 0;\n    }\n  });\n}\n__name(findCode, \"findCode\");\nfunction isWholeOptional(ast) {\n  const quantifier = ast.quantifier;\n  if (quantifier && quantifier.atLeast === 0) {\n    return true;\n  }\n  if (!ast.value) {\n    return false;\n  }\n  return isArray_default(ast.value) ? every_default(ast.value, isWholeOptional) : isWholeOptional(ast.value);\n}\n__name(isWholeOptional, \"isWholeOptional\");\nvar CharCodeFinder = class extends BaseRegExpVisitor {\n  static {\n    __name(this, \"CharCodeFinder\");\n  }\n  constructor(targetCharCodes) {\n    super();\n    this.targetCharCodes = targetCharCodes;\n    this.found = false;\n  }\n  visitChildren(node) {\n    if (this.found === true) {\n      return;\n    }\n    switch (node.type) {\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        return;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        return;\n    }\n    super.visitChildren(node);\n  }\n  visitCharacter(node) {\n    if (includes_default(this.targetCharCodes, node.value)) {\n      this.found = true;\n    }\n  }\n  visitSet(node) {\n    if (node.complement) {\n      if (findCode(node, this.targetCharCodes) === void 0) {\n        this.found = true;\n      }\n    } else {\n      if (findCode(node, this.targetCharCodes) !== void 0) {\n        this.found = true;\n      }\n    }\n  }\n};\nfunction canMatchCharCode(charCodes, pattern) {\n  if (pattern instanceof RegExp) {\n    const ast = getRegExpAst(pattern);\n    const charCodeFinder = new CharCodeFinder(charCodes);\n    charCodeFinder.visit(ast);\n    return charCodeFinder.found;\n  } else {\n    return find_default(pattern, (char) => {\n      return includes_default(charCodes, char.charCodeAt(0));\n    }) !== void 0;\n  }\n}\n__name(canMatchCharCode, \"canMatchCharCode\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/scan/lexer.js\nvar PATTERN = \"PATTERN\";\nvar DEFAULT_MODE = \"defaultMode\";\nvar MODES = \"modes\";\nvar SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nfunction analyzeTokenTypes(tokenTypes, options) {\n  options = defaults_default(options, {\n    useSticky: SUPPORT_STICKY,\n    debug: false,\n    safeMode: false,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: /* @__PURE__ */ __name((msg, action) => action(), \"tracer\")\n  });\n  const tracer = options.tracer;\n  tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n    initCharCodeToOptimizedIndexMap();\n  });\n  let onlyRelevantTypes;\n  tracer(\"Reject Lexer.NA\", () => {\n    onlyRelevantTypes = reject_default(tokenTypes, (currType) => {\n      return currType[PATTERN] === Lexer.NA;\n    });\n  });\n  let hasCustom = false;\n  let allTransformedPatterns;\n  tracer(\"Transform Patterns\", () => {\n    hasCustom = false;\n    allTransformedPatterns = map_default(onlyRelevantTypes, (currType) => {\n      const currPattern = currType[PATTERN];\n      if (isRegExp_default(currPattern)) {\n        const regExpSource = currPattern.source;\n        if (regExpSource.length === 1 && // only these regExp meta characters which can appear in a length one regExp\n        regExpSource !== \"^\" && regExpSource !== \"$\" && regExpSource !== \".\" && !currPattern.ignoreCase) {\n          return regExpSource;\n        } else if (regExpSource.length === 2 && regExpSource[0] === \"\\\\\" && // not a meta character\n        !includes_default([\n          \"d\",\n          \"D\",\n          \"s\",\n          \"S\",\n          \"t\",\n          \"r\",\n          \"n\",\n          \"t\",\n          \"0\",\n          \"c\",\n          \"b\",\n          \"B\",\n          \"f\",\n          \"v\",\n          \"w\",\n          \"W\"\n        ], regExpSource[1])) {\n          return regExpSource[1];\n        } else {\n          return options.useSticky ? addStickyFlag(currPattern) : addStartOfInput(currPattern);\n        }\n      } else if (isFunction_default(currPattern)) {\n        hasCustom = true;\n        return { exec: currPattern };\n      } else if (typeof currPattern === \"object\") {\n        hasCustom = true;\n        return currPattern;\n      } else if (typeof currPattern === \"string\") {\n        if (currPattern.length === 1) {\n          return currPattern;\n        } else {\n          const escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n          const wrappedRegExp = new RegExp(escapedRegExpString);\n          return options.useSticky ? addStickyFlag(wrappedRegExp) : addStartOfInput(wrappedRegExp);\n        }\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  });\n  let patternIdxToType;\n  let patternIdxToGroup;\n  let patternIdxToLongerAltIdxArr;\n  let patternIdxToPushMode;\n  let patternIdxToPopMode;\n  tracer(\"misc mapping\", () => {\n    patternIdxToType = map_default(onlyRelevantTypes, (currType) => currType.tokenTypeIdx);\n    patternIdxToGroup = map_default(onlyRelevantTypes, (clazz) => {\n      const groupName = clazz.GROUP;\n      if (groupName === Lexer.SKIPPED) {\n        return void 0;\n      } else if (isString_default(groupName)) {\n        return groupName;\n      } else if (isUndefined_default(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n    patternIdxToLongerAltIdxArr = map_default(onlyRelevantTypes, (clazz) => {\n      const longerAltType = clazz.LONGER_ALT;\n      if (longerAltType) {\n        const longerAltIdxArr = isArray_default(longerAltType) ? map_default(longerAltType, (type) => indexOf_default(onlyRelevantTypes, type)) : [indexOf_default(onlyRelevantTypes, longerAltType)];\n        return longerAltIdxArr;\n      }\n    });\n    patternIdxToPushMode = map_default(onlyRelevantTypes, (clazz) => clazz.PUSH_MODE);\n    patternIdxToPopMode = map_default(onlyRelevantTypes, (clazz) => has_default(clazz, \"POP_MODE\"));\n  });\n  let patternIdxToCanLineTerminator;\n  tracer(\"Line Terminator Handling\", () => {\n    const lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n    patternIdxToCanLineTerminator = map_default(onlyRelevantTypes, (tokType) => false);\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = map_default(onlyRelevantTypes, (tokType) => {\n        if (has_default(tokType, \"LINE_BREAKS\")) {\n          return !!tokType.LINE_BREAKS;\n        } else {\n          return checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false && canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n        }\n      });\n    }\n  });\n  let patternIdxToIsCustom;\n  let patternIdxToShort;\n  let emptyGroups;\n  let patternIdxToConfig;\n  tracer(\"Misc Mapping #2\", () => {\n    patternIdxToIsCustom = map_default(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = map_default(allTransformedPatterns, isShortPattern);\n    emptyGroups = reduce_default(onlyRelevantTypes, (acc, clazz) => {\n      const groupName = clazz.GROUP;\n      if (isString_default(groupName) && !(groupName === Lexer.SKIPPED)) {\n        acc[groupName] = [];\n      }\n      return acc;\n    }, {});\n    patternIdxToConfig = map_default(allTransformedPatterns, (x, idx) => {\n      return {\n        pattern: allTransformedPatterns[idx],\n        longerAlt: patternIdxToLongerAltIdxArr[idx],\n        canLineTerminator: patternIdxToCanLineTerminator[idx],\n        isCustom: patternIdxToIsCustom[idx],\n        short: patternIdxToShort[idx],\n        group: patternIdxToGroup[idx],\n        push: patternIdxToPushMode[idx],\n        pop: patternIdxToPopMode[idx],\n        tokenTypeIdx: patternIdxToType[idx],\n        tokenType: onlyRelevantTypes[idx]\n      };\n    });\n  });\n  let canBeOptimized = true;\n  let charCodeToPatternIdxToConfig = [];\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", () => {\n      charCodeToPatternIdxToConfig = reduce_default(onlyRelevantTypes, (result, currTokType, idx) => {\n        if (typeof currTokType.PATTERN === \"string\") {\n          const charCode = currTokType.PATTERN.charCodeAt(0);\n          const optimizedIdx = charCodeToOptimizedIndex(charCode);\n          addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n        } else if (isArray_default(currTokType.START_CHARS_HINT)) {\n          let lastOptimizedIdx;\n          forEach_default(currTokType.START_CHARS_HINT, (charOrInt) => {\n            const charCode = typeof charOrInt === \"string\" ? charOrInt.charCodeAt(0) : charOrInt;\n            const currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n            if (lastOptimizedIdx !== currOptimizedIdx) {\n              lastOptimizedIdx = currOptimizedIdx;\n              addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n            }\n          });\n        } else if (isRegExp_default(currTokType.PATTERN)) {\n          if (currTokType.PATTERN.unicode) {\n            canBeOptimized = false;\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(`${failedOptimizationPrefixMsg}\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\n\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\n\tThis will disable the lexer's first char optimizations.\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE`);\n            }\n          } else {\n            const optimizedCodes = getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\n            if (isEmpty_default(optimizedCodes)) {\n              canBeOptimized = false;\n            }\n            forEach_default(optimizedCodes, (code) => {\n              addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n            });\n          }\n        } else {\n          if (options.ensureOptimizations) {\n            PRINT_ERROR(`${failedOptimizationPrefixMsg}\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\n\tThis will disable the lexer's first char optimizations.\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE`);\n          }\n          canBeOptimized = false;\n        }\n        return result;\n      }, []);\n    });\n  }\n  return {\n    emptyGroups,\n    patternIdxToConfig,\n    charCodeToPatternIdxToConfig,\n    hasCustom,\n    canBeOptimized\n  };\n}\n__name(analyzeTokenTypes, \"analyzeTokenTypes\");\nfunction validatePatterns(tokenTypes, validModesNames) {\n  let errors = [];\n  const missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n  const invalidResult = findInvalidPatterns(missingResult.valid);\n  const validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n  errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n  return errors;\n}\n__name(validatePatterns, \"validatePatterns\");\nfunction validateRegExpPattern(tokenTypes) {\n  let errors = [];\n  const withRegExpPatterns = filter_default(tokenTypes, (currTokType) => isRegExp_default(currTokType[PATTERN]));\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n  return errors;\n}\n__name(validateRegExpPattern, \"validateRegExpPattern\");\nfunction findMissingPatterns(tokenTypes) {\n  const tokenTypesWithMissingPattern = filter_default(tokenTypes, (currType) => {\n    return !has_default(currType, PATTERN);\n  });\n  const errors = map_default(tokenTypesWithMissingPattern, (currType) => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- missing static 'PATTERN' property\",\n      type: LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  const valid = difference_default(tokenTypes, tokenTypesWithMissingPattern);\n  return { errors, valid };\n}\n__name(findMissingPatterns, \"findMissingPatterns\");\nfunction findInvalidPatterns(tokenTypes) {\n  const tokenTypesWithInvalidPattern = filter_default(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return !isRegExp_default(pattern) && !isFunction_default(pattern) && !has_default(pattern, \"exec\") && !isString_default(pattern);\n  });\n  const errors = map_default(tokenTypesWithInvalidPattern, (currType) => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' can only be a RegExp, a Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  const valid = difference_default(tokenTypes, tokenTypesWithInvalidPattern);\n  return { errors, valid };\n}\n__name(findInvalidPatterns, \"findInvalidPatterns\");\nvar end_of_input = /[^\\\\][$]/;\nfunction findEndOfInputAnchor(tokenTypes) {\n  class EndAnchorFinder extends BaseRegExpVisitor {\n    static {\n      __name(this, \"EndAnchorFinder\");\n    }\n    constructor() {\n      super(...arguments);\n      this.found = false;\n    }\n    visitEndAnchor(node) {\n      this.found = true;\n    }\n  }\n  const invalidRegex = filter_default(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN;\n    try {\n      const regexpAst = getRegExpAst(pattern);\n      const endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n      return endAnchorVisitor.found;\n    } catch (e) {\n      return end_of_input.test(pattern.source);\n    }\n  });\n  const errors = map_default(invalidRegex, (currType) => {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\tfor details.\",\n      type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n__name(findEndOfInputAnchor, \"findEndOfInputAnchor\");\nfunction findEmptyMatchRegExps(tokenTypes) {\n  const matchesEmptyString = filter_default(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN;\n    return pattern.test(\"\");\n  });\n  const errors = map_default(matchesEmptyString, (currType) => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' must not match an empty string\",\n      type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n__name(findEmptyMatchRegExps, \"findEmptyMatchRegExps\");\nvar start_of_input = /[^\\\\[][\\^]|^\\^/;\nfunction findStartOfInputAnchor(tokenTypes) {\n  class StartAnchorFinder extends BaseRegExpVisitor {\n    static {\n      __name(this, \"StartAnchorFinder\");\n    }\n    constructor() {\n      super(...arguments);\n      this.found = false;\n    }\n    visitStartAnchor(node) {\n      this.found = true;\n    }\n  }\n  const invalidRegex = filter_default(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN;\n    try {\n      const regexpAst = getRegExpAst(pattern);\n      const startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n      return startAnchorVisitor.found;\n    } catch (e) {\n      return start_of_input.test(pattern.source);\n    }\n  });\n  const errors = map_default(invalidRegex, (currType) => {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\tfor details.\",\n      type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n__name(findStartOfInputAnchor, \"findStartOfInputAnchor\");\nfunction findUnsupportedFlags(tokenTypes) {\n  const invalidFlags = filter_default(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n  const errors = map_default(invalidFlags, (currType) => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n__name(findUnsupportedFlags, \"findUnsupportedFlags\");\nfunction findDuplicatePatterns(tokenTypes) {\n  const found = [];\n  let identicalPatterns = map_default(tokenTypes, (outerType) => {\n    return reduce_default(tokenTypes, (result, innerType) => {\n      if (outerType.PATTERN.source === innerType.PATTERN.source && !includes_default(found, innerType) && innerType.PATTERN !== Lexer.NA) {\n        found.push(innerType);\n        result.push(innerType);\n        return result;\n      }\n      return result;\n    }, []);\n  });\n  identicalPatterns = compact_default(identicalPatterns);\n  const duplicatePatterns = filter_default(identicalPatterns, (currIdenticalSet) => {\n    return currIdenticalSet.length > 1;\n  });\n  const errors = map_default(duplicatePatterns, (setOfIdentical) => {\n    const tokenTypeNames = map_default(setOfIdentical, (currType) => {\n      return currType.name;\n    });\n    const dupPatternSrc = head_default(setOfIdentical).PATTERN;\n    return {\n      message: `The same RegExp pattern ->${dupPatternSrc}<-has been used in all of the following Token Types: ${tokenTypeNames.join(\", \")} <-`,\n      type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical\n    };\n  });\n  return errors;\n}\n__name(findDuplicatePatterns, \"findDuplicatePatterns\");\nfunction findInvalidGroupType(tokenTypes) {\n  const invalidTypes = filter_default(tokenTypes, (clazz) => {\n    if (!has_default(clazz, \"GROUP\")) {\n      return false;\n    }\n    const group = clazz.GROUP;\n    return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString_default(group);\n  });\n  const errors = map_default(invalidTypes, (currType) => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n__name(findInvalidGroupType, \"findInvalidGroupType\");\nfunction findModesThatDoNotExist(tokenTypes, validModes) {\n  const invalidModes = filter_default(tokenTypes, (clazz) => {\n    return clazz.PUSH_MODE !== void 0 && !includes_default(validModes, clazz.PUSH_MODE);\n  });\n  const errors = map_default(invalidModes, (tokType) => {\n    const msg = `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-which does not exist`;\n    return {\n      message: msg,\n      type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType]\n    };\n  });\n  return errors;\n}\n__name(findModesThatDoNotExist, \"findModesThatDoNotExist\");\nfunction findUnreachablePatterns(tokenTypes) {\n  const errors = [];\n  const canBeTested = reduce_default(tokenTypes, (result, tokType, idx) => {\n    const pattern = tokType.PATTERN;\n    if (pattern === Lexer.NA) {\n      return result;\n    }\n    if (isString_default(pattern)) {\n      result.push({ str: pattern, idx, tokenType: tokType });\n    } else if (isRegExp_default(pattern) && noMetaChar(pattern)) {\n      result.push({ str: pattern.source, idx, tokenType: tokType });\n    }\n    return result;\n  }, []);\n  forEach_default(tokenTypes, (tokType, testIdx) => {\n    forEach_default(canBeTested, ({ str, idx, tokenType }) => {\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        const msg = `Token: ->${tokenType.name}<- can never be matched.\nBecause it appears AFTER the Token Type ->${tokType.name}<-in the lexer's definition.\nSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n        errors.push({\n          message: msg,\n          type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType]\n        });\n      }\n    });\n  });\n  return errors;\n}\n__name(findUnreachablePatterns, \"findUnreachablePatterns\");\nfunction testTokenType(str, pattern) {\n  if (isRegExp_default(pattern)) {\n    const regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if (isFunction_default(pattern)) {\n    return pattern(str, 0, [], {});\n  } else if (has_default(pattern, \"exec\")) {\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n__name(testTokenType, \"testTokenType\");\nfunction noMetaChar(regExp) {\n  const metaChars = [\n    \".\",\n    \"\\\\\",\n    \"[\",\n    \"]\",\n    \"|\",\n    \"^\",\n    \"$\",\n    \"(\",\n    \")\",\n    \"?\",\n    \"*\",\n    \"+\",\n    \"{\"\n  ];\n  return find_default(metaChars, (char) => regExp.source.indexOf(char) !== -1) === void 0;\n}\n__name(noMetaChar, \"noMetaChar\");\nfunction addStartOfInput(pattern) {\n  const flags = pattern.ignoreCase ? \"i\" : \"\";\n  return new RegExp(`^(?:${pattern.source})`, flags);\n}\n__name(addStartOfInput, \"addStartOfInput\");\nfunction addStickyFlag(pattern) {\n  const flags = pattern.ignoreCase ? \"iy\" : \"y\";\n  return new RegExp(`${pattern.source}`, flags);\n}\n__name(addStickyFlag, \"addStickyFlag\");\nfunction performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  const errors = [];\n  if (!has_default(lexerDefinition, DEFAULT_MODE)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + DEFAULT_MODE + \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n    });\n  }\n  if (!has_default(lexerDefinition, MODES)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + MODES + \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n    });\n  }\n  if (has_default(lexerDefinition, MODES) && has_default(lexerDefinition, DEFAULT_MODE) && !has_default(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n    errors.push({\n      message: `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>which does not exist\n`,\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n    });\n  }\n  if (has_default(lexerDefinition, MODES)) {\n    forEach_default(lexerDefinition.modes, (currModeValue, currModeName) => {\n      forEach_default(currModeValue, (currTokType, currIdx) => {\n        if (isUndefined_default(currTokType)) {\n          errors.push({\n            message: `A Lexer cannot be initialized using an undefined Token Type. Mode:<${currModeName}> at index: <${currIdx}>\n`,\n            type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n          });\n        } else if (has_default(currTokType, \"LONGER_ALT\")) {\n          const longerAlt = isArray_default(currTokType.LONGER_ALT) ? currTokType.LONGER_ALT : [currTokType.LONGER_ALT];\n          forEach_default(longerAlt, (currLongerAlt) => {\n            if (!isUndefined_default(currLongerAlt) && !includes_default(currModeValue, currLongerAlt)) {\n              errors.push({\n                message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\n`,\n                type: LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\n              });\n            }\n          });\n        }\n      });\n    });\n  }\n  return errors;\n}\n__name(performRuntimeChecks, \"performRuntimeChecks\");\nfunction performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  const warnings = [];\n  let hasAnyLineBreak = false;\n  const allTokenTypes = compact_default(flatten_default(values_default(lexerDefinition.modes)));\n  const concreteTokenTypes = reject_default(allTokenTypes, (currType) => currType[PATTERN] === Lexer.NA);\n  const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n  if (trackLines) {\n    forEach_default(concreteTokenTypes, (tokType) => {\n      const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n      if (currIssue !== false) {\n        const message = buildLineBreakIssueMessage(tokType, currIssue);\n        const warningDescriptor = {\n          message,\n          type: currIssue.issue,\n          tokenType: tokType\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        if (has_default(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if (canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message: \"Warning: No LINE_BREAKS Found.\\n\tThis Lexer has been defined to track line and column information,\\n\tBut none of the Token Types can be identified as matching a line terminator.\\n\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\tfor details.\",\n      type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n    });\n  }\n  return warnings;\n}\n__name(performWarningRuntimeChecks, \"performWarningRuntimeChecks\");\nfunction cloneEmptyGroups(emptyGroups) {\n  const clonedResult = {};\n  const groupKeys = keys_default(emptyGroups);\n  forEach_default(groupKeys, (currKey) => {\n    const currGroupValue = emptyGroups[currKey];\n    if (isArray_default(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n  return clonedResult;\n}\n__name(cloneEmptyGroups, \"cloneEmptyGroups\");\nfunction isCustomPattern(tokenType) {\n  const pattern = tokenType.PATTERN;\n  if (isRegExp_default(pattern)) {\n    return false;\n  } else if (isFunction_default(pattern)) {\n    return true;\n  } else if (has_default(pattern, \"exec\")) {\n    return true;\n  } else if (isString_default(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n__name(isCustomPattern, \"isCustomPattern\");\nfunction isShortPattern(pattern) {\n  if (isString_default(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\n__name(isShortPattern, \"isShortPattern\");\nvar LineTerminatorOptimizedTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: /* @__PURE__ */ __name(function(text) {\n    const len = text.length;\n    for (let i = this.lastIndex; i < len; i++) {\n      const c = text.charCodeAt(i);\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n        return true;\n      }\n    }\n    return false;\n  }, \"test\"),\n  lastIndex: 0\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n  if (has_default(tokType, \"LINE_BREAKS\")) {\n    return false;\n  } else {\n    if (isRegExp_default(tokType.PATTERN)) {\n      try {\n        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n      } catch (e) {\n        return {\n          issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: e.message\n        };\n      }\n      return false;\n    } else if (isString_default(tokType.PATTERN)) {\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\n__name(checkLineBreaksIssues, \"checkLineBreaksIssues\");\nfunction buildLineBreakIssueMessage(tokType, details) {\n  if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return `Warning: unable to identify line terminator usage in pattern.\n\tThe problem is in the <${tokType.name}> Token Type\n\t Root cause: ${details.errMsg}.\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR`;\n  } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return `Warning: A Custom Token Pattern should specify the <line_breaks> option.\n\tThe problem is in the <${tokType.name}> Token Type\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK`;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n__name(buildLineBreakIssueMessage, \"buildLineBreakIssueMessage\");\nfunction getCharCodes(charsOrCodes) {\n  const charCodes = map_default(charsOrCodes, (numOrString) => {\n    if (isString_default(numOrString)) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n  return charCodes;\n}\n__name(getCharCodes, \"getCharCodes\");\nfunction addToMapOfArrays(map, key, value) {\n  if (map[key] === void 0) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\n__name(addToMapOfArrays, \"addToMapOfArrays\");\nvar minOptimizationVal = 256;\nvar charCodeToOptimizedIdxMap = [];\nfunction charCodeToOptimizedIndex(charCode) {\n  return charCode < minOptimizationVal ? charCode : charCodeToOptimizedIdxMap[charCode];\n}\n__name(charCodeToOptimizedIndex, \"charCodeToOptimizedIndex\");\nfunction initCharCodeToOptimizedIndexMap() {\n  if (isEmpty_default(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n    for (let i = 0; i < 65536; i++) {\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n    }\n  }\n}\n__name(initCharCodeToOptimizedIndexMap, \"initCharCodeToOptimizedIndexMap\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/scan/tokens.js\nfunction tokenStructuredMatcher(tokInstance, tokConstructor) {\n  const instanceType = tokInstance.tokenTypeIdx;\n  if (instanceType === tokConstructor.tokenTypeIdx) {\n    return true;\n  } else {\n    return tokConstructor.isParent === true && tokConstructor.categoryMatchesMap[instanceType] === true;\n  }\n}\n__name(tokenStructuredMatcher, \"tokenStructuredMatcher\");\nfunction tokenStructuredMatcherNoCategories(token, tokType) {\n  return token.tokenTypeIdx === tokType.tokenTypeIdx;\n}\n__name(tokenStructuredMatcherNoCategories, \"tokenStructuredMatcherNoCategories\");\nvar tokenShortNameIdx = 1;\nvar tokenIdxToClass = {};\nfunction augmentTokenTypes(tokenTypes) {\n  const tokenTypesAndParents = expandCategories(tokenTypes);\n  assignTokenDefaultProps(tokenTypesAndParents);\n  assignCategoriesMapProp(tokenTypesAndParents);\n  assignCategoriesTokensProp(tokenTypesAndParents);\n  forEach_default(tokenTypesAndParents, (tokType) => {\n    tokType.isParent = tokType.categoryMatches.length > 0;\n  });\n}\n__name(augmentTokenTypes, \"augmentTokenTypes\");\nfunction expandCategories(tokenTypes) {\n  let result = clone_default(tokenTypes);\n  let categories = tokenTypes;\n  let searching = true;\n  while (searching) {\n    categories = compact_default(flatten_default(map_default(categories, (currTokType) => currTokType.CATEGORIES)));\n    const newCategories = difference_default(categories, result);\n    result = result.concat(newCategories);\n    if (isEmpty_default(newCategories)) {\n      searching = false;\n    } else {\n      categories = newCategories;\n    }\n  }\n  return result;\n}\n__name(expandCategories, \"expandCategories\");\nfunction assignTokenDefaultProps(tokenTypes) {\n  forEach_default(tokenTypes, (currTokType) => {\n    if (!hasShortKeyProperty(currTokType)) {\n      tokenIdxToClass[tokenShortNameIdx] = currTokType;\n      currTokType.tokenTypeIdx = tokenShortNameIdx++;\n    }\n    if (hasCategoriesProperty(currTokType) && !isArray_default(currTokType.CATEGORIES)) {\n      currTokType.CATEGORIES = [currTokType.CATEGORIES];\n    }\n    if (!hasCategoriesProperty(currTokType)) {\n      currTokType.CATEGORIES = [];\n    }\n    if (!hasExtendingTokensTypesProperty(currTokType)) {\n      currTokType.categoryMatches = [];\n    }\n    if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n      currTokType.categoryMatchesMap = {};\n    }\n  });\n}\n__name(assignTokenDefaultProps, \"assignTokenDefaultProps\");\nfunction assignCategoriesTokensProp(tokenTypes) {\n  forEach_default(tokenTypes, (currTokType) => {\n    currTokType.categoryMatches = [];\n    forEach_default(currTokType.categoryMatchesMap, (val, key) => {\n      currTokType.categoryMatches.push(tokenIdxToClass[key].tokenTypeIdx);\n    });\n  });\n}\n__name(assignCategoriesTokensProp, \"assignCategoriesTokensProp\");\nfunction assignCategoriesMapProp(tokenTypes) {\n  forEach_default(tokenTypes, (currTokType) => {\n    singleAssignCategoriesToksMap([], currTokType);\n  });\n}\n__name(assignCategoriesMapProp, \"assignCategoriesMapProp\");\nfunction singleAssignCategoriesToksMap(path, nextNode) {\n  forEach_default(path, (pathNode) => {\n    nextNode.categoryMatchesMap[pathNode.tokenTypeIdx] = true;\n  });\n  forEach_default(nextNode.CATEGORIES, (nextCategory) => {\n    const newPath = path.concat(nextNode);\n    if (!includes_default(newPath, nextCategory)) {\n      singleAssignCategoriesToksMap(newPath, nextCategory);\n    }\n  });\n}\n__name(singleAssignCategoriesToksMap, \"singleAssignCategoriesToksMap\");\nfunction hasShortKeyProperty(tokType) {\n  return has_default(tokType, \"tokenTypeIdx\");\n}\n__name(hasShortKeyProperty, \"hasShortKeyProperty\");\nfunction hasCategoriesProperty(tokType) {\n  return has_default(tokType, \"CATEGORIES\");\n}\n__name(hasCategoriesProperty, \"hasCategoriesProperty\");\nfunction hasExtendingTokensTypesProperty(tokType) {\n  return has_default(tokType, \"categoryMatches\");\n}\n__name(hasExtendingTokensTypesProperty, \"hasExtendingTokensTypesProperty\");\nfunction hasExtendingTokensTypesMapProperty(tokType) {\n  return has_default(tokType, \"categoryMatchesMap\");\n}\n__name(hasExtendingTokensTypesMapProperty, \"hasExtendingTokensTypesMapProperty\");\nfunction isTokenType(tokType) {\n  return has_default(tokType, \"tokenTypeIdx\");\n}\n__name(isTokenType, \"isTokenType\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/scan/lexer_errors_public.js\nvar defaultLexerErrorProvider = {\n  buildUnableToPopLexerModeMessage(token) {\n    return `Unable to pop Lexer Mode after encountering Token ->${token.image}<- The Mode Stack is empty`;\n  },\n  buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column) {\n    return `unexpected character: ->${fullText.charAt(startOffset)}<- at offset: ${startOffset}, skipped ${length} characters.`;\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/scan/lexer_public.js\nvar LexerDefinitionErrorType;\n(function(LexerDefinitionErrorType2) {\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n  LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\"] = 17] = \"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\";\n})(LexerDefinitionErrorType || (LexerDefinitionErrorType = {}));\nvar DEFAULT_LEXER_CONFIG = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false,\n  recoveryEnabled: true\n};\nObject.freeze(DEFAULT_LEXER_CONFIG);\nvar Lexer = class {\n  static {\n    __name(this, \"Lexer\");\n  }\n  constructor(lexerDefinition, config = DEFAULT_LEXER_CONFIG) {\n    this.lexerDefinition = lexerDefinition;\n    this.lexerDefinitionErrors = [];\n    this.lexerDefinitionWarning = [];\n    this.patternIdxToConfig = {};\n    this.charCodeToPatternIdxToConfig = {};\n    this.modes = [];\n    this.emptyGroups = {};\n    this.trackStartLines = true;\n    this.trackEndLines = true;\n    this.hasCustom = false;\n    this.canModeBeOptimized = {};\n    this.TRACE_INIT = (phaseDesc, phaseImpl) => {\n      if (this.traceInitPerf === true) {\n        this.traceInitIndent++;\n        const indent = new Array(this.traceInitIndent + 1).join(\"\t\");\n        if (this.traceInitIndent < this.traceInitMaxIdent) {\n          console.log(`${indent}--> <${phaseDesc}>`);\n        }\n        const { time, value } = timer(phaseImpl);\n        const traceMethod = time > 10 ? console.warn : console.log;\n        if (this.traceInitIndent < this.traceInitMaxIdent) {\n          traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n        }\n        this.traceInitIndent--;\n        return value;\n      } else {\n        return phaseImpl();\n      }\n    };\n    if (typeof config === \"boolean\") {\n      throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\na boolean 2nd argument is no longer supported\");\n    }\n    this.config = assign_default({}, DEFAULT_LEXER_CONFIG, config);\n    const traceInitVal = this.config.traceInitPerf;\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity;\n      this.traceInitPerf = true;\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal;\n      this.traceInitPerf = true;\n    }\n    this.traceInitIndent = -1;\n    this.TRACE_INIT(\"Lexer Constructor\", () => {\n      let actualDefinition;\n      let hasOnlySingleMode = true;\n      this.TRACE_INIT(\"Lexer Config handling\", () => {\n        if (this.config.lineTerminatorsPattern === DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n          this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester;\n        } else {\n          if (this.config.lineTerminatorCharacters === DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n            throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n          }\n        }\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n        }\n        this.trackStartLines = /full|onlyStart/i.test(this.config.positionTracking);\n        this.trackEndLines = /full/i.test(this.config.positionTracking);\n        if (isArray_default(lexerDefinition)) {\n          actualDefinition = {\n            modes: { defaultMode: clone_default(lexerDefinition) },\n            defaultMode: DEFAULT_MODE\n          };\n        } else {\n          hasOnlySingleMode = false;\n          actualDefinition = clone_default(lexerDefinition);\n        }\n      });\n      if (this.config.skipValidations === false) {\n        this.TRACE_INIT(\"performRuntimeChecks\", () => {\n          this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(performRuntimeChecks(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n        });\n        this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n          this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(performWarningRuntimeChecks(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n        });\n      }\n      actualDefinition.modes = actualDefinition.modes ? actualDefinition.modes : {};\n      forEach_default(actualDefinition.modes, (currModeValue, currModeName) => {\n        actualDefinition.modes[currModeName] = reject_default(currModeValue, (currTokType) => isUndefined_default(currTokType));\n      });\n      const allModeNames = keys_default(actualDefinition.modes);\n      forEach_default(actualDefinition.modes, (currModDef, currModName) => {\n        this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n          this.modes.push(currModName);\n          if (this.config.skipValidations === false) {\n            this.TRACE_INIT(`validatePatterns`, () => {\n              this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(validatePatterns(currModDef, allModeNames));\n            });\n          }\n          if (isEmpty_default(this.lexerDefinitionErrors)) {\n            augmentTokenTypes(currModDef);\n            let currAnalyzeResult;\n            this.TRACE_INIT(`analyzeTokenTypes`, () => {\n              currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                lineTerminatorCharacters: this.config.lineTerminatorCharacters,\n                positionTracking: config.positionTracking,\n                ensureOptimizations: config.ensureOptimizations,\n                safeMode: config.safeMode,\n                tracer: this.TRACE_INIT\n              });\n            });\n            this.patternIdxToConfig[currModName] = currAnalyzeResult.patternIdxToConfig;\n            this.charCodeToPatternIdxToConfig[currModName] = currAnalyzeResult.charCodeToPatternIdxToConfig;\n            this.emptyGroups = assign_default({}, this.emptyGroups, currAnalyzeResult.emptyGroups);\n            this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n            this.canModeBeOptimized[currModName] = currAnalyzeResult.canBeOptimized;\n          }\n        });\n      });\n      this.defaultMode = actualDefinition.defaultMode;\n      if (!isEmpty_default(this.lexerDefinitionErrors) && !this.config.deferDefinitionErrorsHandling) {\n        const allErrMessages = map_default(this.lexerDefinitionErrors, (error) => {\n          return error.message;\n        });\n        const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n        throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n      }\n      forEach_default(this.lexerDefinitionWarning, (warningDescriptor) => {\n        PRINT_WARNING(warningDescriptor.message);\n      });\n      this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n        if (SUPPORT_STICKY) {\n          this.chopInput = identity_default;\n          this.match = this.matchWithTest;\n        } else {\n          this.updateLastIndex = noop_default;\n          this.match = this.matchWithExec;\n        }\n        if (hasOnlySingleMode) {\n          this.handleModes = noop_default;\n        }\n        if (this.trackStartLines === false) {\n          this.computeNewColumn = identity_default;\n        }\n        if (this.trackEndLines === false) {\n          this.updateTokenEndLineColumnLocation = noop_default;\n        }\n        if (/full/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createFullToken;\n        } else if (/onlyStart/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createStartOnlyToken;\n        } else if (/onlyOffset/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createOffsetOnlyToken;\n        } else {\n          throw Error(`Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`);\n        }\n        if (this.hasCustom) {\n          this.addToken = this.addTokenUsingPush;\n          this.handlePayload = this.handlePayloadWithCustom;\n        } else {\n          this.addToken = this.addTokenUsingMemberAccess;\n          this.handlePayload = this.handlePayloadNoCustom;\n        }\n      });\n      this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n        const unOptimizedModes = reduce_default(this.canModeBeOptimized, (cannotBeOptimized, canBeOptimized, modeName) => {\n          if (canBeOptimized === false) {\n            cannotBeOptimized.push(modeName);\n          }\n          return cannotBeOptimized;\n        }, []);\n        if (config.ensureOptimizations && !isEmpty_default(unOptimizedModes)) {\n          throw Error(`Lexer Modes: < ${unOptimizedModes.join(\", \")} > cannot be optimized.\n\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\n\t Or inspect the console log for details on how to resolve these issues.`);\n        }\n      });\n      this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n        clearRegExpParserCache();\n      });\n      this.TRACE_INIT(\"toFastProperties\", () => {\n        toFastProperties(this);\n      });\n    });\n  }\n  tokenize(text, initialMode = this.defaultMode) {\n    if (!isEmpty_default(this.lexerDefinitionErrors)) {\n      const allErrMessages = map_default(this.lexerDefinitionErrors, (error) => {\n        return error.message;\n      });\n      const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n      throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n    }\n    return this.tokenizeInternal(text, initialMode);\n  }\n  // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n  tokenizeInternal(text, initialMode) {\n    let i, j, k, matchAltImage, longerAlt, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\n    const orgText = text;\n    const orgLength = orgText.length;\n    let offset = 0;\n    let matchedTokensIndex = 0;\n    const guessedNumberOfTokens = this.hasCustom ? 0 : Math.floor(text.length / 10);\n    const matchedTokens = new Array(guessedNumberOfTokens);\n    const errors = [];\n    let line = this.trackStartLines ? 1 : void 0;\n    let column = this.trackStartLines ? 1 : void 0;\n    const groups = cloneEmptyGroups(this.emptyGroups);\n    const trackLines = this.trackStartLines;\n    const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n    let currModePatternsLength = 0;\n    let patternIdxToConfig = [];\n    let currCharCodeToPatternIdxToConfig = [];\n    const modeStack = [];\n    const emptyArray = [];\n    Object.freeze(emptyArray);\n    let getPossiblePatterns;\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig;\n    }\n    __name(getPossiblePatternsSlow, \"getPossiblePatternsSlow\");\n    function getPossiblePatternsOptimized(charCode) {\n      const optimizedCharIdx = charCodeToOptimizedIndex(charCode);\n      const possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n      if (possiblePatterns === void 0) {\n        return emptyArray;\n      } else {\n        return possiblePatterns;\n      }\n    }\n    __name(getPossiblePatternsOptimized, \"getPossiblePatternsOptimized\");\n    const pop_mode = /* @__PURE__ */ __name((popToken) => {\n      if (modeStack.length === 1 && // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n      // So no error should occur.\n      popToken.tokenType.PUSH_MODE === void 0) {\n        const msg2 = this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg2\n        });\n      } else {\n        modeStack.pop();\n        const newMode = last_default(modeStack);\n        patternIdxToConfig = this.patternIdxToConfig[newMode];\n        currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n    }, \"pop_mode\");\n    function push_mode(newMode) {\n      modeStack.push(newMode);\n      currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n      patternIdxToConfig = this.patternIdxToConfig[newMode];\n      currModePatternsLength = patternIdxToConfig.length;\n      currModePatternsLength = patternIdxToConfig.length;\n      const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized;\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow;\n      }\n    }\n    __name(push_mode, \"push_mode\");\n    push_mode.call(this, initialMode);\n    let currConfig;\n    const recoveryEnabled = this.config.recoveryEnabled;\n    while (offset < orgLength) {\n      matchedImage = null;\n      const nextCharCode = orgText.charCodeAt(offset);\n      const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n      const chosenPatternsLength = chosenPatternIdxToConfig.length;\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i];\n        const currPattern = currConfig.pattern;\n        payload = null;\n        const singleCharCode = currConfig.short;\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            matchedImage = currPattern;\n          }\n        } else if (currConfig.isCustom === true) {\n          match = currPattern.exec(orgText, offset, matchedTokens, groups);\n          if (match !== null) {\n            matchedImage = match[0];\n            if (match.payload !== void 0) {\n              payload = match.payload;\n            }\n          } else {\n            matchedImage = null;\n          }\n        } else {\n          this.updateLastIndex(currPattern, offset);\n          matchedImage = this.match(currPattern, text, offset);\n        }\n        if (matchedImage !== null) {\n          longerAlt = currConfig.longerAlt;\n          if (longerAlt !== void 0) {\n            const longerAltLength = longerAlt.length;\n            for (k = 0; k < longerAltLength; k++) {\n              const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n              const longerAltPattern = longerAltConfig.pattern;\n              altPayload = null;\n              if (longerAltConfig.isCustom === true) {\n                match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n                if (match !== null) {\n                  matchAltImage = match[0];\n                  if (match.payload !== void 0) {\n                    altPayload = match.payload;\n                  }\n                } else {\n                  matchAltImage = null;\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern, offset);\n                matchAltImage = this.match(longerAltPattern, text, offset);\n              }\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage;\n                payload = altPayload;\n                currConfig = longerAltConfig;\n                break;\n              }\n            }\n          }\n          break;\n        }\n      }\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length;\n        group = currConfig.group;\n        if (group !== void 0) {\n          tokType = currConfig.tokenTypeIdx;\n          newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n          this.handlePayload(newToken, payload);\n          if (group === false) {\n            matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n          } else {\n            groups[group].push(newToken);\n          }\n        }\n        text = this.chopInput(text, imageLength);\n        offset = offset + imageLength;\n        column = this.computeNewColumn(column, imageLength);\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          let numOfLTsInMatch = 0;\n          let foundTerminator;\n          let lastLTEndOffset;\n          lineTerminatorPattern.lastIndex = 0;\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage);\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n              numOfLTsInMatch++;\n            }\n          } while (foundTerminator === true);\n          if (numOfLTsInMatch !== 0) {\n            line = line + numOfLTsInMatch;\n            column = imageLength - lastLTEndOffset;\n            this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n          }\n        }\n        this.handleModes(currConfig, pop_mode, push_mode, newToken);\n      } else {\n        const errorStartOffset = offset;\n        const errorLine = line;\n        const errorColumn = column;\n        let foundResyncPoint = recoveryEnabled === false;\n        while (foundResyncPoint === false && offset < orgLength) {\n          text = this.chopInput(text, 1);\n          offset++;\n          for (j = 0; j < currModePatternsLength; j++) {\n            const currConfig2 = patternIdxToConfig[j];\n            const currPattern = currConfig2.pattern;\n            const singleCharCode = currConfig2.short;\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                foundResyncPoint = true;\n              }\n            } else if (currConfig2.isCustom === true) {\n              foundResyncPoint = currPattern.exec(orgText, offset, matchedTokens, groups) !== null;\n            } else {\n              this.updateLastIndex(currPattern, offset);\n              foundResyncPoint = currPattern.exec(text) !== null;\n            }\n            if (foundResyncPoint === true) {\n              break;\n            }\n          }\n        }\n        errLength = offset - errorStartOffset;\n        column = this.computeNewColumn(column, errLength);\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg\n        });\n        if (recoveryEnabled === false) {\n          break;\n        }\n      }\n    }\n    if (!this.hasCustom) {\n      matchedTokens.length = matchedTokensIndex;\n    }\n    return {\n      tokens: matchedTokens,\n      groups,\n      errors\n    };\n  }\n  handleModes(config, pop_mode, push_mode, newToken) {\n    if (config.pop === true) {\n      const pushMode = config.push;\n      pop_mode(newToken);\n      if (pushMode !== void 0) {\n        push_mode.call(this, pushMode);\n      }\n    } else if (config.push !== void 0) {\n      push_mode.call(this, config.push);\n    }\n  }\n  chopInput(text, length) {\n    return text.substring(length);\n  }\n  updateLastIndex(regExp, newLastIndex) {\n    regExp.lastIndex = newLastIndex;\n  }\n  // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n  updateTokenEndLineColumnLocation(newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n    let lastCharIsLT, fixForEndingInLT;\n    if (group !== void 0) {\n      lastCharIsLT = lastLTIdx === imageLength - 1;\n      fixForEndingInLT = lastCharIsLT ? -1 : 0;\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        newToken.endLine = line + fixForEndingInLT;\n        newToken.endColumn = column - 1 + -fixForEndingInLT;\n      }\n    }\n  }\n  computeNewColumn(oldColumn, imageLength) {\n    return oldColumn + imageLength;\n  }\n  createOffsetOnlyToken(image, startOffset, tokenTypeIdx, tokenType) {\n    return {\n      image,\n      startOffset,\n      tokenTypeIdx,\n      tokenType\n    };\n  }\n  createStartOnlyToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n    return {\n      image,\n      startOffset,\n      startLine,\n      startColumn,\n      tokenTypeIdx,\n      tokenType\n    };\n  }\n  createFullToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n    return {\n      image,\n      startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine,\n      endLine: startLine,\n      startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx,\n      tokenType\n    };\n  }\n  addTokenUsingPush(tokenVector, index, tokenToAdd) {\n    tokenVector.push(tokenToAdd);\n    return index;\n  }\n  addTokenUsingMemberAccess(tokenVector, index, tokenToAdd) {\n    tokenVector[index] = tokenToAdd;\n    index++;\n    return index;\n  }\n  handlePayloadNoCustom(token, payload) {\n  }\n  handlePayloadWithCustom(token, payload) {\n    if (payload !== null) {\n      token.payload = payload;\n    }\n  }\n  matchWithTest(pattern, text, offset) {\n    const found = pattern.test(text);\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex);\n    }\n    return null;\n  }\n  matchWithExec(pattern, text) {\n    const regExpArray = pattern.exec(text);\n    return regExpArray !== null ? regExpArray[0] : null;\n  }\n};\nLexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it willbe consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\nLexer.NA = /NOT_APPLICABLE/;\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/scan/tokens_public.js\nfunction tokenLabel2(tokType) {\n  if (hasTokenLabel2(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\n__name(tokenLabel2, \"tokenLabel\");\nfunction hasTokenLabel2(obj) {\n  return isString_default(obj.LABEL) && obj.LABEL !== \"\";\n}\n__name(hasTokenLabel2, \"hasTokenLabel\");\nvar PARENT = \"parent\";\nvar CATEGORIES = \"categories\";\nvar LABEL = \"label\";\nvar GROUP = \"group\";\nvar PUSH_MODE = \"push_mode\";\nvar POP_MODE = \"pop_mode\";\nvar LONGER_ALT = \"longer_alt\";\nvar LINE_BREAKS = \"line_breaks\";\nvar START_CHARS_HINT = \"start_chars_hint\";\nfunction createToken(config) {\n  return createTokenInternal(config);\n}\n__name(createToken, \"createToken\");\nfunction createTokenInternal(config) {\n  const pattern = config.pattern;\n  const tokenType = {};\n  tokenType.name = config.name;\n  if (!isUndefined_default(pattern)) {\n    tokenType.PATTERN = pattern;\n  }\n  if (has_default(config, PARENT)) {\n    throw \"The parent property is no longer supported.\\nSee: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\";\n  }\n  if (has_default(config, CATEGORIES)) {\n    tokenType.CATEGORIES = config[CATEGORIES];\n  }\n  augmentTokenTypes([tokenType]);\n  if (has_default(config, LABEL)) {\n    tokenType.LABEL = config[LABEL];\n  }\n  if (has_default(config, GROUP)) {\n    tokenType.GROUP = config[GROUP];\n  }\n  if (has_default(config, POP_MODE)) {\n    tokenType.POP_MODE = config[POP_MODE];\n  }\n  if (has_default(config, PUSH_MODE)) {\n    tokenType.PUSH_MODE = config[PUSH_MODE];\n  }\n  if (has_default(config, LONGER_ALT)) {\n    tokenType.LONGER_ALT = config[LONGER_ALT];\n  }\n  if (has_default(config, LINE_BREAKS)) {\n    tokenType.LINE_BREAKS = config[LINE_BREAKS];\n  }\n  if (has_default(config, START_CHARS_HINT)) {\n    tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n  }\n  return tokenType;\n}\n__name(createTokenInternal, \"createTokenInternal\");\nvar EOF = createToken({ name: \"EOF\", pattern: Lexer.NA });\naugmentTokenTypes([EOF]);\nfunction createTokenInstance(tokType, image, startOffset, endOffset, startLine, endLine, startColumn, endColumn) {\n  return {\n    image,\n    startOffset,\n    endOffset,\n    startLine,\n    endLine,\n    startColumn,\n    endColumn,\n    tokenTypeIdx: tokType.tokenTypeIdx,\n    tokenType: tokType\n  };\n}\n__name(createTokenInstance, \"createTokenInstance\");\nfunction tokenMatcher(token, tokType) {\n  return tokenStructuredMatcher(token, tokType);\n}\n__name(tokenMatcher, \"tokenMatcher\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/errors_public.js\nvar defaultParserErrorProvider = {\n  buildMismatchTokenMessage({ expected, actual, previous, ruleName }) {\n    const hasLabel = hasTokenLabel2(expected);\n    const expectedMsg = hasLabel ? `--> ${tokenLabel2(expected)} <--` : `token of type --> ${expected.name} <--`;\n    const msg = `Expecting ${expectedMsg} but found --> '${actual.image}' <--`;\n    return msg;\n  },\n  buildNotAllInputParsedMessage({ firstRedundant, ruleName }) {\n    return \"Redundant input, expecting EOF but found: \" + firstRedundant.image;\n  },\n  buildNoViableAltMessage({ expectedPathsPerAlt, actual, previous, customUserDescription, ruleName }) {\n    const errPrefix = \"Expecting: \";\n    const actualText = head_default(actual).image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const allLookAheadPaths = reduce_default(expectedPathsPerAlt, (result, currAltPaths) => result.concat(currAltPaths), []);\n      const nextValidTokenSequences = map_default(allLookAheadPaths, (currPath) => `[${map_default(currPath, (currTokenType) => tokenLabel2(currTokenType)).join(\", \")}]`);\n      const nextValidSequenceItems = map_default(nextValidTokenSequences, (itemMsg, idx) => `  ${idx + 1}. ${itemMsg}`);\n      const calculatedDescription = `one of these possible Token sequences:\n${nextValidSequenceItems.join(\"\\n\")}`;\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  },\n  buildEarlyExitMessage({ expectedIterationPaths, actual, customUserDescription, ruleName }) {\n    const errPrefix = \"Expecting: \";\n    const actualText = head_default(actual).image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const nextValidTokenSequences = map_default(expectedIterationPaths, (currPath) => `[${map_default(currPath, (currTokenType) => tokenLabel2(currTokenType)).join(\",\")}]`);\n      const calculatedDescription = `expecting at least one iteration which starts with one of these possible Token sequences::\n  <${nextValidTokenSequences.join(\" ,\")}>`;\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  }\n};\nObject.freeze(defaultParserErrorProvider);\nvar defaultGrammarResolverErrorProvider = {\n  buildRuleNotFoundError(topLevelRule, undefinedRule) {\n    const msg = \"Invalid grammar, reference to a rule which is not defined: ->\" + undefinedRule.nonTerminalName + \"<-\\ninside top level rule: ->\" + topLevelRule.name + \"<-\";\n    return msg;\n  }\n};\nvar defaultGrammarValidatorErrorProvider = {\n  buildDuplicateFoundError(topLevelRule, duplicateProds) {\n    function getExtraProductionArgument2(prod) {\n      if (prod instanceof Terminal) {\n        return prod.terminalType.name;\n      } else if (prod instanceof NonTerminal) {\n        return prod.nonTerminalName;\n      } else {\n        return \"\";\n      }\n    }\n    __name(getExtraProductionArgument2, \"getExtraProductionArgument\");\n    const topLevelName = topLevelRule.name;\n    const duplicateProd = head_default(duplicateProds);\n    const index = duplicateProd.idx;\n    const dslName = getProductionDslName(duplicateProd);\n    const extraArgument = getExtraProductionArgument2(duplicateProd);\n    const hasExplicitIndex = index > 0;\n    let msg = `->${dslName}${hasExplicitIndex ? index : \"\"}<- ${extraArgument ? `with argument: ->${extraArgument}<-` : \"\"}\n                  appears more than once (${duplicateProds.length} times) in the top level rule: ->${topLevelName}<-.                  \n                  For further details see: https://chevrotain.io/docs/FAQ.html#NUMERICAL_SUFFIXES \n                  `;\n    msg = msg.replace(/[ \\t]+/g, \" \");\n    msg = msg.replace(/\\s\\s+/g, \"\\n\");\n    return msg;\n  },\n  buildNamespaceConflictError(rule) {\n    const errMsg = `Namespace conflict found in grammar.\nThe grammar has both a Terminal(Token) and a Non-Terminal(Rule) named: <${rule.name}>.\nTo resolve this make sure each Terminal and Non-Terminal names are unique\nThis is easy to accomplish by using the convention that Terminal names start with an uppercase letter\nand Non-Terminal names start with a lower case letter.`;\n    return errMsg;\n  },\n  buildAlternationPrefixAmbiguityError(options) {\n    const pathMsg = map_default(options.prefixPath, (currTok) => tokenLabel2(currTok)).join(\", \");\n    const occurrence = options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n    const errMsg = `Ambiguous alternatives: <${options.ambiguityIndices.join(\" ,\")}> due to common lookahead prefix\nin <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\n<${pathMsg}> may appears as a prefix path in all these alternatives.\nSee: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#COMMON_PREFIX\nFor Further details.`;\n    return errMsg;\n  },\n  buildAlternationAmbiguityError(options) {\n    const pathMsg = map_default(options.prefixPath, (currtok) => tokenLabel2(currtok)).join(\", \");\n    const occurrence = options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n    let currMessage = `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\" ,\")}> in <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\n<${pathMsg}> may appears as a prefix path in all these alternatives.\n`;\n    currMessage = currMessage + `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\nFor Further details.`;\n    return currMessage;\n  },\n  buildEmptyRepetitionError(options) {\n    let dslName = getProductionDslName(options.repetition);\n    if (options.repetition.idx !== 0) {\n      dslName += options.repetition.idx;\n    }\n    const errMsg = `The repetition <${dslName}> within Rule <${options.topLevelRule.name}> can never consume any tokens.\nThis could lead to an infinite loop.`;\n    return errMsg;\n  },\n  // TODO: remove - `errors_public` from nyc.config.js exclude\n  //       once this method is fully removed from this file\n  buildTokenNameError(options) {\n    return \"deprecated\";\n  },\n  buildEmptyAlternationError(options) {\n    const errMsg = `Ambiguous empty alternative: <${options.emptyChoiceIdx + 1}> in <OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\nOnly the last alternative may be an empty alternative.`;\n    return errMsg;\n  },\n  buildTooManyAlternativesError(options) {\n    const errMsg = `An Alternation cannot have more than 256 alternatives:\n<OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\n has ${options.alternation.definition.length + 1} alternatives.`;\n    return errMsg;\n  },\n  buildLeftRecursionError(options) {\n    const ruleName = options.topLevelRule.name;\n    const pathNames = map_default(options.leftRecursionPath, (currRule) => currRule.name);\n    const leftRecursivePath = `${ruleName} --> ${pathNames.concat([ruleName]).join(\" --> \")}`;\n    const errMsg = `Left Recursion found in grammar.\nrule: <${ruleName}> can be invoked from itself (directly or indirectly)\nwithout consuming any Tokens. The grammar path that causes this is: \n ${leftRecursivePath}\n To fix this refactor your grammar to remove the left recursion.\nsee: https://en.wikipedia.org/wiki/LL_parser#Left_factoring.`;\n    return errMsg;\n  },\n  // TODO: remove - `errors_public` from nyc.config.js exclude\n  //       once this method is fully removed from this file\n  buildInvalidRuleNameError(options) {\n    return \"deprecated\";\n  },\n  buildDuplicateRuleNameError(options) {\n    let ruleName;\n    if (options.topLevelRule instanceof Rule) {\n      ruleName = options.topLevelRule.name;\n    } else {\n      ruleName = options.topLevelRule;\n    }\n    const errMsg = `Duplicate definition, rule: ->${ruleName}<- is already defined in the grammar: ->${options.grammarName}<-`;\n    return errMsg;\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/resolver.js\nfunction resolveGrammar(topLevels, errMsgProvider) {\n  const refResolver = new GastRefResolverVisitor(topLevels, errMsgProvider);\n  refResolver.resolveRefs();\n  return refResolver.errors;\n}\n__name(resolveGrammar, \"resolveGrammar\");\nvar GastRefResolverVisitor = class extends GAstVisitor {\n  static {\n    __name(this, \"GastRefResolverVisitor\");\n  }\n  constructor(nameToTopRule, errMsgProvider) {\n    super();\n    this.nameToTopRule = nameToTopRule;\n    this.errMsgProvider = errMsgProvider;\n    this.errors = [];\n  }\n  resolveRefs() {\n    forEach_default(values_default(this.nameToTopRule), (prod) => {\n      this.currTopLevel = prod;\n      prod.accept(this);\n    });\n  }\n  visitNonTerminal(node) {\n    const ref = this.nameToTopRule[node.nonTerminalName];\n    if (!ref) {\n      const msg = this.errMsgProvider.buildRuleNotFoundError(this.currTopLevel, node);\n      this.errors.push({\n        message: msg,\n        type: ParserDefinitionErrorType.UNRESOLVED_SUBRULE_REF,\n        ruleName: this.currTopLevel.name,\n        unresolvedRefName: node.nonTerminalName\n      });\n    } else {\n      node.referencedRule = ref;\n    }\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/interpreter.js\nvar AbstractNextPossibleTokensWalker = class extends RestWalker {\n  static {\n    __name(this, \"AbstractNextPossibleTokensWalker\");\n  }\n  constructor(topProd, path) {\n    super();\n    this.topProd = topProd;\n    this.path = path;\n    this.possibleTokTypes = [];\n    this.nextProductionName = \"\";\n    this.nextProductionOccurrence = 0;\n    this.found = false;\n    this.isAtEndOfPath = false;\n  }\n  startWalking() {\n    this.found = false;\n    if (this.path.ruleStack[0] !== this.topProd.name) {\n      throw Error(\"The path does not start with the walker's top Rule!\");\n    }\n    this.ruleStack = clone_default(this.path.ruleStack).reverse();\n    this.occurrenceStack = clone_default(this.path.occurrenceStack).reverse();\n    this.ruleStack.pop();\n    this.occurrenceStack.pop();\n    this.updateExpectedNext();\n    this.walk(this.topProd);\n    return this.possibleTokTypes;\n  }\n  walk(prod, prevRest = []) {\n    if (!this.found) {\n      super.walk(prod, prevRest);\n    }\n  }\n  walkProdRef(refProd, currRest, prevRest) {\n    if (refProd.referencedRule.name === this.nextProductionName && refProd.idx === this.nextProductionOccurrence) {\n      const fullRest = currRest.concat(prevRest);\n      this.updateExpectedNext();\n      this.walk(refProd.referencedRule, fullRest);\n    }\n  }\n  updateExpectedNext() {\n    if (isEmpty_default(this.ruleStack)) {\n      this.nextProductionName = \"\";\n      this.nextProductionOccurrence = 0;\n      this.isAtEndOfPath = true;\n    } else {\n      this.nextProductionName = this.ruleStack.pop();\n      this.nextProductionOccurrence = this.occurrenceStack.pop();\n    }\n  }\n};\nvar NextAfterTokenWalker = class extends AbstractNextPossibleTokensWalker {\n  static {\n    __name(this, \"NextAfterTokenWalker\");\n  }\n  constructor(topProd, path) {\n    super(topProd, path);\n    this.path = path;\n    this.nextTerminalName = \"\";\n    this.nextTerminalOccurrence = 0;\n    this.nextTerminalName = this.path.lastTok.name;\n    this.nextTerminalOccurrence = this.path.lastTokOccurrence;\n  }\n  walkTerminal(terminal, currRest, prevRest) {\n    if (this.isAtEndOfPath && terminal.terminalType.name === this.nextTerminalName && terminal.idx === this.nextTerminalOccurrence && !this.found) {\n      const fullRest = currRest.concat(prevRest);\n      const restProd = new Alternative({ definition: fullRest });\n      this.possibleTokTypes = first(restProd);\n      this.found = true;\n    }\n  }\n};\nvar AbstractNextTerminalAfterProductionWalker = class extends RestWalker {\n  static {\n    __name(this, \"AbstractNextTerminalAfterProductionWalker\");\n  }\n  constructor(topRule, occurrence) {\n    super();\n    this.topRule = topRule;\n    this.occurrence = occurrence;\n    this.result = {\n      token: void 0,\n      occurrence: void 0,\n      isEndOfRule: void 0\n    };\n  }\n  startWalking() {\n    this.walk(this.topRule);\n    return this.result;\n  }\n};\nvar NextTerminalAfterManyWalker = class extends AbstractNextTerminalAfterProductionWalker {\n  static {\n    __name(this, \"NextTerminalAfterManyWalker\");\n  }\n  walkMany(manyProd, currRest, prevRest) {\n    if (manyProd.idx === this.occurrence) {\n      const firstAfterMany = head_default(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterMany === void 0;\n      if (firstAfterMany instanceof Terminal) {\n        this.result.token = firstAfterMany.terminalType;\n        this.result.occurrence = firstAfterMany.idx;\n      }\n    } else {\n      super.walkMany(manyProd, currRest, prevRest);\n    }\n  }\n};\nvar NextTerminalAfterManySepWalker = class extends AbstractNextTerminalAfterProductionWalker {\n  static {\n    __name(this, \"NextTerminalAfterManySepWalker\");\n  }\n  walkManySep(manySepProd, currRest, prevRest) {\n    if (manySepProd.idx === this.occurrence) {\n      const firstAfterManySep = head_default(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterManySep === void 0;\n      if (firstAfterManySep instanceof Terminal) {\n        this.result.token = firstAfterManySep.terminalType;\n        this.result.occurrence = firstAfterManySep.idx;\n      }\n    } else {\n      super.walkManySep(manySepProd, currRest, prevRest);\n    }\n  }\n};\nvar NextTerminalAfterAtLeastOneWalker = class extends AbstractNextTerminalAfterProductionWalker {\n  static {\n    __name(this, \"NextTerminalAfterAtLeastOneWalker\");\n  }\n  walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n    if (atLeastOneProd.idx === this.occurrence) {\n      const firstAfterAtLeastOne = head_default(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterAtLeastOne === void 0;\n      if (firstAfterAtLeastOne instanceof Terminal) {\n        this.result.token = firstAfterAtLeastOne.terminalType;\n        this.result.occurrence = firstAfterAtLeastOne.idx;\n      }\n    } else {\n      super.walkAtLeastOne(atLeastOneProd, currRest, prevRest);\n    }\n  }\n};\nvar NextTerminalAfterAtLeastOneSepWalker = class extends AbstractNextTerminalAfterProductionWalker {\n  static {\n    __name(this, \"NextTerminalAfterAtLeastOneSepWalker\");\n  }\n  walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest) {\n    if (atleastOneSepProd.idx === this.occurrence) {\n      const firstAfterfirstAfterAtLeastOneSep = head_default(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterfirstAfterAtLeastOneSep === void 0;\n      if (firstAfterfirstAfterAtLeastOneSep instanceof Terminal) {\n        this.result.token = firstAfterfirstAfterAtLeastOneSep.terminalType;\n        this.result.occurrence = firstAfterfirstAfterAtLeastOneSep.idx;\n      }\n    } else {\n      super.walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest);\n    }\n  }\n};\nfunction possiblePathsFrom(targetDef, maxLength, currPath = []) {\n  currPath = clone_default(currPath);\n  let result = [];\n  let i = 0;\n  function remainingPathWith(nextDef) {\n    return nextDef.concat(drop_default(targetDef, i + 1));\n  }\n  __name(remainingPathWith, \"remainingPathWith\");\n  function getAlternativesForProd(definition) {\n    const alternatives = possiblePathsFrom(remainingPathWith(definition), maxLength, currPath);\n    return result.concat(alternatives);\n  }\n  __name(getAlternativesForProd, \"getAlternativesForProd\");\n  while (currPath.length < maxLength && i < targetDef.length) {\n    const prod = targetDef[i];\n    if (prod instanceof Alternative) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof NonTerminal) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof Option) {\n      result = getAlternativesForProd(prod.definition);\n    } else if (prod instanceof RepetitionMandatory) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition\n        })\n      ]);\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      const newDef = [\n        new Alternative({ definition: prod.definition }),\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(prod.definition)\n        })\n      ];\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(prod.definition)\n        })\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Repetition) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition\n        })\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Alternation) {\n      forEach_default(prod.definition, (currAlt) => {\n        if (isEmpty_default(currAlt.definition) === false) {\n          result = getAlternativesForProd(currAlt.definition);\n        }\n      });\n      return result;\n    } else if (prod instanceof Terminal) {\n      currPath.push(prod.terminalType);\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n    i++;\n  }\n  result.push({\n    partialPath: currPath,\n    suffixDef: drop_default(targetDef, i)\n  });\n  return result;\n}\n__name(possiblePathsFrom, \"possiblePathsFrom\");\nfunction nextPossibleTokensAfter(initialDef, tokenVector, tokMatcher, maxLookAhead) {\n  const EXIT_NON_TERMINAL = \"EXIT_NONE_TERMINAL\";\n  const EXIT_NON_TERMINAL_ARR = [EXIT_NON_TERMINAL];\n  const EXIT_ALTERNATIVE = \"EXIT_ALTERNATIVE\";\n  let foundCompletePath = false;\n  const tokenVectorLength = tokenVector.length;\n  const minimalAlternativesIndex = tokenVectorLength - maxLookAhead - 1;\n  const result = [];\n  const possiblePaths = [];\n  possiblePaths.push({\n    idx: -1,\n    def: initialDef,\n    ruleStack: [],\n    occurrenceStack: []\n  });\n  while (!isEmpty_default(possiblePaths)) {\n    const currPath = possiblePaths.pop();\n    if (currPath === EXIT_ALTERNATIVE) {\n      if (foundCompletePath && last_default(possiblePaths).idx <= minimalAlternativesIndex) {\n        possiblePaths.pop();\n      }\n      continue;\n    }\n    const currDef = currPath.def;\n    const currIdx = currPath.idx;\n    const currRuleStack = currPath.ruleStack;\n    const currOccurrenceStack = currPath.occurrenceStack;\n    if (isEmpty_default(currDef)) {\n      continue;\n    }\n    const prod = currDef[0];\n    if (prod === EXIT_NON_TERMINAL) {\n      const nextPath = {\n        idx: currIdx,\n        def: drop_default(currDef),\n        ruleStack: dropRight_default(currRuleStack),\n        occurrenceStack: dropRight_default(currOccurrenceStack)\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Terminal) {\n      if (currIdx < tokenVectorLength - 1) {\n        const nextIdx = currIdx + 1;\n        const actualToken = tokenVector[nextIdx];\n        if (tokMatcher(actualToken, prod.terminalType)) {\n          const nextPath = {\n            idx: nextIdx,\n            def: drop_default(currDef),\n            ruleStack: currRuleStack,\n            occurrenceStack: currOccurrenceStack\n          };\n          possiblePaths.push(nextPath);\n        }\n      } else if (currIdx === tokenVectorLength - 1) {\n        result.push({\n          nextTokenType: prod.terminalType,\n          nextTokenOccurrence: prod.idx,\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        });\n        foundCompletePath = true;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    } else if (prod instanceof NonTerminal) {\n      const newRuleStack = clone_default(currRuleStack);\n      newRuleStack.push(prod.nonTerminalName);\n      const newOccurrenceStack = clone_default(currOccurrenceStack);\n      newOccurrenceStack.push(prod.idx);\n      const nextPath = {\n        idx: currIdx,\n        def: prod.definition.concat(EXIT_NON_TERMINAL_ARR, drop_default(currDef)),\n        ruleStack: newRuleStack,\n        occurrenceStack: newOccurrenceStack\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Option) {\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop_default(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack\n      };\n      possiblePaths.push(nextPathWithout);\n      possiblePaths.push(EXIT_ALTERNATIVE);\n      const nextPathWith = {\n        idx: currIdx,\n        def: prod.definition.concat(drop_default(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof RepetitionMandatory) {\n      const secondIteration = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop_default(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      const separatorGast = new Terminal({\n        terminalType: prod.separator\n      });\n      const secondIteration = new Repetition({\n        definition: [separatorGast].concat(prod.definition),\n        idx: prod.idx\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop_default(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop_default(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack\n      };\n      possiblePaths.push(nextPathWithout);\n      possiblePaths.push(EXIT_ALTERNATIVE);\n      const separatorGast = new Terminal({\n        terminalType: prod.separator\n      });\n      const nthRepetition = new Repetition({\n        definition: [separatorGast].concat(prod.definition),\n        idx: prod.idx\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop_default(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Repetition) {\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop_default(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack\n      };\n      possiblePaths.push(nextPathWithout);\n      possiblePaths.push(EXIT_ALTERNATIVE);\n      const nthRepetition = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop_default(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Alternation) {\n      for (let i = prod.definition.length - 1; i >= 0; i--) {\n        const currAlt = prod.definition[i];\n        const currAltPath = {\n          idx: currIdx,\n          def: currAlt.definition.concat(drop_default(currDef)),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        };\n        possiblePaths.push(currAltPath);\n        possiblePaths.push(EXIT_ALTERNATIVE);\n      }\n    } else if (prod instanceof Alternative) {\n      possiblePaths.push({\n        idx: currIdx,\n        def: prod.definition.concat(drop_default(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack\n      });\n    } else if (prod instanceof Rule) {\n      possiblePaths.push(expandTopLevelRule(prod, currIdx, currRuleStack, currOccurrenceStack));\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  return result;\n}\n__name(nextPossibleTokensAfter, \"nextPossibleTokensAfter\");\nfunction expandTopLevelRule(topRule, currIdx, currRuleStack, currOccurrenceStack) {\n  const newRuleStack = clone_default(currRuleStack);\n  newRuleStack.push(topRule.name);\n  const newCurrOccurrenceStack = clone_default(currOccurrenceStack);\n  newCurrOccurrenceStack.push(1);\n  return {\n    idx: currIdx,\n    def: topRule.definition,\n    ruleStack: newRuleStack,\n    occurrenceStack: newCurrOccurrenceStack\n  };\n}\n__name(expandTopLevelRule, \"expandTopLevelRule\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/lookahead.js\nvar PROD_TYPE;\n(function(PROD_TYPE2) {\n  PROD_TYPE2[PROD_TYPE2[\"OPTION\"] = 0] = \"OPTION\";\n  PROD_TYPE2[PROD_TYPE2[\"REPETITION\"] = 1] = \"REPETITION\";\n  PROD_TYPE2[PROD_TYPE2[\"REPETITION_MANDATORY\"] = 2] = \"REPETITION_MANDATORY\";\n  PROD_TYPE2[PROD_TYPE2[\"REPETITION_MANDATORY_WITH_SEPARATOR\"] = 3] = \"REPETITION_MANDATORY_WITH_SEPARATOR\";\n  PROD_TYPE2[PROD_TYPE2[\"REPETITION_WITH_SEPARATOR\"] = 4] = \"REPETITION_WITH_SEPARATOR\";\n  PROD_TYPE2[PROD_TYPE2[\"ALTERNATION\"] = 5] = \"ALTERNATION\";\n})(PROD_TYPE || (PROD_TYPE = {}));\nfunction getProdType(prod) {\n  if (prod instanceof Option || prod === \"Option\") {\n    return PROD_TYPE.OPTION;\n  } else if (prod instanceof Repetition || prod === \"Repetition\") {\n    return PROD_TYPE.REPETITION;\n  } else if (prod instanceof RepetitionMandatory || prod === \"RepetitionMandatory\") {\n    return PROD_TYPE.REPETITION_MANDATORY;\n  } else if (prod instanceof RepetitionMandatoryWithSeparator || prod === \"RepetitionMandatoryWithSeparator\") {\n    return PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR;\n  } else if (prod instanceof RepetitionWithSeparator || prod === \"RepetitionWithSeparator\") {\n    return PROD_TYPE.REPETITION_WITH_SEPARATOR;\n  } else if (prod instanceof Alternation || prod === \"Alternation\") {\n    return PROD_TYPE.ALTERNATION;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n__name(getProdType, \"getProdType\");\nfunction getLookaheadPaths(options) {\n  const { occurrence, rule, prodType, maxLookahead } = options;\n  const type = getProdType(prodType);\n  if (type === PROD_TYPE.ALTERNATION) {\n    return getLookaheadPathsForOr(occurrence, rule, maxLookahead);\n  } else {\n    return getLookaheadPathsForOptionalProd(occurrence, rule, type, maxLookahead);\n  }\n}\n__name(getLookaheadPaths, \"getLookaheadPaths\");\nfunction buildLookaheadFuncForOr(occurrence, ruleGrammar, maxLookahead, hasPredicates, dynamicTokensEnabled, laFuncBuilder) {\n  const lookAheadPaths = getLookaheadPathsForOr(occurrence, ruleGrammar, maxLookahead);\n  const tokenMatcher2 = areTokenCategoriesNotUsed(lookAheadPaths) ? tokenStructuredMatcherNoCategories : tokenStructuredMatcher;\n  return laFuncBuilder(lookAheadPaths, hasPredicates, tokenMatcher2, dynamicTokensEnabled);\n}\n__name(buildLookaheadFuncForOr, \"buildLookaheadFuncForOr\");\nfunction buildLookaheadFuncForOptionalProd(occurrence, ruleGrammar, k, dynamicTokensEnabled, prodType, lookaheadBuilder) {\n  const lookAheadPaths = getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k);\n  const tokenMatcher2 = areTokenCategoriesNotUsed(lookAheadPaths) ? tokenStructuredMatcherNoCategories : tokenStructuredMatcher;\n  return lookaheadBuilder(lookAheadPaths[0], tokenMatcher2, dynamicTokensEnabled);\n}\n__name(buildLookaheadFuncForOptionalProd, \"buildLookaheadFuncForOptionalProd\");\nfunction buildAlternativesLookAheadFunc(alts, hasPredicates, tokenMatcher2, dynamicTokensEnabled) {\n  const numOfAlts = alts.length;\n  const areAllOneTokenLookahead = every_default(alts, (currAlt) => {\n    return every_default(currAlt, (currPath) => {\n      return currPath.length === 1;\n    });\n  });\n  if (hasPredicates) {\n    return function(orAlts) {\n      const predicates = map_default(orAlts, (currAlt) => currAlt.GATE);\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n        const currPredicate = predicates[t];\n        if (currPredicate !== void 0 && currPredicate.call(this) === false) {\n          continue;\n        }\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher2(nextToken, currPath[i]) === false) {\n              continue nextPath;\n            }\n          }\n          return t;\n        }\n      }\n      return void 0;\n    };\n  } else if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    const singleTokenAlts = map_default(alts, (currAlt) => {\n      return flatten_default(currAlt);\n    });\n    const choiceToAlt = reduce_default(singleTokenAlts, (result, currAlt, idx) => {\n      forEach_default(currAlt, (currTokType) => {\n        if (!has_default(result, currTokType.tokenTypeIdx)) {\n          result[currTokType.tokenTypeIdx] = idx;\n        }\n        forEach_default(currTokType.categoryMatches, (currExtendingType) => {\n          if (!has_default(result, currExtendingType)) {\n            result[currExtendingType] = idx;\n          }\n        });\n      });\n      return result;\n    }, {});\n    return function() {\n      const nextToken = this.LA(1);\n      return choiceToAlt[nextToken.tokenTypeIdx];\n    };\n  } else {\n    return function() {\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher2(nextToken, currPath[i]) === false) {\n              continue nextPath;\n            }\n          }\n          return t;\n        }\n      }\n      return void 0;\n    };\n  }\n}\n__name(buildAlternativesLookAheadFunc, \"buildAlternativesLookAheadFunc\");\nfunction buildSingleAlternativeLookaheadFunction(alt, tokenMatcher2, dynamicTokensEnabled) {\n  const areAllOneTokenLookahead = every_default(alt, (currPath) => {\n    return currPath.length === 1;\n  });\n  const numOfPaths = alt.length;\n  if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    const singleTokensTypes = flatten_default(alt);\n    if (singleTokensTypes.length === 1 && isEmpty_default(singleTokensTypes[0].categoryMatches)) {\n      const expectedTokenType = singleTokensTypes[0];\n      const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx;\n      return function() {\n        return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n      };\n    } else {\n      const choiceToAlt = reduce_default(singleTokensTypes, (result, currTokType, idx) => {\n        result[currTokType.tokenTypeIdx] = true;\n        forEach_default(currTokType.categoryMatches, (currExtendingType) => {\n          result[currExtendingType] = true;\n        });\n        return result;\n      }, []);\n      return function() {\n        const nextToken = this.LA(1);\n        return choiceToAlt[nextToken.tokenTypeIdx] === true;\n      };\n    }\n  } else {\n    return function() {\n      nextPath: for (let j = 0; j < numOfPaths; j++) {\n        const currPath = alt[j];\n        const currPathLength = currPath.length;\n        for (let i = 0; i < currPathLength; i++) {\n          const nextToken = this.LA(i + 1);\n          if (tokenMatcher2(nextToken, currPath[i]) === false) {\n            continue nextPath;\n          }\n        }\n        return true;\n      }\n      return false;\n    };\n  }\n}\n__name(buildSingleAlternativeLookaheadFunction, \"buildSingleAlternativeLookaheadFunction\");\nvar RestDefinitionFinderWalker = class extends RestWalker {\n  static {\n    __name(this, \"RestDefinitionFinderWalker\");\n  }\n  constructor(topProd, targetOccurrence, targetProdType) {\n    super();\n    this.topProd = topProd;\n    this.targetOccurrence = targetOccurrence;\n    this.targetProdType = targetProdType;\n  }\n  startWalking() {\n    this.walk(this.topProd);\n    return this.restDef;\n  }\n  checkIsTarget(node, expectedProdType, currRest, prevRest) {\n    if (node.idx === this.targetOccurrence && this.targetProdType === expectedProdType) {\n      this.restDef = currRest.concat(prevRest);\n      return true;\n    }\n    return false;\n  }\n  walkOption(optionProd, currRest, prevRest) {\n    if (!this.checkIsTarget(optionProd, PROD_TYPE.OPTION, currRest, prevRest)) {\n      super.walkOption(optionProd, currRest, prevRest);\n    }\n  }\n  walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n    if (!this.checkIsTarget(atLeastOneProd, PROD_TYPE.REPETITION_MANDATORY, currRest, prevRest)) {\n      super.walkOption(atLeastOneProd, currRest, prevRest);\n    }\n  }\n  walkAtLeastOneSep(atLeastOneSepProd, currRest, prevRest) {\n    if (!this.checkIsTarget(atLeastOneSepProd, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, currRest, prevRest)) {\n      super.walkOption(atLeastOneSepProd, currRest, prevRest);\n    }\n  }\n  walkMany(manyProd, currRest, prevRest) {\n    if (!this.checkIsTarget(manyProd, PROD_TYPE.REPETITION, currRest, prevRest)) {\n      super.walkOption(manyProd, currRest, prevRest);\n    }\n  }\n  walkManySep(manySepProd, currRest, prevRest) {\n    if (!this.checkIsTarget(manySepProd, PROD_TYPE.REPETITION_WITH_SEPARATOR, currRest, prevRest)) {\n      super.walkOption(manySepProd, currRest, prevRest);\n    }\n  }\n};\nvar InsideDefinitionFinderVisitor = class extends GAstVisitor {\n  static {\n    __name(this, \"InsideDefinitionFinderVisitor\");\n  }\n  constructor(targetOccurrence, targetProdType, targetRef) {\n    super();\n    this.targetOccurrence = targetOccurrence;\n    this.targetProdType = targetProdType;\n    this.targetRef = targetRef;\n    this.result = [];\n  }\n  checkIsTarget(node, expectedProdName) {\n    if (node.idx === this.targetOccurrence && this.targetProdType === expectedProdName && (this.targetRef === void 0 || node === this.targetRef)) {\n      this.result = node.definition;\n    }\n  }\n  visitOption(node) {\n    this.checkIsTarget(node, PROD_TYPE.OPTION);\n  }\n  visitRepetition(node) {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION);\n  }\n  visitRepetitionMandatory(node) {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY);\n  }\n  visitRepetitionMandatoryWithSeparator(node) {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR);\n  }\n  visitRepetitionWithSeparator(node) {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_WITH_SEPARATOR);\n  }\n  visitAlternation(node) {\n    this.checkIsTarget(node, PROD_TYPE.ALTERNATION);\n  }\n};\nfunction initializeArrayOfArrays(size) {\n  const result = new Array(size);\n  for (let i = 0; i < size; i++) {\n    result[i] = [];\n  }\n  return result;\n}\n__name(initializeArrayOfArrays, \"initializeArrayOfArrays\");\nfunction pathToHashKeys(path) {\n  let keys = [\"\"];\n  for (let i = 0; i < path.length; i++) {\n    const tokType = path[i];\n    const longerKeys = [];\n    for (let j = 0; j < keys.length; j++) {\n      const currShorterKey = keys[j];\n      longerKeys.push(currShorterKey + \"_\" + tokType.tokenTypeIdx);\n      for (let t = 0; t < tokType.categoryMatches.length; t++) {\n        const categoriesKeySuffix = \"_\" + tokType.categoryMatches[t];\n        longerKeys.push(currShorterKey + categoriesKeySuffix);\n      }\n    }\n    keys = longerKeys;\n  }\n  return keys;\n}\n__name(pathToHashKeys, \"pathToHashKeys\");\nfunction isUniquePrefixHash(altKnownPathsKeys, searchPathKeys, idx) {\n  for (let currAltIdx = 0; currAltIdx < altKnownPathsKeys.length; currAltIdx++) {\n    if (currAltIdx === idx) {\n      continue;\n    }\n    const otherAltKnownPathsKeys = altKnownPathsKeys[currAltIdx];\n    for (let searchIdx = 0; searchIdx < searchPathKeys.length; searchIdx++) {\n      const searchKey = searchPathKeys[searchIdx];\n      if (otherAltKnownPathsKeys[searchKey] === true) {\n        return false;\n      }\n    }\n  }\n  return true;\n}\n__name(isUniquePrefixHash, \"isUniquePrefixHash\");\nfunction lookAheadSequenceFromAlternatives(altsDefs, k) {\n  const partialAlts = map_default(altsDefs, (currAlt) => possiblePathsFrom([currAlt], 1));\n  const finalResult = initializeArrayOfArrays(partialAlts.length);\n  const altsHashes = map_default(partialAlts, (currAltPaths) => {\n    const dict = {};\n    forEach_default(currAltPaths, (item) => {\n      const keys = pathToHashKeys(item.partialPath);\n      forEach_default(keys, (currKey) => {\n        dict[currKey] = true;\n      });\n    });\n    return dict;\n  });\n  let newData = partialAlts;\n  for (let pathLength = 1; pathLength <= k; pathLength++) {\n    const currDataset = newData;\n    newData = initializeArrayOfArrays(currDataset.length);\n    for (let altIdx = 0; altIdx < currDataset.length; altIdx++) {\n      const currAltPathsAndSuffixes = currDataset[altIdx];\n      for (let currPathIdx = 0; currPathIdx < currAltPathsAndSuffixes.length; currPathIdx++) {\n        const currPathPrefix = currAltPathsAndSuffixes[currPathIdx].partialPath;\n        const suffixDef = currAltPathsAndSuffixes[currPathIdx].suffixDef;\n        const prefixKeys = pathToHashKeys(currPathPrefix);\n        const isUnique = isUniquePrefixHash(altsHashes, prefixKeys, altIdx);\n        if (isUnique || isEmpty_default(suffixDef) || currPathPrefix.length === k) {\n          const currAltResult = finalResult[altIdx];\n          if (containsPath(currAltResult, currPathPrefix) === false) {\n            currAltResult.push(currPathPrefix);\n            for (let j = 0; j < prefixKeys.length; j++) {\n              const currKey = prefixKeys[j];\n              altsHashes[altIdx][currKey] = true;\n            }\n          }\n        } else {\n          const newPartialPathsAndSuffixes = possiblePathsFrom(suffixDef, pathLength + 1, currPathPrefix);\n          newData[altIdx] = newData[altIdx].concat(newPartialPathsAndSuffixes);\n          forEach_default(newPartialPathsAndSuffixes, (item) => {\n            const prefixKeys2 = pathToHashKeys(item.partialPath);\n            forEach_default(prefixKeys2, (key) => {\n              altsHashes[altIdx][key] = true;\n            });\n          });\n        }\n      }\n    }\n  }\n  return finalResult;\n}\n__name(lookAheadSequenceFromAlternatives, \"lookAheadSequenceFromAlternatives\");\nfunction getLookaheadPathsForOr(occurrence, ruleGrammar, k, orProd) {\n  const visitor2 = new InsideDefinitionFinderVisitor(occurrence, PROD_TYPE.ALTERNATION, orProd);\n  ruleGrammar.accept(visitor2);\n  return lookAheadSequenceFromAlternatives(visitor2.result, k);\n}\n__name(getLookaheadPathsForOr, \"getLookaheadPathsForOr\");\nfunction getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k) {\n  const insideDefVisitor = new InsideDefinitionFinderVisitor(occurrence, prodType);\n  ruleGrammar.accept(insideDefVisitor);\n  const insideDef = insideDefVisitor.result;\n  const afterDefWalker = new RestDefinitionFinderWalker(ruleGrammar, occurrence, prodType);\n  const afterDef = afterDefWalker.startWalking();\n  const insideFlat = new Alternative({ definition: insideDef });\n  const afterFlat = new Alternative({ definition: afterDef });\n  return lookAheadSequenceFromAlternatives([insideFlat, afterFlat], k);\n}\n__name(getLookaheadPathsForOptionalProd, \"getLookaheadPathsForOptionalProd\");\nfunction containsPath(alternative, searchPath) {\n  compareOtherPath: for (let i = 0; i < alternative.length; i++) {\n    const otherPath = alternative[i];\n    if (otherPath.length !== searchPath.length) {\n      continue;\n    }\n    for (let j = 0; j < otherPath.length; j++) {\n      const searchTok = searchPath[j];\n      const otherTok = otherPath[j];\n      const matchingTokens = searchTok === otherTok || otherTok.categoryMatchesMap[searchTok.tokenTypeIdx] !== void 0;\n      if (matchingTokens === false) {\n        continue compareOtherPath;\n      }\n    }\n    return true;\n  }\n  return false;\n}\n__name(containsPath, \"containsPath\");\nfunction isStrictPrefixOfPath(prefix, other) {\n  return prefix.length < other.length && every_default(prefix, (tokType, idx) => {\n    const otherTokType = other[idx];\n    return tokType === otherTokType || otherTokType.categoryMatchesMap[tokType.tokenTypeIdx];\n  });\n}\n__name(isStrictPrefixOfPath, \"isStrictPrefixOfPath\");\nfunction areTokenCategoriesNotUsed(lookAheadPaths) {\n  return every_default(lookAheadPaths, (singleAltPaths) => every_default(singleAltPaths, (singlePath) => every_default(singlePath, (token) => isEmpty_default(token.categoryMatches))));\n}\n__name(areTokenCategoriesNotUsed, \"areTokenCategoriesNotUsed\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/checks.js\nfunction validateLookahead(options) {\n  const lookaheadValidationErrorMessages = options.lookaheadStrategy.validate({\n    rules: options.rules,\n    tokenTypes: options.tokenTypes,\n    grammarName: options.grammarName\n  });\n  return map_default(lookaheadValidationErrorMessages, (errorMessage) => Object.assign({ type: ParserDefinitionErrorType.CUSTOM_LOOKAHEAD_VALIDATION }, errorMessage));\n}\n__name(validateLookahead, \"validateLookahead\");\nfunction validateGrammar(topLevels, tokenTypes, errMsgProvider, grammarName) {\n  const duplicateErrors = flatMap_default(topLevels, (currTopLevel) => validateDuplicateProductions(currTopLevel, errMsgProvider));\n  const termsNamespaceConflictErrors = checkTerminalAndNoneTerminalsNameSpace(topLevels, tokenTypes, errMsgProvider);\n  const tooManyAltsErrors = flatMap_default(topLevels, (curRule) => validateTooManyAlts(curRule, errMsgProvider));\n  const duplicateRulesError = flatMap_default(topLevels, (curRule) => validateRuleDoesNotAlreadyExist(curRule, topLevels, grammarName, errMsgProvider));\n  return duplicateErrors.concat(termsNamespaceConflictErrors, tooManyAltsErrors, duplicateRulesError);\n}\n__name(validateGrammar, \"validateGrammar\");\nfunction validateDuplicateProductions(topLevelRule, errMsgProvider) {\n  const collectorVisitor2 = new OccurrenceValidationCollector();\n  topLevelRule.accept(collectorVisitor2);\n  const allRuleProductions = collectorVisitor2.allProductions;\n  const productionGroups = groupBy_default(allRuleProductions, identifyProductionForDuplicates);\n  const duplicates = pickBy_default(productionGroups, (currGroup) => {\n    return currGroup.length > 1;\n  });\n  const errors = map_default(values_default(duplicates), (currDuplicates) => {\n    const firstProd = head_default(currDuplicates);\n    const msg = errMsgProvider.buildDuplicateFoundError(topLevelRule, currDuplicates);\n    const dslName = getProductionDslName(firstProd);\n    const defError = {\n      message: msg,\n      type: ParserDefinitionErrorType.DUPLICATE_PRODUCTIONS,\n      ruleName: topLevelRule.name,\n      dslName,\n      occurrence: firstProd.idx\n    };\n    const param = getExtraProductionArgument(firstProd);\n    if (param) {\n      defError.parameter = param;\n    }\n    return defError;\n  });\n  return errors;\n}\n__name(validateDuplicateProductions, \"validateDuplicateProductions\");\nfunction identifyProductionForDuplicates(prod) {\n  return `${getProductionDslName(prod)}_#_${prod.idx}_#_${getExtraProductionArgument(prod)}`;\n}\n__name(identifyProductionForDuplicates, \"identifyProductionForDuplicates\");\nfunction getExtraProductionArgument(prod) {\n  if (prod instanceof Terminal) {\n    return prod.terminalType.name;\n  } else if (prod instanceof NonTerminal) {\n    return prod.nonTerminalName;\n  } else {\n    return \"\";\n  }\n}\n__name(getExtraProductionArgument, \"getExtraProductionArgument\");\nvar OccurrenceValidationCollector = class extends GAstVisitor {\n  static {\n    __name(this, \"OccurrenceValidationCollector\");\n  }\n  constructor() {\n    super(...arguments);\n    this.allProductions = [];\n  }\n  visitNonTerminal(subrule) {\n    this.allProductions.push(subrule);\n  }\n  visitOption(option2) {\n    this.allProductions.push(option2);\n  }\n  visitRepetitionWithSeparator(manySep) {\n    this.allProductions.push(manySep);\n  }\n  visitRepetitionMandatory(atLeastOne) {\n    this.allProductions.push(atLeastOne);\n  }\n  visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n    this.allProductions.push(atLeastOneSep);\n  }\n  visitRepetition(many) {\n    this.allProductions.push(many);\n  }\n  visitAlternation(or) {\n    this.allProductions.push(or);\n  }\n  visitTerminal(terminal) {\n    this.allProductions.push(terminal);\n  }\n};\nfunction validateRuleDoesNotAlreadyExist(rule, allRules, className, errMsgProvider) {\n  const errors = [];\n  const occurrences = reduce_default(allRules, (result, curRule) => {\n    if (curRule.name === rule.name) {\n      return result + 1;\n    }\n    return result;\n  }, 0);\n  if (occurrences > 1) {\n    const errMsg = errMsgProvider.buildDuplicateRuleNameError({\n      topLevelRule: rule,\n      grammarName: className\n    });\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n      ruleName: rule.name\n    });\n  }\n  return errors;\n}\n__name(validateRuleDoesNotAlreadyExist, \"validateRuleDoesNotAlreadyExist\");\nfunction validateRuleIsOverridden(ruleName, definedRulesNames, className) {\n  const errors = [];\n  let errMsg;\n  if (!includes_default(definedRulesNames, ruleName)) {\n    errMsg = `Invalid rule override, rule: ->${ruleName}<- cannot be overridden in the grammar: ->${className}<-as it is not defined in any of the super grammars `;\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.INVALID_RULE_OVERRIDE,\n      ruleName\n    });\n  }\n  return errors;\n}\n__name(validateRuleIsOverridden, \"validateRuleIsOverridden\");\nfunction validateNoLeftRecursion(topRule, currRule, errMsgProvider, path = []) {\n  const errors = [];\n  const nextNonTerminals = getFirstNoneTerminal(currRule.definition);\n  if (isEmpty_default(nextNonTerminals)) {\n    return [];\n  } else {\n    const ruleName = topRule.name;\n    const foundLeftRecursion = includes_default(nextNonTerminals, topRule);\n    if (foundLeftRecursion) {\n      errors.push({\n        message: errMsgProvider.buildLeftRecursionError({\n          topLevelRule: topRule,\n          leftRecursionPath: path\n        }),\n        type: ParserDefinitionErrorType.LEFT_RECURSION,\n        ruleName\n      });\n    }\n    const validNextSteps = difference_default(nextNonTerminals, path.concat([topRule]));\n    const errorsFromNextSteps = flatMap_default(validNextSteps, (currRefRule) => {\n      const newPath = clone_default(path);\n      newPath.push(currRefRule);\n      return validateNoLeftRecursion(topRule, currRefRule, errMsgProvider, newPath);\n    });\n    return errors.concat(errorsFromNextSteps);\n  }\n}\n__name(validateNoLeftRecursion, \"validateNoLeftRecursion\");\nfunction getFirstNoneTerminal(definition) {\n  let result = [];\n  if (isEmpty_default(definition)) {\n    return result;\n  }\n  const firstProd = head_default(definition);\n  if (firstProd instanceof NonTerminal) {\n    result.push(firstProd.referencedRule);\n  } else if (firstProd instanceof Alternative || firstProd instanceof Option || firstProd instanceof RepetitionMandatory || firstProd instanceof RepetitionMandatoryWithSeparator || firstProd instanceof RepetitionWithSeparator || firstProd instanceof Repetition) {\n    result = result.concat(getFirstNoneTerminal(firstProd.definition));\n  } else if (firstProd instanceof Alternation) {\n    result = flatten_default(map_default(firstProd.definition, (currSubDef) => getFirstNoneTerminal(currSubDef.definition)));\n  } else if (firstProd instanceof Terminal) {\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n  const isFirstOptional = isOptionalProd(firstProd);\n  const hasMore = definition.length > 1;\n  if (isFirstOptional && hasMore) {\n    const rest = drop_default(definition);\n    return result.concat(getFirstNoneTerminal(rest));\n  } else {\n    return result;\n  }\n}\n__name(getFirstNoneTerminal, \"getFirstNoneTerminal\");\nvar OrCollector = class extends GAstVisitor {\n  static {\n    __name(this, \"OrCollector\");\n  }\n  constructor() {\n    super(...arguments);\n    this.alternations = [];\n  }\n  visitAlternation(node) {\n    this.alternations.push(node);\n  }\n};\nfunction validateEmptyOrAlternative(topLevelRule, errMsgProvider) {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n  const errors = flatMap_default(ors, (currOr) => {\n    const exceptLast = dropRight_default(currOr.definition);\n    return flatMap_default(exceptLast, (currAlternative, currAltIdx) => {\n      const possibleFirstInAlt = nextPossibleTokensAfter([currAlternative], [], tokenStructuredMatcher, 1);\n      if (isEmpty_default(possibleFirstInAlt)) {\n        return [\n          {\n            message: errMsgProvider.buildEmptyAlternationError({\n              topLevelRule,\n              alternation: currOr,\n              emptyChoiceIdx: currAltIdx\n            }),\n            type: ParserDefinitionErrorType.NONE_LAST_EMPTY_ALT,\n            ruleName: topLevelRule.name,\n            occurrence: currOr.idx,\n            alternative: currAltIdx + 1\n          }\n        ];\n      } else {\n        return [];\n      }\n    });\n  });\n  return errors;\n}\n__name(validateEmptyOrAlternative, \"validateEmptyOrAlternative\");\nfunction validateAmbiguousAlternationAlternatives(topLevelRule, globalMaxLookahead, errMsgProvider) {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  let ors = orCollector.alternations;\n  ors = reject_default(ors, (currOr) => currOr.ignoreAmbiguities === true);\n  const errors = flatMap_default(ors, (currOr) => {\n    const currOccurrence = currOr.idx;\n    const actualMaxLookahead = currOr.maxLookahead || globalMaxLookahead;\n    const alternatives = getLookaheadPathsForOr(currOccurrence, topLevelRule, actualMaxLookahead, currOr);\n    const altsAmbiguityErrors = checkAlternativesAmbiguities(alternatives, currOr, topLevelRule, errMsgProvider);\n    const altsPrefixAmbiguityErrors = checkPrefixAlternativesAmbiguities(alternatives, currOr, topLevelRule, errMsgProvider);\n    return altsAmbiguityErrors.concat(altsPrefixAmbiguityErrors);\n  });\n  return errors;\n}\n__name(validateAmbiguousAlternationAlternatives, \"validateAmbiguousAlternationAlternatives\");\nvar RepetitionCollector = class extends GAstVisitor {\n  static {\n    __name(this, \"RepetitionCollector\");\n  }\n  constructor() {\n    super(...arguments);\n    this.allProductions = [];\n  }\n  visitRepetitionWithSeparator(manySep) {\n    this.allProductions.push(manySep);\n  }\n  visitRepetitionMandatory(atLeastOne) {\n    this.allProductions.push(atLeastOne);\n  }\n  visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n    this.allProductions.push(atLeastOneSep);\n  }\n  visitRepetition(many) {\n    this.allProductions.push(many);\n  }\n};\nfunction validateTooManyAlts(topLevelRule, errMsgProvider) {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n  const errors = flatMap_default(ors, (currOr) => {\n    if (currOr.definition.length > 255) {\n      return [\n        {\n          message: errMsgProvider.buildTooManyAlternativesError({\n            topLevelRule,\n            alternation: currOr\n          }),\n          type: ParserDefinitionErrorType.TOO_MANY_ALTS,\n          ruleName: topLevelRule.name,\n          occurrence: currOr.idx\n        }\n      ];\n    } else {\n      return [];\n    }\n  });\n  return errors;\n}\n__name(validateTooManyAlts, \"validateTooManyAlts\");\nfunction validateSomeNonEmptyLookaheadPath(topLevelRules, maxLookahead, errMsgProvider) {\n  const errors = [];\n  forEach_default(topLevelRules, (currTopRule) => {\n    const collectorVisitor2 = new RepetitionCollector();\n    currTopRule.accept(collectorVisitor2);\n    const allRuleProductions = collectorVisitor2.allProductions;\n    forEach_default(allRuleProductions, (currProd) => {\n      const prodType = getProdType(currProd);\n      const actualMaxLookahead = currProd.maxLookahead || maxLookahead;\n      const currOccurrence = currProd.idx;\n      const paths = getLookaheadPathsForOptionalProd(currOccurrence, currTopRule, prodType, actualMaxLookahead);\n      const pathsInsideProduction = paths[0];\n      if (isEmpty_default(flatten_default(pathsInsideProduction))) {\n        const errMsg = errMsgProvider.buildEmptyRepetitionError({\n          topLevelRule: currTopRule,\n          repetition: currProd\n        });\n        errors.push({\n          message: errMsg,\n          type: ParserDefinitionErrorType.NO_NON_EMPTY_LOOKAHEAD,\n          ruleName: currTopRule.name\n        });\n      }\n    });\n  });\n  return errors;\n}\n__name(validateSomeNonEmptyLookaheadPath, \"validateSomeNonEmptyLookaheadPath\");\nfunction checkAlternativesAmbiguities(alternatives, alternation2, rule, errMsgProvider) {\n  const foundAmbiguousPaths = [];\n  const identicalAmbiguities = reduce_default(alternatives, (result, currAlt, currAltIdx) => {\n    if (alternation2.definition[currAltIdx].ignoreAmbiguities === true) {\n      return result;\n    }\n    forEach_default(currAlt, (currPath) => {\n      const altsCurrPathAppearsIn = [currAltIdx];\n      forEach_default(alternatives, (currOtherAlt, currOtherAltIdx) => {\n        if (currAltIdx !== currOtherAltIdx && containsPath(currOtherAlt, currPath) && // ignore (skip) ambiguities with this \"other\" alternative\n        alternation2.definition[currOtherAltIdx].ignoreAmbiguities !== true) {\n          altsCurrPathAppearsIn.push(currOtherAltIdx);\n        }\n      });\n      if (altsCurrPathAppearsIn.length > 1 && !containsPath(foundAmbiguousPaths, currPath)) {\n        foundAmbiguousPaths.push(currPath);\n        result.push({\n          alts: altsCurrPathAppearsIn,\n          path: currPath\n        });\n      }\n    });\n    return result;\n  }, []);\n  const currErrors = map_default(identicalAmbiguities, (currAmbDescriptor) => {\n    const ambgIndices = map_default(currAmbDescriptor.alts, (currAltIdx) => currAltIdx + 1);\n    const currMessage = errMsgProvider.buildAlternationAmbiguityError({\n      topLevelRule: rule,\n      alternation: alternation2,\n      ambiguityIndices: ambgIndices,\n      prefixPath: currAmbDescriptor.path\n    });\n    return {\n      message: currMessage,\n      type: ParserDefinitionErrorType.AMBIGUOUS_ALTS,\n      ruleName: rule.name,\n      occurrence: alternation2.idx,\n      alternatives: currAmbDescriptor.alts\n    };\n  });\n  return currErrors;\n}\n__name(checkAlternativesAmbiguities, \"checkAlternativesAmbiguities\");\nfunction checkPrefixAlternativesAmbiguities(alternatives, alternation2, rule, errMsgProvider) {\n  const pathsAndIndices = reduce_default(alternatives, (result, currAlt, idx) => {\n    const currPathsAndIdx = map_default(currAlt, (currPath) => {\n      return { idx, path: currPath };\n    });\n    return result.concat(currPathsAndIdx);\n  }, []);\n  const errors = compact_default(flatMap_default(pathsAndIndices, (currPathAndIdx) => {\n    const alternativeGast = alternation2.definition[currPathAndIdx.idx];\n    if (alternativeGast.ignoreAmbiguities === true) {\n      return [];\n    }\n    const targetIdx = currPathAndIdx.idx;\n    const targetPath = currPathAndIdx.path;\n    const prefixAmbiguitiesPathsAndIndices = filter_default(pathsAndIndices, (searchPathAndIdx) => {\n      return (\n        // ignore (skip) ambiguities with this \"other\" alternative\n        alternation2.definition[searchPathAndIdx.idx].ignoreAmbiguities !== true && searchPathAndIdx.idx < targetIdx && // checking for strict prefix because identical lookaheads\n        // will be be detected using a different validation.\n        isStrictPrefixOfPath(searchPathAndIdx.path, targetPath)\n      );\n    });\n    const currPathPrefixErrors = map_default(prefixAmbiguitiesPathsAndIndices, (currAmbPathAndIdx) => {\n      const ambgIndices = [currAmbPathAndIdx.idx + 1, targetIdx + 1];\n      const occurrence = alternation2.idx === 0 ? \"\" : alternation2.idx;\n      const message = errMsgProvider.buildAlternationPrefixAmbiguityError({\n        topLevelRule: rule,\n        alternation: alternation2,\n        ambiguityIndices: ambgIndices,\n        prefixPath: currAmbPathAndIdx.path\n      });\n      return {\n        message,\n        type: ParserDefinitionErrorType.AMBIGUOUS_PREFIX_ALTS,\n        ruleName: rule.name,\n        occurrence,\n        alternatives: ambgIndices\n      };\n    });\n    return currPathPrefixErrors;\n  }));\n  return errors;\n}\n__name(checkPrefixAlternativesAmbiguities, \"checkPrefixAlternativesAmbiguities\");\nfunction checkTerminalAndNoneTerminalsNameSpace(topLevels, tokenTypes, errMsgProvider) {\n  const errors = [];\n  const tokenNames = map_default(tokenTypes, (currToken) => currToken.name);\n  forEach_default(topLevels, (currRule) => {\n    const currRuleName = currRule.name;\n    if (includes_default(tokenNames, currRuleName)) {\n      const errMsg = errMsgProvider.buildNamespaceConflictError(currRule);\n      errors.push({\n        message: errMsg,\n        type: ParserDefinitionErrorType.CONFLICT_TOKENS_RULES_NAMESPACE,\n        ruleName: currRuleName\n      });\n    }\n  });\n  return errors;\n}\n__name(checkTerminalAndNoneTerminalsNameSpace, \"checkTerminalAndNoneTerminalsNameSpace\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/gast/gast_resolver_public.js\nfunction resolveGrammar2(options) {\n  const actualOptions = defaults_default(options, {\n    errMsgProvider: defaultGrammarResolverErrorProvider\n  });\n  const topRulesTable = {};\n  forEach_default(options.rules, (rule) => {\n    topRulesTable[rule.name] = rule;\n  });\n  return resolveGrammar(topRulesTable, actualOptions.errMsgProvider);\n}\n__name(resolveGrammar2, \"resolveGrammar\");\nfunction validateGrammar2(options) {\n  options = defaults_default(options, {\n    errMsgProvider: defaultGrammarValidatorErrorProvider\n  });\n  return validateGrammar(options.rules, options.tokenTypes, options.errMsgProvider, options.grammarName);\n}\n__name(validateGrammar2, \"validateGrammar\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/exceptions_public.js\nvar MISMATCHED_TOKEN_EXCEPTION = \"MismatchedTokenException\";\nvar NO_VIABLE_ALT_EXCEPTION = \"NoViableAltException\";\nvar EARLY_EXIT_EXCEPTION = \"EarlyExitException\";\nvar NOT_ALL_INPUT_PARSED_EXCEPTION = \"NotAllInputParsedException\";\nvar RECOGNITION_EXCEPTION_NAMES = [\n  MISMATCHED_TOKEN_EXCEPTION,\n  NO_VIABLE_ALT_EXCEPTION,\n  EARLY_EXIT_EXCEPTION,\n  NOT_ALL_INPUT_PARSED_EXCEPTION\n];\nObject.freeze(RECOGNITION_EXCEPTION_NAMES);\nfunction isRecognitionException(error) {\n  return includes_default(RECOGNITION_EXCEPTION_NAMES, error.name);\n}\n__name(isRecognitionException, \"isRecognitionException\");\nvar RecognitionException = class extends Error {\n  static {\n    __name(this, \"RecognitionException\");\n  }\n  constructor(message, token) {\n    super(message);\n    this.token = token;\n    this.resyncedTokens = [];\n    Object.setPrototypeOf(this, new.target.prototype);\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n};\nvar MismatchedTokenException = class extends RecognitionException {\n  static {\n    __name(this, \"MismatchedTokenException\");\n  }\n  constructor(message, token, previousToken) {\n    super(message, token);\n    this.previousToken = previousToken;\n    this.name = MISMATCHED_TOKEN_EXCEPTION;\n  }\n};\nvar NoViableAltException = class extends RecognitionException {\n  static {\n    __name(this, \"NoViableAltException\");\n  }\n  constructor(message, token, previousToken) {\n    super(message, token);\n    this.previousToken = previousToken;\n    this.name = NO_VIABLE_ALT_EXCEPTION;\n  }\n};\nvar NotAllInputParsedException = class extends RecognitionException {\n  static {\n    __name(this, \"NotAllInputParsedException\");\n  }\n  constructor(message, token) {\n    super(message, token);\n    this.name = NOT_ALL_INPUT_PARSED_EXCEPTION;\n  }\n};\nvar EarlyExitException = class extends RecognitionException {\n  static {\n    __name(this, \"EarlyExitException\");\n  }\n  constructor(message, token, previousToken) {\n    super(message, token);\n    this.previousToken = previousToken;\n    this.name = EARLY_EXIT_EXCEPTION;\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/recoverable.js\nvar EOF_FOLLOW_KEY = {};\nvar IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\nvar InRuleRecoveryException = class extends Error {\n  static {\n    __name(this, \"InRuleRecoveryException\");\n  }\n  constructor(message) {\n    super(message);\n    this.name = IN_RULE_RECOVERY_EXCEPTION;\n  }\n};\nvar Recoverable = class {\n  static {\n    __name(this, \"Recoverable\");\n  }\n  initRecoverable(config) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n    this.recoveryEnabled = has_default(config, \"recoveryEnabled\") ? config.recoveryEnabled : DEFAULT_PARSER_CONFIG.recoveryEnabled;\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  }\n  getTokenToInsert(tokType) {\n    const tokToInsert = createTokenInstance(tokType, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  }\n  canTokenTypeBeInsertedInRecovery(tokType) {\n    return true;\n  }\n  canTokenTypeBeDeletedInRecovery(tokType) {\n    return true;\n  }\n  tryInRepetitionRecovery(grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n    const reSyncTokType = this.findReSyncTokenType();\n    const savedLexerState = this.exportLexerState();\n    const resyncedTokens = [];\n    let passedResyncPoint = false;\n    const nextTokenWithoutResync = this.LA(1);\n    let currToken = this.LA(1);\n    const generateErrorMessage = /* @__PURE__ */ __name(() => {\n      const previousToken = this.LA(0);\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName()\n      });\n      const error = new MismatchedTokenException(msg, nextTokenWithoutResync, this.LA(0));\n      error.resyncedTokens = dropRight_default(resyncedTokens);\n      this.SAVE_ERROR(error);\n    }, \"generateErrorMessage\");\n    while (!passedResyncPoint) {\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return;\n      } else if (lookAheadFunc.call(this)) {\n        generateErrorMessage();\n        grammarRule.apply(this, grammarRuleArgs);\n        return;\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    }\n    this.importLexerState(savedLexerState);\n  }\n  shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck) {\n    if (notStuck === false) {\n      return false;\n    }\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    }\n    if (this.isBackTracking()) {\n      return false;\n    }\n    if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n      return false;\n    }\n    return true;\n  }\n  // Error Recovery functionality\n  getFollowsForInRuleRecovery(tokType, tokIdxInRule) {\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    const follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  }\n  tryInRuleRecovery(expectedTokType, follows) {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      const tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      const nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  }\n  canPerformInRuleRecovery(expectedToken, follows) {\n    return this.canRecoverWithSingleTokenInsertion(expectedToken, follows) || this.canRecoverWithSingleTokenDeletion(expectedToken);\n  }\n  canRecoverWithSingleTokenInsertion(expectedTokType, follows) {\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    }\n    if (isEmpty_default(follows)) {\n      return false;\n    }\n    const mismatchedTok = this.LA(1);\n    const isMisMatchedTokInFollows = find_default(follows, (possibleFollowsTokType) => {\n      return this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n    }) !== void 0;\n    return isMisMatchedTokInFollows;\n  }\n  canRecoverWithSingleTokenDeletion(expectedTokType) {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false;\n    }\n    const isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n    return isNextTokenWhatIsExpected;\n  }\n  isInCurrentRuleReSyncSet(tokenTypeIdx) {\n    const followKey = this.getCurrFollowKey();\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return includes_default(currentRuleReSyncSet, tokenTypeIdx);\n  }\n  findReSyncTokenType() {\n    const allPossibleReSyncTokTypes = this.flattenFollowSet();\n    let nextToken = this.LA(1);\n    let k = 2;\n    while (true) {\n      const foundMatch = find_default(allPossibleReSyncTokTypes, (resyncTokType) => {\n        const canMatch = tokenMatcher(nextToken, resyncTokType);\n        return canMatch;\n      });\n      if (foundMatch !== void 0) {\n        return foundMatch;\n      }\n      nextToken = this.LA(k);\n      k++;\n    }\n  }\n  getCurrFollowKey() {\n    if (this.RULE_STACK.length === 1) {\n      return EOF_FOLLOW_KEY;\n    }\n    const currRuleShortName = this.getLastExplicitRuleShortName();\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName();\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    };\n  }\n  buildFullFollowKeyStack() {\n    const explicitRuleStack = this.RULE_STACK;\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return map_default(explicitRuleStack, (ruleName, idx) => {\n      if (idx === 0) {\n        return EOF_FOLLOW_KEY;\n      }\n      return {\n        ruleName: this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      };\n    });\n  }\n  flattenFollowSet() {\n    const followStack = map_default(this.buildFullFollowKeyStack(), (currKey) => {\n      return this.getFollowSetFromFollowKey(currKey);\n    });\n    return flatten_default(followStack);\n  }\n  getFollowSetFromFollowKey(followKey) {\n    if (followKey === EOF_FOLLOW_KEY) {\n      return [EOF];\n    }\n    const followName = followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule;\n    return this.resyncFollows[followName];\n  }\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  addToResyncTokens(token, resyncTokens) {\n    if (!this.tokenMatcher(token, EOF)) {\n      resyncTokens.push(token);\n    }\n    return resyncTokens;\n  }\n  reSyncTo(tokType) {\n    const resyncedTokens = [];\n    let nextTok = this.LA(1);\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    }\n    return dropRight_default(resyncedTokens);\n  }\n  attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n  }\n  getCurrentGrammarPath(tokType, tokIdxInRule) {\n    const pathRuleStack = this.getHumanReadableRuleStack();\n    const pathOccurrenceStack = clone_default(this.RULE_OCCURRENCE_STACK);\n    const grammarPath = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    };\n    return grammarPath;\n  }\n  getHumanReadableRuleStack() {\n    return map_default(this.RULE_STACK, (currShortName) => this.shortRuleNameToFullName(currShortName));\n  }\n};\nfunction attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  let firstAfterRepInfo = this.firstAfterRepMap[key];\n  if (firstAfterRepInfo === void 0) {\n    const currRuleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[currRuleName];\n    const walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n  let expectTokAfterLastMatch = firstAfterRepInfo.token;\n  let nextTokIdx = firstAfterRepInfo.occurrence;\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule;\n  if (this.RULE_STACK.length === 1 && isEndOfRule && expectTokAfterLastMatch === void 0) {\n    expectTokAfterLastMatch = EOF;\n    nextTokIdx = 1;\n  }\n  if (expectTokAfterLastMatch === void 0 || nextTokIdx === void 0) {\n    return;\n  }\n  if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck)) {\n    this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n  }\n}\n__name(attemptInRepetitionRecovery, \"attemptInRepetitionRecovery\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/keys.js\nvar BITS_FOR_METHOD_TYPE = 4;\nvar BITS_FOR_OCCURRENCE_IDX = 8;\nvar BITS_FOR_ALT_IDX = 8;\nvar OR_IDX = 1 << BITS_FOR_OCCURRENCE_IDX;\nvar OPTION_IDX = 2 << BITS_FOR_OCCURRENCE_IDX;\nvar MANY_IDX = 3 << BITS_FOR_OCCURRENCE_IDX;\nvar AT_LEAST_ONE_IDX = 4 << BITS_FOR_OCCURRENCE_IDX;\nvar MANY_SEP_IDX = 5 << BITS_FOR_OCCURRENCE_IDX;\nvar AT_LEAST_ONE_SEP_IDX = 6 << BITS_FOR_OCCURRENCE_IDX;\nfunction getKeyForAutomaticLookahead(ruleIdx, dslMethodIdx, occurrence) {\n  return occurrence | dslMethodIdx | ruleIdx;\n}\n__name(getKeyForAutomaticLookahead, \"getKeyForAutomaticLookahead\");\nvar BITS_START_FOR_ALT_IDX = 32 - BITS_FOR_ALT_IDX;\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/grammar/llk_lookahead.js\nvar LLkLookaheadStrategy = class {\n  static {\n    __name(this, \"LLkLookaheadStrategy\");\n  }\n  constructor(options) {\n    var _a;\n    this.maxLookahead = (_a = options === null || options === void 0 ? void 0 : options.maxLookahead) !== null && _a !== void 0 ? _a : DEFAULT_PARSER_CONFIG.maxLookahead;\n  }\n  validate(options) {\n    const leftRecursionErrors = this.validateNoLeftRecursion(options.rules);\n    if (isEmpty_default(leftRecursionErrors)) {\n      const emptyAltErrors = this.validateEmptyOrAlternatives(options.rules);\n      const ambiguousAltsErrors = this.validateAmbiguousAlternationAlternatives(options.rules, this.maxLookahead);\n      const emptyRepetitionErrors = this.validateSomeNonEmptyLookaheadPath(options.rules, this.maxLookahead);\n      const allErrors = [\n        ...leftRecursionErrors,\n        ...emptyAltErrors,\n        ...ambiguousAltsErrors,\n        ...emptyRepetitionErrors\n      ];\n      return allErrors;\n    }\n    return leftRecursionErrors;\n  }\n  validateNoLeftRecursion(rules) {\n    return flatMap_default(rules, (currTopRule) => validateNoLeftRecursion(currTopRule, currTopRule, defaultGrammarValidatorErrorProvider));\n  }\n  validateEmptyOrAlternatives(rules) {\n    return flatMap_default(rules, (currTopRule) => validateEmptyOrAlternative(currTopRule, defaultGrammarValidatorErrorProvider));\n  }\n  validateAmbiguousAlternationAlternatives(rules, maxLookahead) {\n    return flatMap_default(rules, (currTopRule) => validateAmbiguousAlternationAlternatives(currTopRule, maxLookahead, defaultGrammarValidatorErrorProvider));\n  }\n  validateSomeNonEmptyLookaheadPath(rules, maxLookahead) {\n    return validateSomeNonEmptyLookaheadPath(rules, maxLookahead, defaultGrammarValidatorErrorProvider);\n  }\n  buildLookaheadForAlternation(options) {\n    return buildLookaheadFuncForOr(options.prodOccurrence, options.rule, options.maxLookahead, options.hasPredicates, options.dynamicTokensEnabled, buildAlternativesLookAheadFunc);\n  }\n  buildLookaheadForOptional(options) {\n    return buildLookaheadFuncForOptionalProd(options.prodOccurrence, options.rule, options.maxLookahead, options.dynamicTokensEnabled, getProdType(options.prodType), buildSingleAlternativeLookaheadFunction);\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/looksahead.js\nvar LooksAhead = class {\n  static {\n    __name(this, \"LooksAhead\");\n  }\n  initLooksAhead(config) {\n    this.dynamicTokensEnabled = has_default(config, \"dynamicTokensEnabled\") ? config.dynamicTokensEnabled : DEFAULT_PARSER_CONFIG.dynamicTokensEnabled;\n    this.maxLookahead = has_default(config, \"maxLookahead\") ? config.maxLookahead : DEFAULT_PARSER_CONFIG.maxLookahead;\n    this.lookaheadStrategy = has_default(config, \"lookaheadStrategy\") ? config.lookaheadStrategy : new LLkLookaheadStrategy({ maxLookahead: this.maxLookahead });\n    this.lookAheadFuncsCache = /* @__PURE__ */ new Map();\n  }\n  preComputeLookaheadFunctions(rules) {\n    forEach_default(rules, (currRule) => {\n      this.TRACE_INIT(`${currRule.name} Rule Lookahead`, () => {\n        const { alternation: alternation2, repetition: repetition2, option: option2, repetitionMandatory: repetitionMandatory2, repetitionMandatoryWithSeparator, repetitionWithSeparator } = collectMethods(currRule);\n        forEach_default(alternation2, (currProd) => {\n          const prodIdx = currProd.idx === 0 ? \"\" : currProd.idx;\n          this.TRACE_INIT(`${getProductionDslName(currProd)}${prodIdx}`, () => {\n            const laFunc = this.lookaheadStrategy.buildLookaheadForAlternation({\n              prodOccurrence: currProd.idx,\n              rule: currRule,\n              maxLookahead: currProd.maxLookahead || this.maxLookahead,\n              hasPredicates: currProd.hasPredicates,\n              dynamicTokensEnabled: this.dynamicTokensEnabled\n            });\n            const key = getKeyForAutomaticLookahead(this.fullRuleNameToShort[currRule.name], OR_IDX, currProd.idx);\n            this.setLaFuncCache(key, laFunc);\n          });\n        });\n        forEach_default(repetition2, (currProd) => {\n          this.computeLookaheadFunc(currRule, currProd.idx, MANY_IDX, \"Repetition\", currProd.maxLookahead, getProductionDslName(currProd));\n        });\n        forEach_default(option2, (currProd) => {\n          this.computeLookaheadFunc(currRule, currProd.idx, OPTION_IDX, \"Option\", currProd.maxLookahead, getProductionDslName(currProd));\n        });\n        forEach_default(repetitionMandatory2, (currProd) => {\n          this.computeLookaheadFunc(currRule, currProd.idx, AT_LEAST_ONE_IDX, \"RepetitionMandatory\", currProd.maxLookahead, getProductionDslName(currProd));\n        });\n        forEach_default(repetitionMandatoryWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(currRule, currProd.idx, AT_LEAST_ONE_SEP_IDX, \"RepetitionMandatoryWithSeparator\", currProd.maxLookahead, getProductionDslName(currProd));\n        });\n        forEach_default(repetitionWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(currRule, currProd.idx, MANY_SEP_IDX, \"RepetitionWithSeparator\", currProd.maxLookahead, getProductionDslName(currProd));\n        });\n      });\n    });\n  }\n  computeLookaheadFunc(rule, prodOccurrence, prodKey, prodType, prodMaxLookahead, dslMethodName) {\n    this.TRACE_INIT(`${dslMethodName}${prodOccurrence === 0 ? \"\" : prodOccurrence}`, () => {\n      const laFunc = this.lookaheadStrategy.buildLookaheadForOptional({\n        prodOccurrence,\n        rule,\n        maxLookahead: prodMaxLookahead || this.maxLookahead,\n        dynamicTokensEnabled: this.dynamicTokensEnabled,\n        prodType\n      });\n      const key = getKeyForAutomaticLookahead(this.fullRuleNameToShort[rule.name], prodKey, prodOccurrence);\n      this.setLaFuncCache(key, laFunc);\n    });\n  }\n  // this actually returns a number, but it is always used as a string (object prop key)\n  getKeyForAutomaticLookahead(dslMethodIdx, occurrence) {\n    const currRuleShortName = this.getLastExplicitRuleShortName();\n    return getKeyForAutomaticLookahead(currRuleShortName, dslMethodIdx, occurrence);\n  }\n  getLaFuncFromCache(key) {\n    return this.lookAheadFuncsCache.get(key);\n  }\n  /* istanbul ignore next */\n  setLaFuncCache(key, value) {\n    this.lookAheadFuncsCache.set(key, value);\n  }\n};\nvar DslMethodsCollectorVisitor = class extends GAstVisitor {\n  static {\n    __name(this, \"DslMethodsCollectorVisitor\");\n  }\n  constructor() {\n    super(...arguments);\n    this.dslMethods = {\n      option: [],\n      alternation: [],\n      repetition: [],\n      repetitionWithSeparator: [],\n      repetitionMandatory: [],\n      repetitionMandatoryWithSeparator: []\n    };\n  }\n  reset() {\n    this.dslMethods = {\n      option: [],\n      alternation: [],\n      repetition: [],\n      repetitionWithSeparator: [],\n      repetitionMandatory: [],\n      repetitionMandatoryWithSeparator: []\n    };\n  }\n  visitOption(option2) {\n    this.dslMethods.option.push(option2);\n  }\n  visitRepetitionWithSeparator(manySep) {\n    this.dslMethods.repetitionWithSeparator.push(manySep);\n  }\n  visitRepetitionMandatory(atLeastOne) {\n    this.dslMethods.repetitionMandatory.push(atLeastOne);\n  }\n  visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n    this.dslMethods.repetitionMandatoryWithSeparator.push(atLeastOneSep);\n  }\n  visitRepetition(many) {\n    this.dslMethods.repetition.push(many);\n  }\n  visitAlternation(or) {\n    this.dslMethods.alternation.push(or);\n  }\n};\nvar collectorVisitor = new DslMethodsCollectorVisitor();\nfunction collectMethods(rule) {\n  collectorVisitor.reset();\n  rule.accept(collectorVisitor);\n  const dslMethods = collectorVisitor.dslMethods;\n  collectorVisitor.reset();\n  return dslMethods;\n}\n__name(collectMethods, \"collectMethods\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/cst/cst.js\nfunction setNodeLocationOnlyOffset(currNodeLocation, newLocationInfo) {\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  } else if (currNodeLocation.endOffset < newLocationInfo.endOffset === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  }\n}\n__name(setNodeLocationOnlyOffset, \"setNodeLocationOnlyOffset\");\nfunction setNodeLocationFull(currNodeLocation, newLocationInfo) {\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.startColumn = newLocationInfo.startColumn;\n    currNodeLocation.startLine = newLocationInfo.startLine;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  } else if (currNodeLocation.endOffset < newLocationInfo.endOffset === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  }\n}\n__name(setNodeLocationFull, \"setNodeLocationFull\");\nfunction addTerminalToCst(node, token, tokenTypeName) {\n  if (node.children[tokenTypeName] === void 0) {\n    node.children[tokenTypeName] = [token];\n  } else {\n    node.children[tokenTypeName].push(token);\n  }\n}\n__name(addTerminalToCst, \"addTerminalToCst\");\nfunction addNoneTerminalToCst(node, ruleName, ruleResult) {\n  if (node.children[ruleName] === void 0) {\n    node.children[ruleName] = [ruleResult];\n  } else {\n    node.children[ruleName].push(ruleResult);\n  }\n}\n__name(addNoneTerminalToCst, \"addNoneTerminalToCst\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/lang/lang_extensions.js\nvar NAME = \"name\";\nfunction defineNameProp(obj, nameValue) {\n  Object.defineProperty(obj, NAME, {\n    enumerable: false,\n    configurable: true,\n    writable: false,\n    value: nameValue\n  });\n}\n__name(defineNameProp, \"defineNameProp\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/cst/cst_visitor.js\nfunction defaultVisit(ctx, param) {\n  const childrenNames = keys_default(ctx);\n  const childrenNamesLength = childrenNames.length;\n  for (let i = 0; i < childrenNamesLength; i++) {\n    const currChildName = childrenNames[i];\n    const currChildArray = ctx[currChildName];\n    const currChildArrayLength = currChildArray.length;\n    for (let j = 0; j < currChildArrayLength; j++) {\n      const currChild = currChildArray[j];\n      if (currChild.tokenTypeIdx === void 0) {\n        this[currChild.name](currChild.children, param);\n      }\n    }\n  }\n}\n__name(defaultVisit, \"defaultVisit\");\nfunction createBaseSemanticVisitorConstructor(grammarName, ruleNames) {\n  const derivedConstructor = /* @__PURE__ */ __name(function() {\n  }, \"derivedConstructor\");\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemantics\");\n  const semanticProto = {\n    visit: /* @__PURE__ */ __name(function(cstNode, param) {\n      if (isArray_default(cstNode)) {\n        cstNode = cstNode[0];\n      }\n      if (isUndefined_default(cstNode)) {\n        return void 0;\n      }\n      return this[cstNode.name](cstNode.children, param);\n    }, \"visit\"),\n    validateVisitor: /* @__PURE__ */ __name(function() {\n      const semanticDefinitionErrors = validateVisitor(this, ruleNames);\n      if (!isEmpty_default(semanticDefinitionErrors)) {\n        const errorMessages = map_default(semanticDefinitionErrors, (currDefError) => currDefError.msg);\n        throw Error(`Errors Detected in CST Visitor <${this.constructor.name}>:\n\t${errorMessages.join(\"\\n\\n\").replace(/\\n/g, \"\\n\t\")}`);\n      }\n    }, \"validateVisitor\")\n  };\n  derivedConstructor.prototype = semanticProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n  derivedConstructor._RULE_NAMES = ruleNames;\n  return derivedConstructor;\n}\n__name(createBaseSemanticVisitorConstructor, \"createBaseSemanticVisitorConstructor\");\nfunction createBaseVisitorConstructorWithDefaults(grammarName, ruleNames, baseConstructor) {\n  const derivedConstructor = /* @__PURE__ */ __name(function() {\n  }, \"derivedConstructor\");\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemanticsWithDefaults\");\n  const withDefaultsProto = Object.create(baseConstructor.prototype);\n  forEach_default(ruleNames, (ruleName) => {\n    withDefaultsProto[ruleName] = defaultVisit;\n  });\n  derivedConstructor.prototype = withDefaultsProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n  return derivedConstructor;\n}\n__name(createBaseVisitorConstructorWithDefaults, \"createBaseVisitorConstructorWithDefaults\");\nvar CstVisitorDefinitionError;\n(function(CstVisitorDefinitionError2) {\n  CstVisitorDefinitionError2[CstVisitorDefinitionError2[\"REDUNDANT_METHOD\"] = 0] = \"REDUNDANT_METHOD\";\n  CstVisitorDefinitionError2[CstVisitorDefinitionError2[\"MISSING_METHOD\"] = 1] = \"MISSING_METHOD\";\n})(CstVisitorDefinitionError || (CstVisitorDefinitionError = {}));\nfunction validateVisitor(visitorInstance, ruleNames) {\n  const missingErrors = validateMissingCstMethods(visitorInstance, ruleNames);\n  return missingErrors;\n}\n__name(validateVisitor, \"validateVisitor\");\nfunction validateMissingCstMethods(visitorInstance, ruleNames) {\n  const missingRuleNames = filter_default(ruleNames, (currRuleName) => {\n    return isFunction_default(visitorInstance[currRuleName]) === false;\n  });\n  const errors = map_default(missingRuleNames, (currRuleName) => {\n    return {\n      msg: `Missing visitor method: <${currRuleName}> on ${visitorInstance.constructor.name} CST Visitor.`,\n      type: CstVisitorDefinitionError.MISSING_METHOD,\n      methodName: currRuleName\n    };\n  });\n  return compact_default(errors);\n}\n__name(validateMissingCstMethods, \"validateMissingCstMethods\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/tree_builder.js\nvar TreeBuilder = class {\n  static {\n    __name(this, \"TreeBuilder\");\n  }\n  initTreeBuilder(config) {\n    this.CST_STACK = [];\n    this.outputCst = config.outputCst;\n    this.nodeLocationTracking = has_default(config, \"nodeLocationTracking\") ? config.nodeLocationTracking : DEFAULT_PARSER_CONFIG.nodeLocationTracking;\n    if (!this.outputCst) {\n      this.cstInvocationStateUpdate = noop_default;\n      this.cstFinallyStateUpdate = noop_default;\n      this.cstPostTerminal = noop_default;\n      this.cstPostNonTerminal = noop_default;\n      this.cstPostRule = noop_default;\n    } else {\n      if (/full/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = setNodeLocationFull;\n          this.setNodeLocationFromNode = setNodeLocationFull;\n          this.cstPostRule = noop_default;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop_default;\n          this.setNodeLocationFromNode = noop_default;\n          this.cstPostRule = this.cstPostRuleFull;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRegular;\n        }\n      } else if (/onlyOffset/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = setNodeLocationOnlyOffset;\n          this.setNodeLocationFromNode = setNodeLocationOnlyOffset;\n          this.cstPostRule = noop_default;\n          this.setInitialNodeLocation = this.setInitialNodeLocationOnlyOffsetRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop_default;\n          this.setNodeLocationFromNode = noop_default;\n          this.cstPostRule = this.cstPostRuleOnlyOffset;\n          this.setInitialNodeLocation = this.setInitialNodeLocationOnlyOffsetRegular;\n        }\n      } else if (/none/i.test(this.nodeLocationTracking)) {\n        this.setNodeLocationFromToken = noop_default;\n        this.setNodeLocationFromNode = noop_default;\n        this.cstPostRule = noop_default;\n        this.setInitialNodeLocation = noop_default;\n      } else {\n        throw Error(`Invalid <nodeLocationTracking> config option: \"${config.nodeLocationTracking}\"`);\n      }\n    }\n  }\n  setInitialNodeLocationOnlyOffsetRecovery(cstNode) {\n    cstNode.location = {\n      startOffset: NaN,\n      endOffset: NaN\n    };\n  }\n  setInitialNodeLocationOnlyOffsetRegular(cstNode) {\n    cstNode.location = {\n      // without error recovery the starting Location of a new CstNode is guaranteed\n      // To be the next Token's startOffset (for valid inputs).\n      // For invalid inputs there won't be any CSTOutput so this potential\n      // inaccuracy does not matter\n      startOffset: this.LA(1).startOffset,\n      endOffset: NaN\n    };\n  }\n  setInitialNodeLocationFullRecovery(cstNode) {\n    cstNode.location = {\n      startOffset: NaN,\n      startLine: NaN,\n      startColumn: NaN,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN\n    };\n  }\n  /**\n       *  @see setInitialNodeLocationOnlyOffsetRegular for explanation why this work\n  \n       * @param cstNode\n       */\n  setInitialNodeLocationFullRegular(cstNode) {\n    const nextToken = this.LA(1);\n    cstNode.location = {\n      startOffset: nextToken.startOffset,\n      startLine: nextToken.startLine,\n      startColumn: nextToken.startColumn,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN\n    };\n  }\n  cstInvocationStateUpdate(fullRuleName) {\n    const cstNode = {\n      name: fullRuleName,\n      children: /* @__PURE__ */ Object.create(null)\n    };\n    this.setInitialNodeLocation(cstNode);\n    this.CST_STACK.push(cstNode);\n  }\n  cstFinallyStateUpdate() {\n    this.CST_STACK.pop();\n  }\n  cstPostRuleFull(ruleCstNode) {\n    const prevToken = this.LA(0);\n    const loc = ruleCstNode.location;\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n      loc.endLine = prevToken.endLine;\n      loc.endColumn = prevToken.endColumn;\n    } else {\n      loc.startOffset = NaN;\n      loc.startLine = NaN;\n      loc.startColumn = NaN;\n    }\n  }\n  cstPostRuleOnlyOffset(ruleCstNode) {\n    const prevToken = this.LA(0);\n    const loc = ruleCstNode.location;\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n    } else {\n      loc.startOffset = NaN;\n    }\n  }\n  cstPostTerminal(key, consumedToken) {\n    const rootCst = this.CST_STACK[this.CST_STACK.length - 1];\n    addTerminalToCst(rootCst, consumedToken, key);\n    this.setNodeLocationFromToken(rootCst.location, consumedToken);\n  }\n  cstPostNonTerminal(ruleCstResult, ruleName) {\n    const preCstNode = this.CST_STACK[this.CST_STACK.length - 1];\n    addNoneTerminalToCst(preCstNode, ruleName, ruleCstResult);\n    this.setNodeLocationFromNode(preCstNode.location, ruleCstResult.location);\n  }\n  getBaseCstVisitorConstructor() {\n    if (isUndefined_default(this.baseCstVisitorConstructor)) {\n      const newBaseCstVisitorConstructor = createBaseSemanticVisitorConstructor(this.className, keys_default(this.gastProductionsCache));\n      this.baseCstVisitorConstructor = newBaseCstVisitorConstructor;\n      return newBaseCstVisitorConstructor;\n    }\n    return this.baseCstVisitorConstructor;\n  }\n  getBaseCstVisitorConstructorWithDefaults() {\n    if (isUndefined_default(this.baseCstVisitorWithDefaultsConstructor)) {\n      const newConstructor = createBaseVisitorConstructorWithDefaults(this.className, keys_default(this.gastProductionsCache), this.getBaseCstVisitorConstructor());\n      this.baseCstVisitorWithDefaultsConstructor = newConstructor;\n      return newConstructor;\n    }\n    return this.baseCstVisitorWithDefaultsConstructor;\n  }\n  getLastExplicitRuleShortName() {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 1];\n  }\n  getPreviousExplicitRuleShortName() {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 2];\n  }\n  getLastExplicitRuleOccurrenceIndex() {\n    const occurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return occurrenceStack[occurrenceStack.length - 1];\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/lexer_adapter.js\nvar LexerAdapter = class {\n  static {\n    __name(this, \"LexerAdapter\");\n  }\n  initLexerAdapter() {\n    this.tokVector = [];\n    this.tokVectorLength = 0;\n    this.currIdx = -1;\n  }\n  set input(newInput) {\n    if (this.selfAnalysisDone !== true) {\n      throw Error(`Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`);\n    }\n    this.reset();\n    this.tokVector = newInput;\n    this.tokVectorLength = newInput.length;\n  }\n  get input() {\n    return this.tokVector;\n  }\n  // skips a token and returns the next token\n  SKIP_TOKEN() {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken();\n      return this.LA(1);\n    } else {\n      return END_OF_FILE;\n    }\n  }\n  // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n  LA(howMuch) {\n    const soughtIdx = this.currIdx + howMuch;\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return END_OF_FILE;\n    } else {\n      return this.tokVector[soughtIdx];\n    }\n  }\n  consumeToken() {\n    this.currIdx++;\n  }\n  exportLexerState() {\n    return this.currIdx;\n  }\n  importLexerState(newState2) {\n    this.currIdx = newState2;\n  }\n  resetLexerState() {\n    this.currIdx = -1;\n  }\n  moveToTerminatedState() {\n    this.currIdx = this.tokVector.length - 1;\n  }\n  getLexerPosition() {\n    return this.exportLexerState();\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/recognizer_api.js\nvar RecognizerApi = class {\n  static {\n    __name(this, \"RecognizerApi\");\n  }\n  ACTION(impl) {\n    return impl.call(this);\n  }\n  consume(idx, tokType, options) {\n    return this.consumeInternal(tokType, idx, options);\n  }\n  subrule(idx, ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, idx, options);\n  }\n  option(idx, actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, idx);\n  }\n  or(idx, altsOrOpts) {\n    return this.orInternal(altsOrOpts, idx);\n  }\n  many(idx, actionORMethodDef) {\n    return this.manyInternal(idx, actionORMethodDef);\n  }\n  atLeastOne(idx, actionORMethodDef) {\n    return this.atLeastOneInternal(idx, actionORMethodDef);\n  }\n  CONSUME(tokType, options) {\n    return this.consumeInternal(tokType, 0, options);\n  }\n  CONSUME1(tokType, options) {\n    return this.consumeInternal(tokType, 1, options);\n  }\n  CONSUME2(tokType, options) {\n    return this.consumeInternal(tokType, 2, options);\n  }\n  CONSUME3(tokType, options) {\n    return this.consumeInternal(tokType, 3, options);\n  }\n  CONSUME4(tokType, options) {\n    return this.consumeInternal(tokType, 4, options);\n  }\n  CONSUME5(tokType, options) {\n    return this.consumeInternal(tokType, 5, options);\n  }\n  CONSUME6(tokType, options) {\n    return this.consumeInternal(tokType, 6, options);\n  }\n  CONSUME7(tokType, options) {\n    return this.consumeInternal(tokType, 7, options);\n  }\n  CONSUME8(tokType, options) {\n    return this.consumeInternal(tokType, 8, options);\n  }\n  CONSUME9(tokType, options) {\n    return this.consumeInternal(tokType, 9, options);\n  }\n  SUBRULE(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 0, options);\n  }\n  SUBRULE1(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 1, options);\n  }\n  SUBRULE2(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 2, options);\n  }\n  SUBRULE3(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 3, options);\n  }\n  SUBRULE4(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 4, options);\n  }\n  SUBRULE5(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 5, options);\n  }\n  SUBRULE6(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 6, options);\n  }\n  SUBRULE7(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 7, options);\n  }\n  SUBRULE8(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 8, options);\n  }\n  SUBRULE9(ruleToCall, options) {\n    return this.subruleInternal(ruleToCall, 9, options);\n  }\n  OPTION(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 0);\n  }\n  OPTION1(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 1);\n  }\n  OPTION2(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 2);\n  }\n  OPTION3(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 3);\n  }\n  OPTION4(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 4);\n  }\n  OPTION5(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 5);\n  }\n  OPTION6(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 6);\n  }\n  OPTION7(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 7);\n  }\n  OPTION8(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 8);\n  }\n  OPTION9(actionORMethodDef) {\n    return this.optionInternal(actionORMethodDef, 9);\n  }\n  OR(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 0);\n  }\n  OR1(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 1);\n  }\n  OR2(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 2);\n  }\n  OR3(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 3);\n  }\n  OR4(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 4);\n  }\n  OR5(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 5);\n  }\n  OR6(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 6);\n  }\n  OR7(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 7);\n  }\n  OR8(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 8);\n  }\n  OR9(altsOrOpts) {\n    return this.orInternal(altsOrOpts, 9);\n  }\n  MANY(actionORMethodDef) {\n    this.manyInternal(0, actionORMethodDef);\n  }\n  MANY1(actionORMethodDef) {\n    this.manyInternal(1, actionORMethodDef);\n  }\n  MANY2(actionORMethodDef) {\n    this.manyInternal(2, actionORMethodDef);\n  }\n  MANY3(actionORMethodDef) {\n    this.manyInternal(3, actionORMethodDef);\n  }\n  MANY4(actionORMethodDef) {\n    this.manyInternal(4, actionORMethodDef);\n  }\n  MANY5(actionORMethodDef) {\n    this.manyInternal(5, actionORMethodDef);\n  }\n  MANY6(actionORMethodDef) {\n    this.manyInternal(6, actionORMethodDef);\n  }\n  MANY7(actionORMethodDef) {\n    this.manyInternal(7, actionORMethodDef);\n  }\n  MANY8(actionORMethodDef) {\n    this.manyInternal(8, actionORMethodDef);\n  }\n  MANY9(actionORMethodDef) {\n    this.manyInternal(9, actionORMethodDef);\n  }\n  MANY_SEP(options) {\n    this.manySepFirstInternal(0, options);\n  }\n  MANY_SEP1(options) {\n    this.manySepFirstInternal(1, options);\n  }\n  MANY_SEP2(options) {\n    this.manySepFirstInternal(2, options);\n  }\n  MANY_SEP3(options) {\n    this.manySepFirstInternal(3, options);\n  }\n  MANY_SEP4(options) {\n    this.manySepFirstInternal(4, options);\n  }\n  MANY_SEP5(options) {\n    this.manySepFirstInternal(5, options);\n  }\n  MANY_SEP6(options) {\n    this.manySepFirstInternal(6, options);\n  }\n  MANY_SEP7(options) {\n    this.manySepFirstInternal(7, options);\n  }\n  MANY_SEP8(options) {\n    this.manySepFirstInternal(8, options);\n  }\n  MANY_SEP9(options) {\n    this.manySepFirstInternal(9, options);\n  }\n  AT_LEAST_ONE(actionORMethodDef) {\n    this.atLeastOneInternal(0, actionORMethodDef);\n  }\n  AT_LEAST_ONE1(actionORMethodDef) {\n    return this.atLeastOneInternal(1, actionORMethodDef);\n  }\n  AT_LEAST_ONE2(actionORMethodDef) {\n    this.atLeastOneInternal(2, actionORMethodDef);\n  }\n  AT_LEAST_ONE3(actionORMethodDef) {\n    this.atLeastOneInternal(3, actionORMethodDef);\n  }\n  AT_LEAST_ONE4(actionORMethodDef) {\n    this.atLeastOneInternal(4, actionORMethodDef);\n  }\n  AT_LEAST_ONE5(actionORMethodDef) {\n    this.atLeastOneInternal(5, actionORMethodDef);\n  }\n  AT_LEAST_ONE6(actionORMethodDef) {\n    this.atLeastOneInternal(6, actionORMethodDef);\n  }\n  AT_LEAST_ONE7(actionORMethodDef) {\n    this.atLeastOneInternal(7, actionORMethodDef);\n  }\n  AT_LEAST_ONE8(actionORMethodDef) {\n    this.atLeastOneInternal(8, actionORMethodDef);\n  }\n  AT_LEAST_ONE9(actionORMethodDef) {\n    this.atLeastOneInternal(9, actionORMethodDef);\n  }\n  AT_LEAST_ONE_SEP(options) {\n    this.atLeastOneSepFirstInternal(0, options);\n  }\n  AT_LEAST_ONE_SEP1(options) {\n    this.atLeastOneSepFirstInternal(1, options);\n  }\n  AT_LEAST_ONE_SEP2(options) {\n    this.atLeastOneSepFirstInternal(2, options);\n  }\n  AT_LEAST_ONE_SEP3(options) {\n    this.atLeastOneSepFirstInternal(3, options);\n  }\n  AT_LEAST_ONE_SEP4(options) {\n    this.atLeastOneSepFirstInternal(4, options);\n  }\n  AT_LEAST_ONE_SEP5(options) {\n    this.atLeastOneSepFirstInternal(5, options);\n  }\n  AT_LEAST_ONE_SEP6(options) {\n    this.atLeastOneSepFirstInternal(6, options);\n  }\n  AT_LEAST_ONE_SEP7(options) {\n    this.atLeastOneSepFirstInternal(7, options);\n  }\n  AT_LEAST_ONE_SEP8(options) {\n    this.atLeastOneSepFirstInternal(8, options);\n  }\n  AT_LEAST_ONE_SEP9(options) {\n    this.atLeastOneSepFirstInternal(9, options);\n  }\n  RULE(name, implementation, config = DEFAULT_RULE_CONFIG) {\n    if (includes_default(this.definedRulesNames, name)) {\n      const errMsg = defaultGrammarValidatorErrorProvider.buildDuplicateRuleNameError({\n        topLevelRule: name,\n        grammarName: this.className\n      });\n      const error = {\n        message: errMsg,\n        type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n        ruleName: name\n      };\n      this.definitionErrors.push(error);\n    }\n    this.definedRulesNames.push(name);\n    const ruleImplementation = this.defineRule(name, implementation, config);\n    this[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n  OVERRIDE_RULE(name, impl, config = DEFAULT_RULE_CONFIG) {\n    const ruleErrors = validateRuleIsOverridden(name, this.definedRulesNames, this.className);\n    this.definitionErrors = this.definitionErrors.concat(ruleErrors);\n    const ruleImplementation = this.defineRule(name, impl, config);\n    this[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n  BACKTRACK(grammarRule, args) {\n    return function() {\n      this.isBackTrackingStack.push(1);\n      const orgState = this.saveRecogState();\n      try {\n        grammarRule.apply(this, args);\n        return true;\n      } catch (e) {\n        if (isRecognitionException(e)) {\n          return false;\n        } else {\n          throw e;\n        }\n      } finally {\n        this.reloadRecogState(orgState);\n        this.isBackTrackingStack.pop();\n      }\n    };\n  }\n  // GAST export APIs\n  getGAstProductions() {\n    return this.gastProductionsCache;\n  }\n  getSerializedGastProductions() {\n    return serializeGrammar(values_default(this.gastProductionsCache));\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/recognizer_engine.js\nvar RecognizerEngine = class {\n  static {\n    __name(this, \"RecognizerEngine\");\n  }\n  initRecognizerEngine(tokenVocabulary, config) {\n    this.className = this.constructor.name;\n    this.shortRuleNameToFull = {};\n    this.fullRuleNameToShort = {};\n    this.ruleShortNameIdx = 256;\n    this.tokenMatcher = tokenStructuredMatcherNoCategories;\n    this.subruleIdx = 0;\n    this.definedRulesNames = [];\n    this.tokensMap = {};\n    this.isBackTrackingStack = [];\n    this.RULE_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n    this.gastProductionsCache = {};\n    if (has_default(config, \"serializedGrammar\")) {\n      throw Error(\"The Parser's configuration can no longer contain a <serializedGrammar> property.\\n\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_6-0-0\\n\tFor Further details.\");\n    }\n    if (isArray_default(tokenVocabulary)) {\n      if (isEmpty_default(tokenVocabulary)) {\n        throw Error(\"A Token Vocabulary cannot be empty.\\n\tNote that the first argument for the parser constructor\\n\tis no longer a Token vector (since v4.0).\");\n      }\n      if (typeof tokenVocabulary[0].startOffset === \"number\") {\n        throw Error(\"The Parser constructor no longer accepts a token vector as the first argument.\\n\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_4-0-0\\n\tFor Further details.\");\n      }\n    }\n    if (isArray_default(tokenVocabulary)) {\n      this.tokensMap = reduce_default(tokenVocabulary, (acc, tokType) => {\n        acc[tokType.name] = tokType;\n        return acc;\n      }, {});\n    } else if (has_default(tokenVocabulary, \"modes\") && every_default(flatten_default(values_default(tokenVocabulary.modes)), isTokenType)) {\n      const allTokenTypes2 = flatten_default(values_default(tokenVocabulary.modes));\n      const uniqueTokens = uniq_default(allTokenTypes2);\n      this.tokensMap = reduce_default(uniqueTokens, (acc, tokType) => {\n        acc[tokType.name] = tokType;\n        return acc;\n      }, {});\n    } else if (isObject_default(tokenVocabulary)) {\n      this.tokensMap = clone_default(tokenVocabulary);\n    } else {\n      throw new Error(\"<tokensDictionary> argument must be An Array of Token constructors, A dictionary of Token constructors or an IMultiModeLexerDefinition\");\n    }\n    this.tokensMap[\"EOF\"] = EOF;\n    const allTokenTypes = has_default(tokenVocabulary, \"modes\") ? flatten_default(values_default(tokenVocabulary.modes)) : values_default(tokenVocabulary);\n    const noTokenCategoriesUsed = every_default(allTokenTypes, (tokenConstructor) => isEmpty_default(tokenConstructor.categoryMatches));\n    this.tokenMatcher = noTokenCategoriesUsed ? tokenStructuredMatcherNoCategories : tokenStructuredMatcher;\n    augmentTokenTypes(values_default(this.tokensMap));\n  }\n  defineRule(ruleName, impl, config) {\n    if (this.selfAnalysisDone) {\n      throw Error(`Grammar rule <${ruleName}> may not be defined after the 'performSelfAnalysis' method has been called'\nMake sure that all grammar rule definitions are done before 'performSelfAnalysis' is called.`);\n    }\n    const resyncEnabled = has_default(config, \"resyncEnabled\") ? config.resyncEnabled : DEFAULT_RULE_CONFIG.resyncEnabled;\n    const recoveryValueFunc = has_default(config, \"recoveryValueFunc\") ? config.recoveryValueFunc : DEFAULT_RULE_CONFIG.recoveryValueFunc;\n    const shortName = this.ruleShortNameIdx << BITS_FOR_METHOD_TYPE + BITS_FOR_OCCURRENCE_IDX;\n    this.ruleShortNameIdx++;\n    this.shortRuleNameToFull[shortName] = ruleName;\n    this.fullRuleNameToShort[ruleName] = shortName;\n    let invokeRuleWithTry;\n    if (this.outputCst === true) {\n      invokeRuleWithTry = /* @__PURE__ */ __name(function invokeRuleWithTry2(...args) {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          impl.apply(this, args);\n          const cst = this.CST_STACK[this.CST_STACK.length - 1];\n          this.cstPostRule(cst);\n          return cst;\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc);\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      }, \"invokeRuleWithTry\");\n    } else {\n      invokeRuleWithTry = /* @__PURE__ */ __name(function invokeRuleWithTryCst(...args) {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          return impl.apply(this, args);\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc);\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      }, \"invokeRuleWithTryCst\");\n    }\n    const wrappedGrammarRule = Object.assign(invokeRuleWithTry, { ruleName, originalGrammarAction: impl });\n    return wrappedGrammarRule;\n  }\n  invokeRuleCatch(e, resyncEnabledConfig, recoveryValueFunc) {\n    const isFirstInvokedRule = this.RULE_STACK.length === 1;\n    const reSyncEnabled = resyncEnabledConfig && !this.isBackTracking() && this.recoveryEnabled;\n    if (isRecognitionException(e)) {\n      const recogError = e;\n      if (reSyncEnabled) {\n        const reSyncTokType = this.findReSyncTokenType();\n        if (this.isInCurrentRuleReSyncSet(reSyncTokType)) {\n          recogError.resyncedTokens = this.reSyncTo(reSyncTokType);\n          if (this.outputCst) {\n            const partialCstResult = this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            return partialCstResult;\n          } else {\n            return recoveryValueFunc(e);\n          }\n        } else {\n          if (this.outputCst) {\n            const partialCstResult = this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            recogError.partialCstResult = partialCstResult;\n          }\n          throw recogError;\n        }\n      } else if (isFirstInvokedRule) {\n        this.moveToTerminatedState();\n        return recoveryValueFunc(e);\n      } else {\n        throw recogError;\n      }\n    } else {\n      throw e;\n    }\n  }\n  // Implementation of parsing DSL\n  optionInternal(actionORMethodDef, occurrence) {\n    const key = this.getKeyForAutomaticLookahead(OPTION_IDX, occurrence);\n    return this.optionInternalLogic(actionORMethodDef, occurrence, key);\n  }\n  optionInternalLogic(actionORMethodDef, occurrence, key) {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      if (predicate !== void 0) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = /* @__PURE__ */ __name(() => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        }, \"lookAheadFunc\");\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n    if (lookAheadFunc.call(this) === true) {\n      return action.call(this);\n    }\n    return void 0;\n  }\n  atLeastOneInternal(prodOccurrence, actionORMethodDef) {\n    const laKey = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_IDX, prodOccurrence);\n    return this.atLeastOneInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n  }\n  atLeastOneInternalLogic(prodOccurrence, actionORMethodDef, key) {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      if (predicate !== void 0) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = /* @__PURE__ */ __name(() => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        }, \"lookAheadFunc\");\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n    if (lookAheadFunc.call(this) === true) {\n      let notStuck = this.doSingleRepetition(action);\n      while (lookAheadFunc.call(this) === true && notStuck === true) {\n        notStuck = this.doSingleRepetition(action);\n      }\n    } else {\n      throw this.raiseEarlyExitException(prodOccurrence, PROD_TYPE.REPETITION_MANDATORY, actionORMethodDef.ERR_MSG);\n    }\n    this.attemptInRepetitionRecovery(this.atLeastOneInternal, [prodOccurrence, actionORMethodDef], lookAheadFunc, AT_LEAST_ONE_IDX, prodOccurrence, NextTerminalAfterAtLeastOneWalker);\n  }\n  atLeastOneSepFirstInternal(prodOccurrence, options) {\n    const laKey = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_SEP_IDX, prodOccurrence);\n    this.atLeastOneSepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n  atLeastOneSepFirstInternalLogic(prodOccurrence, options, key) {\n    const action = options.DEF;\n    const separator = options.SEP;\n    const firstIterationLookaheadFunc = this.getLaFuncFromCache(key);\n    if (firstIterationLookaheadFunc.call(this) === true) {\n      action.call(this);\n      const separatorLookAheadFunc = /* @__PURE__ */ __name(() => {\n        return this.tokenMatcher(this.LA(1), separator);\n      }, \"separatorLookAheadFunc\");\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        this.CONSUME(separator);\n        action.call(this);\n      }\n      this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [\n        prodOccurrence,\n        separator,\n        separatorLookAheadFunc,\n        action,\n        NextTerminalAfterAtLeastOneSepWalker\n      ], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, NextTerminalAfterAtLeastOneSepWalker);\n    } else {\n      throw this.raiseEarlyExitException(prodOccurrence, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, options.ERR_MSG);\n    }\n  }\n  manyInternal(prodOccurrence, actionORMethodDef) {\n    const laKey = this.getKeyForAutomaticLookahead(MANY_IDX, prodOccurrence);\n    return this.manyInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n  }\n  manyInternalLogic(prodOccurrence, actionORMethodDef, key) {\n    let lookaheadFunction = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      if (predicate !== void 0) {\n        const orgLookaheadFunction = lookaheadFunction;\n        lookaheadFunction = /* @__PURE__ */ __name(() => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        }, \"lookaheadFunction\");\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n    let notStuck = true;\n    while (lookaheadFunction.call(this) === true && notStuck === true) {\n      notStuck = this.doSingleRepetition(action);\n    }\n    this.attemptInRepetitionRecovery(\n      this.manyInternal,\n      [prodOccurrence, actionORMethodDef],\n      lookaheadFunction,\n      MANY_IDX,\n      prodOccurrence,\n      NextTerminalAfterManyWalker,\n      // The notStuck parameter is only relevant when \"attemptInRepetitionRecovery\"\n      // is invoked from manyInternal, in the MANY_SEP case and AT_LEAST_ONE[_SEP]\n      // An infinite loop cannot occur as:\n      // - Either the lookahead is guaranteed to consume something (Single Token Separator)\n      // - AT_LEAST_ONE by definition is guaranteed to consume something (or error out).\n      notStuck\n    );\n  }\n  manySepFirstInternal(prodOccurrence, options) {\n    const laKey = this.getKeyForAutomaticLookahead(MANY_SEP_IDX, prodOccurrence);\n    this.manySepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n  manySepFirstInternalLogic(prodOccurrence, options, key) {\n    const action = options.DEF;\n    const separator = options.SEP;\n    const firstIterationLaFunc = this.getLaFuncFromCache(key);\n    if (firstIterationLaFunc.call(this) === true) {\n      action.call(this);\n      const separatorLookAheadFunc = /* @__PURE__ */ __name(() => {\n        return this.tokenMatcher(this.LA(1), separator);\n      }, \"separatorLookAheadFunc\");\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        this.CONSUME(separator);\n        action.call(this);\n      }\n      this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [\n        prodOccurrence,\n        separator,\n        separatorLookAheadFunc,\n        action,\n        NextTerminalAfterManySepWalker\n      ], separatorLookAheadFunc, MANY_SEP_IDX, prodOccurrence, NextTerminalAfterManySepWalker);\n    }\n  }\n  repetitionSepSecondInternal(prodOccurrence, separator, separatorLookAheadFunc, action, nextTerminalAfterWalker) {\n    while (separatorLookAheadFunc()) {\n      this.CONSUME(separator);\n      action.call(this);\n    }\n    this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [\n      prodOccurrence,\n      separator,\n      separatorLookAheadFunc,\n      action,\n      nextTerminalAfterWalker\n    ], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, nextTerminalAfterWalker);\n  }\n  doSingleRepetition(action) {\n    const beforeIteration = this.getLexerPosition();\n    action.call(this);\n    const afterIteration = this.getLexerPosition();\n    return afterIteration > beforeIteration;\n  }\n  orInternal(altsOrOpts, occurrence) {\n    const laKey = this.getKeyForAutomaticLookahead(OR_IDX, occurrence);\n    const alts = isArray_default(altsOrOpts) ? altsOrOpts : altsOrOpts.DEF;\n    const laFunc = this.getLaFuncFromCache(laKey);\n    const altIdxToTake = laFunc.call(this, alts);\n    if (altIdxToTake !== void 0) {\n      const chosenAlternative = alts[altIdxToTake];\n      return chosenAlternative.ALT.call(this);\n    }\n    this.raiseNoAltException(occurrence, altsOrOpts.ERR_MSG);\n  }\n  ruleFinallyStateUpdate() {\n    this.RULE_STACK.pop();\n    this.RULE_OCCURRENCE_STACK.pop();\n    this.cstFinallyStateUpdate();\n    if (this.RULE_STACK.length === 0 && this.isAtEndOfInput() === false) {\n      const firstRedundantTok = this.LA(1);\n      const errMsg = this.errorMessageProvider.buildNotAllInputParsedMessage({\n        firstRedundant: firstRedundantTok,\n        ruleName: this.getCurrRuleFullName()\n      });\n      this.SAVE_ERROR(new NotAllInputParsedException(errMsg, firstRedundantTok));\n    }\n  }\n  subruleInternal(ruleToCall, idx, options) {\n    let ruleResult;\n    try {\n      const args = options !== void 0 ? options.ARGS : void 0;\n      this.subruleIdx = idx;\n      ruleResult = ruleToCall.apply(this, args);\n      this.cstPostNonTerminal(ruleResult, options !== void 0 && options.LABEL !== void 0 ? options.LABEL : ruleToCall.ruleName);\n      return ruleResult;\n    } catch (e) {\n      throw this.subruleInternalError(e, options, ruleToCall.ruleName);\n    }\n  }\n  subruleInternalError(e, options, ruleName) {\n    if (isRecognitionException(e) && e.partialCstResult !== void 0) {\n      this.cstPostNonTerminal(e.partialCstResult, options !== void 0 && options.LABEL !== void 0 ? options.LABEL : ruleName);\n      delete e.partialCstResult;\n    }\n    throw e;\n  }\n  consumeInternal(tokType, idx, options) {\n    let consumedToken;\n    try {\n      const nextToken = this.LA(1);\n      if (this.tokenMatcher(nextToken, tokType) === true) {\n        this.consumeToken();\n        consumedToken = nextToken;\n      } else {\n        this.consumeInternalError(tokType, nextToken, options);\n      }\n    } catch (eFromConsumption) {\n      consumedToken = this.consumeInternalRecovery(tokType, idx, eFromConsumption);\n    }\n    this.cstPostTerminal(options !== void 0 && options.LABEL !== void 0 ? options.LABEL : tokType.name, consumedToken);\n    return consumedToken;\n  }\n  consumeInternalError(tokType, nextToken, options) {\n    let msg;\n    const previousToken = this.LA(0);\n    if (options !== void 0 && options.ERR_MSG) {\n      msg = options.ERR_MSG;\n    } else {\n      msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: tokType,\n        actual: nextToken,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName()\n      });\n    }\n    throw this.SAVE_ERROR(new MismatchedTokenException(msg, nextToken, previousToken));\n  }\n  consumeInternalRecovery(tokType, idx, eFromConsumption) {\n    if (this.recoveryEnabled && // TODO: more robust checking of the exception type. Perhaps Typescript extending expressions?\n    eFromConsumption.name === \"MismatchedTokenException\" && !this.isBackTracking()) {\n      const follows = this.getFollowsForInRuleRecovery(tokType, idx);\n      try {\n        return this.tryInRuleRecovery(tokType, follows);\n      } catch (eFromInRuleRecovery) {\n        if (eFromInRuleRecovery.name === IN_RULE_RECOVERY_EXCEPTION) {\n          throw eFromConsumption;\n        } else {\n          throw eFromInRuleRecovery;\n        }\n      }\n    } else {\n      throw eFromConsumption;\n    }\n  }\n  saveRecogState() {\n    const savedErrors = this.errors;\n    const savedRuleStack = clone_default(this.RULE_STACK);\n    return {\n      errors: savedErrors,\n      lexerState: this.exportLexerState(),\n      RULE_STACK: savedRuleStack,\n      CST_STACK: this.CST_STACK\n    };\n  }\n  reloadRecogState(newState2) {\n    this.errors = newState2.errors;\n    this.importLexerState(newState2.lexerState);\n    this.RULE_STACK = newState2.RULE_STACK;\n  }\n  ruleInvocationStateUpdate(shortName, fullName, idxInCallingRule) {\n    this.RULE_OCCURRENCE_STACK.push(idxInCallingRule);\n    this.RULE_STACK.push(shortName);\n    this.cstInvocationStateUpdate(fullName);\n  }\n  isBackTracking() {\n    return this.isBackTrackingStack.length !== 0;\n  }\n  getCurrRuleFullName() {\n    const shortName = this.getLastExplicitRuleShortName();\n    return this.shortRuleNameToFull[shortName];\n  }\n  shortRuleNameToFullName(shortName) {\n    return this.shortRuleNameToFull[shortName];\n  }\n  isAtEndOfInput() {\n    return this.tokenMatcher(this.LA(1), EOF);\n  }\n  reset() {\n    this.resetLexerState();\n    this.subruleIdx = 0;\n    this.isBackTrackingStack = [];\n    this.errors = [];\n    this.RULE_STACK = [];\n    this.CST_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/error_handler.js\nvar ErrorHandler = class {\n  static {\n    __name(this, \"ErrorHandler\");\n  }\n  initErrorHandler(config) {\n    this._errors = [];\n    this.errorMessageProvider = has_default(config, \"errorMessageProvider\") ? config.errorMessageProvider : DEFAULT_PARSER_CONFIG.errorMessageProvider;\n  }\n  SAVE_ERROR(error) {\n    if (isRecognitionException(error)) {\n      error.context = {\n        ruleStack: this.getHumanReadableRuleStack(),\n        ruleOccurrenceStack: clone_default(this.RULE_OCCURRENCE_STACK)\n      };\n      this._errors.push(error);\n      return error;\n    } else {\n      throw Error(\"Trying to save an Error which is not a RecognitionException\");\n    }\n  }\n  get errors() {\n    return clone_default(this._errors);\n  }\n  set errors(newErrors) {\n    this._errors = newErrors;\n  }\n  // TODO: consider caching the error message computed information\n  raiseEarlyExitException(occurrence, prodType, userDefinedErrMsg) {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, this.maxLookahead);\n    const insideProdPaths = lookAheadPathsPerAlternative[0];\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const msg = this.errorMessageProvider.buildEarlyExitMessage({\n      expectedIterationPaths: insideProdPaths,\n      actual: actualTokens,\n      previous: this.LA(0),\n      customUserDescription: userDefinedErrMsg,\n      ruleName\n    });\n    throw this.SAVE_ERROR(new EarlyExitException(msg, this.LA(1), this.LA(0)));\n  }\n  // TODO: consider caching the error message computed information\n  raiseNoAltException(occurrence, errMsgTypes) {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOr(occurrence, ruleGrammar, this.maxLookahead);\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const previousToken = this.LA(0);\n    const errMsg = this.errorMessageProvider.buildNoViableAltMessage({\n      expectedPathsPerAlt: lookAheadPathsPerAlternative,\n      actual: actualTokens,\n      previous: previousToken,\n      customUserDescription: errMsgTypes,\n      ruleName: this.getCurrRuleFullName()\n    });\n    throw this.SAVE_ERROR(new NoViableAltException(errMsg, this.LA(1), previousToken));\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/context_assist.js\nvar ContentAssist = class {\n  static {\n    __name(this, \"ContentAssist\");\n  }\n  initContentAssist() {\n  }\n  computeContentAssist(startRuleName, precedingInput) {\n    const startRuleGast = this.gastProductionsCache[startRuleName];\n    if (isUndefined_default(startRuleGast)) {\n      throw Error(`Rule ->${startRuleName}<- does not exist in this grammar.`);\n    }\n    return nextPossibleTokensAfter([startRuleGast], precedingInput, this.tokenMatcher, this.maxLookahead);\n  }\n  // TODO: should this be a member method or a utility? it does not have any state or usage of 'this'...\n  // TODO: should this be more explicitly part of the public API?\n  getNextPossibleTokenTypes(grammarPath) {\n    const topRuleName = head_default(grammarPath.ruleStack);\n    const gastProductions = this.getGAstProductions();\n    const topProduction = gastProductions[topRuleName];\n    const nextPossibleTokenTypes = new NextAfterTokenWalker(topProduction, grammarPath).startWalking();\n    return nextPossibleTokenTypes;\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/gast_recorder.js\nvar RECORDING_NULL_OBJECT = {\n  description: \"This Object indicates the Parser is during Recording Phase\"\n};\nObject.freeze(RECORDING_NULL_OBJECT);\nvar HANDLE_SEPARATOR = true;\nvar MAX_METHOD_IDX = Math.pow(2, BITS_FOR_OCCURRENCE_IDX) - 1;\nvar RFT = createToken({ name: \"RECORDING_PHASE_TOKEN\", pattern: Lexer.NA });\naugmentTokenTypes([RFT]);\nvar RECORDING_PHASE_TOKEN = createTokenInstance(\n  RFT,\n  \"This IToken indicates the Parser is in Recording Phase\\n\tSee: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  // Using \"-1\" instead of NaN (as in EOF) because an actual number is less likely to\n  // cause errors if the output of LA or CONSUME would be (incorrectly) used during the recording phase.\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1\n);\nObject.freeze(RECORDING_PHASE_TOKEN);\nvar RECORDING_PHASE_CSTNODE = {\n  name: \"This CSTNode indicates the Parser is in Recording Phase\\n\tSee: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  children: {}\n};\nvar GastRecorder = class {\n  static {\n    __name(this, \"GastRecorder\");\n  }\n  initGastRecorder(config) {\n    this.recordingProdStack = [];\n    this.RECORDING_PHASE = false;\n  }\n  enableRecording() {\n    this.RECORDING_PHASE = true;\n    this.TRACE_INIT(\"Enable Recording\", () => {\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        this[`CONSUME${idx}`] = function(arg1, arg2) {\n          return this.consumeInternalRecord(arg1, i, arg2);\n        };\n        this[`SUBRULE${idx}`] = function(arg1, arg2) {\n          return this.subruleInternalRecord(arg1, i, arg2);\n        };\n        this[`OPTION${idx}`] = function(arg1) {\n          return this.optionInternalRecord(arg1, i);\n        };\n        this[`OR${idx}`] = function(arg1) {\n          return this.orInternalRecord(arg1, i);\n        };\n        this[`MANY${idx}`] = function(arg1) {\n          this.manyInternalRecord(i, arg1);\n        };\n        this[`MANY_SEP${idx}`] = function(arg1) {\n          this.manySepFirstInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE${idx}`] = function(arg1) {\n          this.atLeastOneInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE_SEP${idx}`] = function(arg1) {\n          this.atLeastOneSepFirstInternalRecord(i, arg1);\n        };\n      }\n      this[`consume`] = function(idx, arg1, arg2) {\n        return this.consumeInternalRecord(arg1, idx, arg2);\n      };\n      this[`subrule`] = function(idx, arg1, arg2) {\n        return this.subruleInternalRecord(arg1, idx, arg2);\n      };\n      this[`option`] = function(idx, arg1) {\n        return this.optionInternalRecord(arg1, idx);\n      };\n      this[`or`] = function(idx, arg1) {\n        return this.orInternalRecord(arg1, idx);\n      };\n      this[`many`] = function(idx, arg1) {\n        this.manyInternalRecord(idx, arg1);\n      };\n      this[`atLeastOne`] = function(idx, arg1) {\n        this.atLeastOneInternalRecord(idx, arg1);\n      };\n      this.ACTION = this.ACTION_RECORD;\n      this.BACKTRACK = this.BACKTRACK_RECORD;\n      this.LA = this.LA_RECORD;\n    });\n  }\n  disableRecording() {\n    this.RECORDING_PHASE = false;\n    this.TRACE_INIT(\"Deleting Recording methods\", () => {\n      const that = this;\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        delete that[`CONSUME${idx}`];\n        delete that[`SUBRULE${idx}`];\n        delete that[`OPTION${idx}`];\n        delete that[`OR${idx}`];\n        delete that[`MANY${idx}`];\n        delete that[`MANY_SEP${idx}`];\n        delete that[`AT_LEAST_ONE${idx}`];\n        delete that[`AT_LEAST_ONE_SEP${idx}`];\n      }\n      delete that[`consume`];\n      delete that[`subrule`];\n      delete that[`option`];\n      delete that[`or`];\n      delete that[`many`];\n      delete that[`atLeastOne`];\n      delete that.ACTION;\n      delete that.BACKTRACK;\n      delete that.LA;\n    });\n  }\n  //   Parser methods are called inside an ACTION?\n  //   Maybe try/catch/finally on ACTIONS while disabling the recorders state changes?\n  // @ts-expect-error -- noop place holder\n  ACTION_RECORD(impl) {\n  }\n  // Executing backtracking logic will break our recording logic assumptions\n  BACKTRACK_RECORD(grammarRule, args) {\n    return () => true;\n  }\n  // LA is part of the official API and may be used for custom lookahead logic\n  // by end users who may forget to wrap it in ACTION or inside a GATE\n  LA_RECORD(howMuch) {\n    return END_OF_FILE;\n  }\n  topLevelRuleRecord(name, def) {\n    try {\n      const newTopLevelRule = new Rule({ definition: [], name });\n      newTopLevelRule.name = name;\n      this.recordingProdStack.push(newTopLevelRule);\n      def.call(this);\n      this.recordingProdStack.pop();\n      return newTopLevelRule;\n    } catch (originalError) {\n      if (originalError.KNOWN_RECORDER_ERROR !== true) {\n        try {\n          originalError.message = originalError.message + '\\n\t This error was thrown during the \"grammar recording phase\" For more info see:\\n\thttps://chevrotain.io/docs/guide/internals.html#grammar-recording';\n        } catch (mutabilityError) {\n          throw originalError;\n        }\n      }\n      throw originalError;\n    }\n  }\n  // Implementation of parsing DSL\n  optionInternalRecord(actionORMethodDef, occurrence) {\n    return recordProd.call(this, Option, actionORMethodDef, occurrence);\n  }\n  atLeastOneInternalRecord(occurrence, actionORMethodDef) {\n    recordProd.call(this, RepetitionMandatory, actionORMethodDef, occurrence);\n  }\n  atLeastOneSepFirstInternalRecord(occurrence, options) {\n    recordProd.call(this, RepetitionMandatoryWithSeparator, options, occurrence, HANDLE_SEPARATOR);\n  }\n  manyInternalRecord(occurrence, actionORMethodDef) {\n    recordProd.call(this, Repetition, actionORMethodDef, occurrence);\n  }\n  manySepFirstInternalRecord(occurrence, options) {\n    recordProd.call(this, RepetitionWithSeparator, options, occurrence, HANDLE_SEPARATOR);\n  }\n  orInternalRecord(altsOrOpts, occurrence) {\n    return recordOrProd.call(this, altsOrOpts, occurrence);\n  }\n  subruleInternalRecord(ruleToCall, occurrence, options) {\n    assertMethodIdxIsValid(occurrence);\n    if (!ruleToCall || has_default(ruleToCall, \"ruleName\") === false) {\n      const error = new Error(`<SUBRULE${getIdxSuffix(occurrence)}> argument is invalid expecting a Parser method reference but got: <${JSON.stringify(ruleToCall)}>\n inside top level rule: <${this.recordingProdStack[0].name}>`);\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n    const prevProd = last_default(this.recordingProdStack);\n    const ruleName = ruleToCall.ruleName;\n    const newNoneTerminal = new NonTerminal({\n      idx: occurrence,\n      nonTerminalName: ruleName,\n      label: options === null || options === void 0 ? void 0 : options.LABEL,\n      // The resolving of the `referencedRule` property will be done once all the Rule's GASTs have been created\n      referencedRule: void 0\n    });\n    prevProd.definition.push(newNoneTerminal);\n    return this.outputCst ? RECORDING_PHASE_CSTNODE : RECORDING_NULL_OBJECT;\n  }\n  consumeInternalRecord(tokType, occurrence, options) {\n    assertMethodIdxIsValid(occurrence);\n    if (!hasShortKeyProperty(tokType)) {\n      const error = new Error(`<CONSUME${getIdxSuffix(occurrence)}> argument is invalid expecting a TokenType reference but got: <${JSON.stringify(tokType)}>\n inside top level rule: <${this.recordingProdStack[0].name}>`);\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n    const prevProd = last_default(this.recordingProdStack);\n    const newNoneTerminal = new Terminal({\n      idx: occurrence,\n      terminalType: tokType,\n      label: options === null || options === void 0 ? void 0 : options.LABEL\n    });\n    prevProd.definition.push(newNoneTerminal);\n    return RECORDING_PHASE_TOKEN;\n  }\n};\nfunction recordProd(prodConstructor, mainProdArg, occurrence, handleSep = false) {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd = last_default(this.recordingProdStack);\n  const grammarAction = isFunction_default(mainProdArg) ? mainProdArg : mainProdArg.DEF;\n  const newProd = new prodConstructor({ definition: [], idx: occurrence });\n  if (handleSep) {\n    newProd.separator = mainProdArg.SEP;\n  }\n  if (has_default(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n  this.recordingProdStack.push(newProd);\n  grammarAction.call(this);\n  prevProd.definition.push(newProd);\n  this.recordingProdStack.pop();\n  return RECORDING_NULL_OBJECT;\n}\n__name(recordProd, \"recordProd\");\nfunction recordOrProd(mainProdArg, occurrence) {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd = last_default(this.recordingProdStack);\n  const hasOptions = isArray_default(mainProdArg) === false;\n  const alts = hasOptions === false ? mainProdArg : mainProdArg.DEF;\n  const newOrProd = new Alternation({\n    definition: [],\n    idx: occurrence,\n    ignoreAmbiguities: hasOptions && mainProdArg.IGNORE_AMBIGUITIES === true\n  });\n  if (has_default(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newOrProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n  const hasPredicates = some_default(alts, (currAlt) => isFunction_default(currAlt.GATE));\n  newOrProd.hasPredicates = hasPredicates;\n  prevProd.definition.push(newOrProd);\n  forEach_default(alts, (currAlt) => {\n    const currAltFlat = new Alternative({ definition: [] });\n    newOrProd.definition.push(currAltFlat);\n    if (has_default(currAlt, \"IGNORE_AMBIGUITIES\")) {\n      currAltFlat.ignoreAmbiguities = currAlt.IGNORE_AMBIGUITIES;\n    } else if (has_default(currAlt, \"GATE\")) {\n      currAltFlat.ignoreAmbiguities = true;\n    }\n    this.recordingProdStack.push(currAltFlat);\n    currAlt.ALT.call(this);\n    this.recordingProdStack.pop();\n  });\n  return RECORDING_NULL_OBJECT;\n}\n__name(recordOrProd, \"recordOrProd\");\nfunction getIdxSuffix(idx) {\n  return idx === 0 ? \"\" : `${idx}`;\n}\n__name(getIdxSuffix, \"getIdxSuffix\");\nfunction assertMethodIdxIsValid(idx) {\n  if (idx < 0 || idx > MAX_METHOD_IDX) {\n    const error = new Error(\n      // The stack trace will contain all the needed details\n      `Invalid DSL Method idx value: <${idx}>\n\tIdx value must be a none negative value smaller than ${MAX_METHOD_IDX + 1}`\n    );\n    error.KNOWN_RECORDER_ERROR = true;\n    throw error;\n  }\n}\n__name(assertMethodIdxIsValid, \"assertMethodIdxIsValid\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/traits/perf_tracer.js\nvar PerformanceTracer = class {\n  static {\n    __name(this, \"PerformanceTracer\");\n  }\n  initPerformanceTracer(config) {\n    if (has_default(config, \"traceInitPerf\")) {\n      const userTraceInitPerf = config.traceInitPerf;\n      const traceIsNumber = typeof userTraceInitPerf === \"number\";\n      this.traceInitMaxIdent = traceIsNumber ? userTraceInitPerf : Infinity;\n      this.traceInitPerf = traceIsNumber ? userTraceInitPerf > 0 : userTraceInitPerf;\n    } else {\n      this.traceInitMaxIdent = 0;\n      this.traceInitPerf = DEFAULT_PARSER_CONFIG.traceInitPerf;\n    }\n    this.traceInitIndent = -1;\n  }\n  TRACE_INIT(phaseDesc, phaseImpl) {\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++;\n      const indent = new Array(this.traceInitIndent + 1).join(\"\t\");\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`);\n      }\n      const { time, value } = timer(phaseImpl);\n      const traceMethod = time > 10 ? console.warn : console.log;\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n      }\n      this.traceInitIndent--;\n      return value;\n    } else {\n      return phaseImpl();\n    }\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/utils/apply_mixins.js\nfunction applyMixins(derivedCtor, baseCtors) {\n  baseCtors.forEach((baseCtor) => {\n    const baseProto = baseCtor.prototype;\n    Object.getOwnPropertyNames(baseProto).forEach((propName) => {\n      if (propName === \"constructor\") {\n        return;\n      }\n      const basePropDescriptor = Object.getOwnPropertyDescriptor(baseProto, propName);\n      if (basePropDescriptor && (basePropDescriptor.get || basePropDescriptor.set)) {\n        Object.defineProperty(derivedCtor.prototype, propName, basePropDescriptor);\n      } else {\n        derivedCtor.prototype[propName] = baseCtor.prototype[propName];\n      }\n    });\n  });\n}\n__name(applyMixins, \"applyMixins\");\n\n// ../../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/lib/src/parse/parser/parser.js\nvar END_OF_FILE = createTokenInstance(EOF, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\nObject.freeze(END_OF_FILE);\nvar DEFAULT_PARSER_CONFIG = Object.freeze({\n  recoveryEnabled: false,\n  maxLookahead: 3,\n  dynamicTokensEnabled: false,\n  outputCst: true,\n  errorMessageProvider: defaultParserErrorProvider,\n  nodeLocationTracking: \"none\",\n  traceInitPerf: false,\n  skipValidations: false\n});\nvar DEFAULT_RULE_CONFIG = Object.freeze({\n  recoveryValueFunc: /* @__PURE__ */ __name(() => void 0, \"recoveryValueFunc\"),\n  resyncEnabled: true\n});\nvar ParserDefinitionErrorType;\n(function(ParserDefinitionErrorType2) {\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"INVALID_RULE_NAME\"] = 0] = \"INVALID_RULE_NAME\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"DUPLICATE_RULE_NAME\"] = 1] = \"DUPLICATE_RULE_NAME\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"INVALID_RULE_OVERRIDE\"] = 2] = \"INVALID_RULE_OVERRIDE\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"DUPLICATE_PRODUCTIONS\"] = 3] = \"DUPLICATE_PRODUCTIONS\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"UNRESOLVED_SUBRULE_REF\"] = 4] = \"UNRESOLVED_SUBRULE_REF\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"LEFT_RECURSION\"] = 5] = \"LEFT_RECURSION\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"NONE_LAST_EMPTY_ALT\"] = 6] = \"NONE_LAST_EMPTY_ALT\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"AMBIGUOUS_ALTS\"] = 7] = \"AMBIGUOUS_ALTS\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"CONFLICT_TOKENS_RULES_NAMESPACE\"] = 8] = \"CONFLICT_TOKENS_RULES_NAMESPACE\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"INVALID_TOKEN_NAME\"] = 9] = \"INVALID_TOKEN_NAME\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"NO_NON_EMPTY_LOOKAHEAD\"] = 10] = \"NO_NON_EMPTY_LOOKAHEAD\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"AMBIGUOUS_PREFIX_ALTS\"] = 11] = \"AMBIGUOUS_PREFIX_ALTS\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"TOO_MANY_ALTS\"] = 12] = \"TOO_MANY_ALTS\";\n  ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"CUSTOM_LOOKAHEAD_VALIDATION\"] = 13] = \"CUSTOM_LOOKAHEAD_VALIDATION\";\n})(ParserDefinitionErrorType || (ParserDefinitionErrorType = {}));\nfunction EMPTY_ALT(value = void 0) {\n  return function() {\n    return value;\n  };\n}\n__name(EMPTY_ALT, \"EMPTY_ALT\");\nvar Parser = class _Parser {\n  static {\n    __name(this, \"Parser\");\n  }\n  /**\n   *  @deprecated use the **instance** method with the same name instead\n   */\n  static performSelfAnalysis(parserInstance) {\n    throw Error(\"The **static** `performSelfAnalysis` method has been deprecated.\t\\nUse the **instance** method with the same name instead.\");\n  }\n  performSelfAnalysis() {\n    this.TRACE_INIT(\"performSelfAnalysis\", () => {\n      let defErrorsMsgs;\n      this.selfAnalysisDone = true;\n      const className = this.className;\n      this.TRACE_INIT(\"toFastProps\", () => {\n        toFastProperties(this);\n      });\n      this.TRACE_INIT(\"Grammar Recording\", () => {\n        try {\n          this.enableRecording();\n          forEach_default(this.definedRulesNames, (currRuleName) => {\n            const wrappedRule = this[currRuleName];\n            const originalGrammarAction = wrappedRule[\"originalGrammarAction\"];\n            let recordedRuleGast;\n            this.TRACE_INIT(`${currRuleName} Rule`, () => {\n              recordedRuleGast = this.topLevelRuleRecord(currRuleName, originalGrammarAction);\n            });\n            this.gastProductionsCache[currRuleName] = recordedRuleGast;\n          });\n        } finally {\n          this.disableRecording();\n        }\n      });\n      let resolverErrors = [];\n      this.TRACE_INIT(\"Grammar Resolving\", () => {\n        resolverErrors = resolveGrammar2({\n          rules: values_default(this.gastProductionsCache)\n        });\n        this.definitionErrors = this.definitionErrors.concat(resolverErrors);\n      });\n      this.TRACE_INIT(\"Grammar Validations\", () => {\n        if (isEmpty_default(resolverErrors) && this.skipValidations === false) {\n          const validationErrors = validateGrammar2({\n            rules: values_default(this.gastProductionsCache),\n            tokenTypes: values_default(this.tokensMap),\n            errMsgProvider: defaultGrammarValidatorErrorProvider,\n            grammarName: className\n          });\n          const lookaheadValidationErrors = validateLookahead({\n            lookaheadStrategy: this.lookaheadStrategy,\n            rules: values_default(this.gastProductionsCache),\n            tokenTypes: values_default(this.tokensMap),\n            grammarName: className\n          });\n          this.definitionErrors = this.definitionErrors.concat(validationErrors, lookaheadValidationErrors);\n        }\n      });\n      if (isEmpty_default(this.definitionErrors)) {\n        if (this.recoveryEnabled) {\n          this.TRACE_INIT(\"computeAllProdsFollows\", () => {\n            const allFollows = computeAllProdsFollows(values_default(this.gastProductionsCache));\n            this.resyncFollows = allFollows;\n          });\n        }\n        this.TRACE_INIT(\"ComputeLookaheadFunctions\", () => {\n          var _a, _b;\n          (_b = (_a = this.lookaheadStrategy).initialize) === null || _b === void 0 ? void 0 : _b.call(_a, {\n            rules: values_default(this.gastProductionsCache)\n          });\n          this.preComputeLookaheadFunctions(values_default(this.gastProductionsCache));\n        });\n      }\n      if (!_Parser.DEFER_DEFINITION_ERRORS_HANDLING && !isEmpty_default(this.definitionErrors)) {\n        defErrorsMsgs = map_default(this.definitionErrors, (defError) => defError.message);\n        throw new Error(`Parser Definition Errors detected:\n ${defErrorsMsgs.join(\"\\n-------------------------------\\n\")}`);\n      }\n    });\n  }\n  constructor(tokenVocabulary, config) {\n    this.definitionErrors = [];\n    this.selfAnalysisDone = false;\n    const that = this;\n    that.initErrorHandler(config);\n    that.initLexerAdapter();\n    that.initLooksAhead(config);\n    that.initRecognizerEngine(tokenVocabulary, config);\n    that.initRecoverable(config);\n    that.initTreeBuilder(config);\n    that.initContentAssist();\n    that.initGastRecorder(config);\n    that.initPerformanceTracer(config);\n    if (has_default(config, \"ignoredIssues\")) {\n      throw new Error(\"The <ignoredIssues> IParserConfig property has been deprecated.\\n\tPlease use the <IGNORE_AMBIGUITIES> flag on the relevant DSL method instead.\\n\tSee: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#IGNORING_AMBIGUITIES\\n\tFor further details.\");\n    }\n    this.skipValidations = has_default(config, \"skipValidations\") ? config.skipValidations : DEFAULT_PARSER_CONFIG.skipValidations;\n  }\n};\nParser.DEFER_DEFINITION_ERRORS_HANDLING = false;\napplyMixins(Parser, [\n  Recoverable,\n  LooksAhead,\n  TreeBuilder,\n  LexerAdapter,\n  RecognizerEngine,\n  RecognizerApi,\n  ErrorHandler,\n  ContentAssist,\n  GastRecorder,\n  PerformanceTracer\n]);\nvar EmbeddedActionsParser = class extends Parser {\n  static {\n    __name(this, \"EmbeddedActionsParser\");\n  }\n  constructor(tokenVocabulary, config = DEFAULT_PARSER_CONFIG) {\n    const configClone = clone_default(config);\n    configClone.outputCst = false;\n    super(tokenVocabulary, configClone);\n  }\n};\n\n// ../../node_modules/.pnpm/chevrotain-allstar@0.3.1_chevrotain@11.0.3/node_modules/chevrotain-allstar/lib/atn.js\nfunction buildATNKey(rule, type, occurrence) {\n  return `${rule.name}_${type}_${occurrence}`;\n}\n__name(buildATNKey, \"buildATNKey\");\nvar ATN_BASIC = 1;\nvar ATN_RULE_START = 2;\nvar ATN_PLUS_BLOCK_START = 4;\nvar ATN_STAR_BLOCK_START = 5;\nvar ATN_RULE_STOP = 7;\nvar ATN_BLOCK_END = 8;\nvar ATN_STAR_LOOP_BACK = 9;\nvar ATN_STAR_LOOP_ENTRY = 10;\nvar ATN_PLUS_LOOP_BACK = 11;\nvar ATN_LOOP_END = 12;\nvar AbstractTransition = class {\n  static {\n    __name(this, \"AbstractTransition\");\n  }\n  constructor(target) {\n    this.target = target;\n  }\n  isEpsilon() {\n    return false;\n  }\n};\nvar AtomTransition = class extends AbstractTransition {\n  static {\n    __name(this, \"AtomTransition\");\n  }\n  constructor(target, tokenType) {\n    super(target);\n    this.tokenType = tokenType;\n  }\n};\nvar EpsilonTransition = class extends AbstractTransition {\n  static {\n    __name(this, \"EpsilonTransition\");\n  }\n  constructor(target) {\n    super(target);\n  }\n  isEpsilon() {\n    return true;\n  }\n};\nvar RuleTransition = class extends AbstractTransition {\n  static {\n    __name(this, \"RuleTransition\");\n  }\n  constructor(ruleStart, rule, followState) {\n    super(ruleStart);\n    this.rule = rule;\n    this.followState = followState;\n  }\n  isEpsilon() {\n    return true;\n  }\n};\nfunction createATN(rules) {\n  const atn = {\n    decisionMap: {},\n    decisionStates: [],\n    ruleToStartState: /* @__PURE__ */ new Map(),\n    ruleToStopState: /* @__PURE__ */ new Map(),\n    states: []\n  };\n  createRuleStartAndStopATNStates(atn, rules);\n  const ruleLength = rules.length;\n  for (let i = 0; i < ruleLength; i++) {\n    const rule = rules[i];\n    const ruleBlock = block(atn, rule, rule);\n    if (ruleBlock === void 0) {\n      continue;\n    }\n    buildRuleHandle(atn, rule, ruleBlock);\n  }\n  return atn;\n}\n__name(createATN, \"createATN\");\nfunction createRuleStartAndStopATNStates(atn, rules) {\n  const ruleLength = rules.length;\n  for (let i = 0; i < ruleLength; i++) {\n    const rule = rules[i];\n    const start = newState(atn, rule, void 0, {\n      type: ATN_RULE_START\n    });\n    const stop = newState(atn, rule, void 0, {\n      type: ATN_RULE_STOP\n    });\n    start.stop = stop;\n    atn.ruleToStartState.set(rule, start);\n    atn.ruleToStopState.set(rule, stop);\n  }\n}\n__name(createRuleStartAndStopATNStates, \"createRuleStartAndStopATNStates\");\nfunction atom(atn, rule, production) {\n  if (production instanceof Terminal) {\n    return tokenRef(atn, rule, production.terminalType, production);\n  } else if (production instanceof NonTerminal) {\n    return ruleRef(atn, rule, production);\n  } else if (production instanceof Alternation) {\n    return alternation(atn, rule, production);\n  } else if (production instanceof Option) {\n    return option(atn, rule, production);\n  } else if (production instanceof Repetition) {\n    return repetition(atn, rule, production);\n  } else if (production instanceof RepetitionWithSeparator) {\n    return repetitionSep(atn, rule, production);\n  } else if (production instanceof RepetitionMandatory) {\n    return repetitionMandatory(atn, rule, production);\n  } else if (production instanceof RepetitionMandatoryWithSeparator) {\n    return repetitionMandatorySep(atn, rule, production);\n  } else {\n    return block(atn, rule, production);\n  }\n}\n__name(atom, \"atom\");\nfunction repetition(atn, rule, repetition2) {\n  const starState = newState(atn, rule, repetition2, {\n    type: ATN_STAR_BLOCK_START\n  });\n  defineDecisionState(atn, starState);\n  const handle = makeAlts(atn, rule, starState, repetition2, block(atn, rule, repetition2));\n  return star(atn, rule, repetition2, handle);\n}\n__name(repetition, \"repetition\");\nfunction repetitionSep(atn, rule, repetition2) {\n  const starState = newState(atn, rule, repetition2, {\n    type: ATN_STAR_BLOCK_START\n  });\n  defineDecisionState(atn, starState);\n  const handle = makeAlts(atn, rule, starState, repetition2, block(atn, rule, repetition2));\n  const sep = tokenRef(atn, rule, repetition2.separator, repetition2);\n  return star(atn, rule, repetition2, handle, sep);\n}\n__name(repetitionSep, \"repetitionSep\");\nfunction repetitionMandatory(atn, rule, repetition2) {\n  const plusState = newState(atn, rule, repetition2, {\n    type: ATN_PLUS_BLOCK_START\n  });\n  defineDecisionState(atn, plusState);\n  const handle = makeAlts(atn, rule, plusState, repetition2, block(atn, rule, repetition2));\n  return plus(atn, rule, repetition2, handle);\n}\n__name(repetitionMandatory, \"repetitionMandatory\");\nfunction repetitionMandatorySep(atn, rule, repetition2) {\n  const plusState = newState(atn, rule, repetition2, {\n    type: ATN_PLUS_BLOCK_START\n  });\n  defineDecisionState(atn, plusState);\n  const handle = makeAlts(atn, rule, plusState, repetition2, block(atn, rule, repetition2));\n  const sep = tokenRef(atn, rule, repetition2.separator, repetition2);\n  return plus(atn, rule, repetition2, handle, sep);\n}\n__name(repetitionMandatorySep, \"repetitionMandatorySep\");\nfunction alternation(atn, rule, alternation2) {\n  const start = newState(atn, rule, alternation2, {\n    type: ATN_BASIC\n  });\n  defineDecisionState(atn, start);\n  const alts = map_default(alternation2.definition, (e) => atom(atn, rule, e));\n  const handle = makeAlts(atn, rule, start, alternation2, ...alts);\n  return handle;\n}\n__name(alternation, \"alternation\");\nfunction option(atn, rule, option2) {\n  const start = newState(atn, rule, option2, {\n    type: ATN_BASIC\n  });\n  defineDecisionState(atn, start);\n  const handle = makeAlts(atn, rule, start, option2, block(atn, rule, option2));\n  return optional(atn, rule, option2, handle);\n}\n__name(option, \"option\");\nfunction block(atn, rule, block2) {\n  const handles = filter_default(map_default(block2.definition, (e) => atom(atn, rule, e)), (e) => e !== void 0);\n  if (handles.length === 1) {\n    return handles[0];\n  } else if (handles.length === 0) {\n    return void 0;\n  } else {\n    return makeBlock(atn, handles);\n  }\n}\n__name(block, \"block\");\nfunction plus(atn, rule, plus2, handle, sep) {\n  const blkStart = handle.left;\n  const blkEnd = handle.right;\n  const loop = newState(atn, rule, plus2, {\n    type: ATN_PLUS_LOOP_BACK\n  });\n  defineDecisionState(atn, loop);\n  const end = newState(atn, rule, plus2, {\n    type: ATN_LOOP_END\n  });\n  blkStart.loopback = loop;\n  end.loopback = loop;\n  atn.decisionMap[buildATNKey(rule, sep ? \"RepetitionMandatoryWithSeparator\" : \"RepetitionMandatory\", plus2.idx)] = loop;\n  epsilon(blkEnd, loop);\n  if (sep === void 0) {\n    epsilon(loop, blkStart);\n    epsilon(loop, end);\n  } else {\n    epsilon(loop, end);\n    epsilon(loop, sep.left);\n    epsilon(sep.right, blkStart);\n  }\n  return {\n    left: blkStart,\n    right: end\n  };\n}\n__name(plus, \"plus\");\nfunction star(atn, rule, star2, handle, sep) {\n  const start = handle.left;\n  const end = handle.right;\n  const entry = newState(atn, rule, star2, {\n    type: ATN_STAR_LOOP_ENTRY\n  });\n  defineDecisionState(atn, entry);\n  const loopEnd = newState(atn, rule, star2, {\n    type: ATN_LOOP_END\n  });\n  const loop = newState(atn, rule, star2, {\n    type: ATN_STAR_LOOP_BACK\n  });\n  entry.loopback = loop;\n  loopEnd.loopback = loop;\n  epsilon(entry, start);\n  epsilon(entry, loopEnd);\n  epsilon(end, loop);\n  if (sep !== void 0) {\n    epsilon(loop, loopEnd);\n    epsilon(loop, sep.left);\n    epsilon(sep.right, start);\n  } else {\n    epsilon(loop, entry);\n  }\n  atn.decisionMap[buildATNKey(rule, sep ? \"RepetitionWithSeparator\" : \"Repetition\", star2.idx)] = entry;\n  return {\n    left: entry,\n    right: loopEnd\n  };\n}\n__name(star, \"star\");\nfunction optional(atn, rule, optional2, handle) {\n  const start = handle.left;\n  const end = handle.right;\n  epsilon(start, end);\n  atn.decisionMap[buildATNKey(rule, \"Option\", optional2.idx)] = start;\n  return handle;\n}\n__name(optional, \"optional\");\nfunction defineDecisionState(atn, state) {\n  atn.decisionStates.push(state);\n  state.decision = atn.decisionStates.length - 1;\n  return state.decision;\n}\n__name(defineDecisionState, \"defineDecisionState\");\nfunction makeAlts(atn, rule, start, production, ...alts) {\n  const end = newState(atn, rule, production, {\n    type: ATN_BLOCK_END,\n    start\n  });\n  start.end = end;\n  for (const alt of alts) {\n    if (alt !== void 0) {\n      epsilon(start, alt.left);\n      epsilon(alt.right, end);\n    } else {\n      epsilon(start, end);\n    }\n  }\n  const handle = {\n    left: start,\n    right: end\n  };\n  atn.decisionMap[buildATNKey(rule, getProdType2(production), production.idx)] = start;\n  return handle;\n}\n__name(makeAlts, \"makeAlts\");\nfunction getProdType2(production) {\n  if (production instanceof Alternation) {\n    return \"Alternation\";\n  } else if (production instanceof Option) {\n    return \"Option\";\n  } else if (production instanceof Repetition) {\n    return \"Repetition\";\n  } else if (production instanceof RepetitionWithSeparator) {\n    return \"RepetitionWithSeparator\";\n  } else if (production instanceof RepetitionMandatory) {\n    return \"RepetitionMandatory\";\n  } else if (production instanceof RepetitionMandatoryWithSeparator) {\n    return \"RepetitionMandatoryWithSeparator\";\n  } else {\n    throw new Error(\"Invalid production type encountered\");\n  }\n}\n__name(getProdType2, \"getProdType\");\nfunction makeBlock(atn, alts) {\n  const altsLength = alts.length;\n  for (let i = 0; i < altsLength - 1; i++) {\n    const handle = alts[i];\n    let transition;\n    if (handle.left.transitions.length === 1) {\n      transition = handle.left.transitions[0];\n    }\n    const isRuleTransition = transition instanceof RuleTransition;\n    const ruleTransition = transition;\n    const next = alts[i + 1].left;\n    if (handle.left.type === ATN_BASIC && handle.right.type === ATN_BASIC && transition !== void 0 && (isRuleTransition && ruleTransition.followState === handle.right || transition.target === handle.right)) {\n      if (isRuleTransition) {\n        ruleTransition.followState = next;\n      } else {\n        transition.target = next;\n      }\n      removeState(atn, handle.right);\n    } else {\n      epsilon(handle.right, next);\n    }\n  }\n  const first2 = alts[0];\n  const last = alts[altsLength - 1];\n  return {\n    left: first2.left,\n    right: last.right\n  };\n}\n__name(makeBlock, \"makeBlock\");\nfunction tokenRef(atn, rule, tokenType, production) {\n  const left = newState(atn, rule, production, {\n    type: ATN_BASIC\n  });\n  const right = newState(atn, rule, production, {\n    type: ATN_BASIC\n  });\n  addTransition(left, new AtomTransition(right, tokenType));\n  return {\n    left,\n    right\n  };\n}\n__name(tokenRef, \"tokenRef\");\nfunction ruleRef(atn, currentRule, nonTerminal) {\n  const rule = nonTerminal.referencedRule;\n  const start = atn.ruleToStartState.get(rule);\n  const left = newState(atn, currentRule, nonTerminal, {\n    type: ATN_BASIC\n  });\n  const right = newState(atn, currentRule, nonTerminal, {\n    type: ATN_BASIC\n  });\n  const call = new RuleTransition(start, rule, right);\n  addTransition(left, call);\n  return {\n    left,\n    right\n  };\n}\n__name(ruleRef, \"ruleRef\");\nfunction buildRuleHandle(atn, rule, block2) {\n  const start = atn.ruleToStartState.get(rule);\n  epsilon(start, block2.left);\n  const stop = atn.ruleToStopState.get(rule);\n  epsilon(block2.right, stop);\n  const handle = {\n    left: start,\n    right: stop\n  };\n  return handle;\n}\n__name(buildRuleHandle, \"buildRuleHandle\");\nfunction epsilon(a, b) {\n  const transition = new EpsilonTransition(b);\n  addTransition(a, transition);\n}\n__name(epsilon, \"epsilon\");\nfunction newState(atn, rule, production, partial) {\n  const t = Object.assign({\n    atn,\n    production,\n    epsilonOnlyTransitions: false,\n    rule,\n    transitions: [],\n    nextTokenWithinRule: [],\n    stateNumber: atn.states.length\n  }, partial);\n  atn.states.push(t);\n  return t;\n}\n__name(newState, \"newState\");\nfunction addTransition(state, transition) {\n  if (state.transitions.length === 0) {\n    state.epsilonOnlyTransitions = transition.isEpsilon();\n  }\n  state.transitions.push(transition);\n}\n__name(addTransition, \"addTransition\");\nfunction removeState(atn, state) {\n  atn.states.splice(atn.states.indexOf(state), 1);\n}\n__name(removeState, \"removeState\");\n\n// ../../node_modules/.pnpm/chevrotain-allstar@0.3.1_chevrotain@11.0.3/node_modules/chevrotain-allstar/lib/dfa.js\nvar DFA_ERROR = {};\nvar ATNConfigSet = class {\n  static {\n    __name(this, \"ATNConfigSet\");\n  }\n  constructor() {\n    this.map = {};\n    this.configs = [];\n  }\n  get size() {\n    return this.configs.length;\n  }\n  finalize() {\n    this.map = {};\n  }\n  add(config) {\n    const key = getATNConfigKey(config);\n    if (!(key in this.map)) {\n      this.map[key] = this.configs.length;\n      this.configs.push(config);\n    }\n  }\n  get elements() {\n    return this.configs;\n  }\n  get alts() {\n    return map_default(this.configs, (e) => e.alt);\n  }\n  get key() {\n    let value = \"\";\n    for (const k in this.map) {\n      value += k + \":\";\n    }\n    return value;\n  }\n};\nfunction getATNConfigKey(config, alt = true) {\n  return `${alt ? `a${config.alt}` : \"\"}s${config.state.stateNumber}:${config.stack.map((e) => e.stateNumber.toString()).join(\"_\")}`;\n}\n__name(getATNConfigKey, \"getATNConfigKey\");\n\n// ../../node_modules/.pnpm/chevrotain-allstar@0.3.1_chevrotain@11.0.3/node_modules/chevrotain-allstar/lib/all-star-lookahead.js\nfunction createDFACache(startState, decision) {\n  const map = {};\n  return (predicateSet) => {\n    const key = predicateSet.toString();\n    let existing = map[key];\n    if (existing !== void 0) {\n      return existing;\n    } else {\n      existing = {\n        atnStartState: startState,\n        decision,\n        states: {}\n      };\n      map[key] = existing;\n      return existing;\n    }\n  };\n}\n__name(createDFACache, \"createDFACache\");\nvar PredicateSet = class {\n  static {\n    __name(this, \"PredicateSet\");\n  }\n  constructor() {\n    this.predicates = [];\n  }\n  is(index) {\n    return index >= this.predicates.length || this.predicates[index];\n  }\n  set(index, value) {\n    this.predicates[index] = value;\n  }\n  toString() {\n    let value = \"\";\n    const size = this.predicates.length;\n    for (let i = 0; i < size; i++) {\n      value += this.predicates[i] === true ? \"1\" : \"0\";\n    }\n    return value;\n  }\n};\nvar EMPTY_PREDICATES = new PredicateSet();\nvar LLStarLookaheadStrategy = class extends LLkLookaheadStrategy {\n  static {\n    __name(this, \"LLStarLookaheadStrategy\");\n  }\n  constructor(options) {\n    var _a;\n    super();\n    this.logging = (_a = options === null || options === void 0 ? void 0 : options.logging) !== null && _a !== void 0 ? _a : (message) => console.log(message);\n  }\n  initialize(options) {\n    this.atn = createATN(options.rules);\n    this.dfas = initATNSimulator(this.atn);\n  }\n  validateAmbiguousAlternationAlternatives() {\n    return [];\n  }\n  validateEmptyOrAlternatives() {\n    return [];\n  }\n  buildLookaheadForAlternation(options) {\n    const { prodOccurrence, rule, hasPredicates, dynamicTokensEnabled } = options;\n    const dfas = this.dfas;\n    const logging = this.logging;\n    const key = buildATNKey(rule, \"Alternation\", prodOccurrence);\n    const decisionState = this.atn.decisionMap[key];\n    const decisionIndex = decisionState.decision;\n    const partialAlts = map_default(getLookaheadPaths({\n      maxLookahead: 1,\n      occurrence: prodOccurrence,\n      prodType: \"Alternation\",\n      rule\n    }), (currAlt) => map_default(currAlt, (path) => path[0]));\n    if (isLL1Sequence(partialAlts, false) && !dynamicTokensEnabled) {\n      const choiceToAlt = reduce_default(partialAlts, (result, currAlt, idx) => {\n        forEach_default(currAlt, (currTokType) => {\n          if (currTokType) {\n            result[currTokType.tokenTypeIdx] = idx;\n            forEach_default(currTokType.categoryMatches, (currExtendingType) => {\n              result[currExtendingType] = idx;\n            });\n          }\n        });\n        return result;\n      }, {});\n      if (hasPredicates) {\n        return function(orAlts) {\n          var _a;\n          const nextToken = this.LA(1);\n          const prediction = choiceToAlt[nextToken.tokenTypeIdx];\n          if (orAlts !== void 0 && prediction !== void 0) {\n            const gate = (_a = orAlts[prediction]) === null || _a === void 0 ? void 0 : _a.GATE;\n            if (gate !== void 0 && gate.call(this) === false) {\n              return void 0;\n            }\n          }\n          return prediction;\n        };\n      } else {\n        return function() {\n          const nextToken = this.LA(1);\n          return choiceToAlt[nextToken.tokenTypeIdx];\n        };\n      }\n    } else if (hasPredicates) {\n      return function(orAlts) {\n        const predicates = new PredicateSet();\n        const length = orAlts === void 0 ? 0 : orAlts.length;\n        for (let i = 0; i < length; i++) {\n          const gate = orAlts === null || orAlts === void 0 ? void 0 : orAlts[i].GATE;\n          predicates.set(i, gate === void 0 || gate.call(this));\n        }\n        const result = adaptivePredict.call(this, dfas, decisionIndex, predicates, logging);\n        return typeof result === \"number\" ? result : void 0;\n      };\n    } else {\n      return function() {\n        const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging);\n        return typeof result === \"number\" ? result : void 0;\n      };\n    }\n  }\n  buildLookaheadForOptional(options) {\n    const { prodOccurrence, rule, prodType, dynamicTokensEnabled } = options;\n    const dfas = this.dfas;\n    const logging = this.logging;\n    const key = buildATNKey(rule, prodType, prodOccurrence);\n    const decisionState = this.atn.decisionMap[key];\n    const decisionIndex = decisionState.decision;\n    const alts = map_default(getLookaheadPaths({\n      maxLookahead: 1,\n      occurrence: prodOccurrence,\n      prodType,\n      rule\n    }), (e) => {\n      return map_default(e, (g) => g[0]);\n    });\n    if (isLL1Sequence(alts) && alts[0][0] && !dynamicTokensEnabled) {\n      const alt = alts[0];\n      const singleTokensTypes = flatten_default(alt);\n      if (singleTokensTypes.length === 1 && isEmpty_default(singleTokensTypes[0].categoryMatches)) {\n        const expectedTokenType = singleTokensTypes[0];\n        const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx;\n        return function() {\n          return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n        };\n      } else {\n        const choiceToAlt = reduce_default(singleTokensTypes, (result, currTokType) => {\n          if (currTokType !== void 0) {\n            result[currTokType.tokenTypeIdx] = true;\n            forEach_default(currTokType.categoryMatches, (currExtendingType) => {\n              result[currExtendingType] = true;\n            });\n          }\n          return result;\n        }, {});\n        return function() {\n          const nextToken = this.LA(1);\n          return choiceToAlt[nextToken.tokenTypeIdx] === true;\n        };\n      }\n    }\n    return function() {\n      const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging);\n      return typeof result === \"object\" ? false : result === 0;\n    };\n  }\n};\nfunction isLL1Sequence(sequences, allowEmpty = true) {\n  const fullSet = /* @__PURE__ */ new Set();\n  for (const alt of sequences) {\n    const altSet = /* @__PURE__ */ new Set();\n    for (const tokType of alt) {\n      if (tokType === void 0) {\n        if (allowEmpty) {\n          break;\n        } else {\n          return false;\n        }\n      }\n      const indices = [tokType.tokenTypeIdx].concat(tokType.categoryMatches);\n      for (const index of indices) {\n        if (fullSet.has(index)) {\n          if (!altSet.has(index)) {\n            return false;\n          }\n        } else {\n          fullSet.add(index);\n          altSet.add(index);\n        }\n      }\n    }\n  }\n  return true;\n}\n__name(isLL1Sequence, \"isLL1Sequence\");\nfunction initATNSimulator(atn) {\n  const decisionLength = atn.decisionStates.length;\n  const decisionToDFA = Array(decisionLength);\n  for (let i = 0; i < decisionLength; i++) {\n    decisionToDFA[i] = createDFACache(atn.decisionStates[i], i);\n  }\n  return decisionToDFA;\n}\n__name(initATNSimulator, \"initATNSimulator\");\nfunction adaptivePredict(dfaCaches, decision, predicateSet, logging) {\n  const dfa = dfaCaches[decision](predicateSet);\n  let start = dfa.start;\n  if (start === void 0) {\n    const closure2 = computeStartState(dfa.atnStartState);\n    start = addDFAState(dfa, newDFAState(closure2));\n    dfa.start = start;\n  }\n  const alt = performLookahead.apply(this, [dfa, start, predicateSet, logging]);\n  return alt;\n}\n__name(adaptivePredict, \"adaptivePredict\");\nfunction performLookahead(dfa, s0, predicateSet, logging) {\n  let previousD = s0;\n  let i = 1;\n  const path = [];\n  let t = this.LA(i++);\n  while (true) {\n    let d = getExistingTargetState(previousD, t);\n    if (d === void 0) {\n      d = computeLookaheadTarget.apply(this, [dfa, previousD, t, i, predicateSet, logging]);\n    }\n    if (d === DFA_ERROR) {\n      return buildAdaptivePredictError(path, previousD, t);\n    }\n    if (d.isAcceptState === true) {\n      return d.prediction;\n    }\n    previousD = d;\n    path.push(t);\n    t = this.LA(i++);\n  }\n}\n__name(performLookahead, \"performLookahead\");\nfunction computeLookaheadTarget(dfa, previousD, token, lookahead, predicateSet, logging) {\n  const reach = computeReachSet(previousD.configs, token, predicateSet);\n  if (reach.size === 0) {\n    addDFAEdge(dfa, previousD, token, DFA_ERROR);\n    return DFA_ERROR;\n  }\n  let newState2 = newDFAState(reach);\n  const predictedAlt = getUniqueAlt(reach, predicateSet);\n  if (predictedAlt !== void 0) {\n    newState2.isAcceptState = true;\n    newState2.prediction = predictedAlt;\n    newState2.configs.uniqueAlt = predictedAlt;\n  } else if (hasConflictTerminatingPrediction(reach)) {\n    const prediction = min_default(reach.alts);\n    newState2.isAcceptState = true;\n    newState2.prediction = prediction;\n    newState2.configs.uniqueAlt = prediction;\n    reportLookaheadAmbiguity.apply(this, [dfa, lookahead, reach.alts, logging]);\n  }\n  newState2 = addDFAEdge(dfa, previousD, token, newState2);\n  return newState2;\n}\n__name(computeLookaheadTarget, \"computeLookaheadTarget\");\nfunction reportLookaheadAmbiguity(dfa, lookahead, ambiguityIndices, logging) {\n  const prefixPath = [];\n  for (let i = 1; i <= lookahead; i++) {\n    prefixPath.push(this.LA(i).tokenType);\n  }\n  const atnState = dfa.atnStartState;\n  const topLevelRule = atnState.rule;\n  const production = atnState.production;\n  const message = buildAmbiguityError({\n    topLevelRule,\n    ambiguityIndices,\n    production,\n    prefixPath\n  });\n  logging(message);\n}\n__name(reportLookaheadAmbiguity, \"reportLookaheadAmbiguity\");\nfunction buildAmbiguityError(options) {\n  const pathMsg = map_default(options.prefixPath, (currtok) => tokenLabel2(currtok)).join(\", \");\n  const occurrence = options.production.idx === 0 ? \"\" : options.production.idx;\n  let currMessage = `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\", \")}> in <${getProductionDslName2(options.production)}${occurrence}> inside <${options.topLevelRule.name}> Rule,\n<${pathMsg}> may appears as a prefix path in all these alternatives.\n`;\n  currMessage = currMessage + `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\nFor Further details.`;\n  return currMessage;\n}\n__name(buildAmbiguityError, \"buildAmbiguityError\");\nfunction getProductionDslName2(prod) {\n  if (prod instanceof NonTerminal) {\n    return \"SUBRULE\";\n  } else if (prod instanceof Option) {\n    return \"OPTION\";\n  } else if (prod instanceof Alternation) {\n    return \"OR\";\n  } else if (prod instanceof RepetitionMandatory) {\n    return \"AT_LEAST_ONE\";\n  } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n    return \"AT_LEAST_ONE_SEP\";\n  } else if (prod instanceof RepetitionWithSeparator) {\n    return \"MANY_SEP\";\n  } else if (prod instanceof Repetition) {\n    return \"MANY\";\n  } else if (prod instanceof Terminal) {\n    return \"CONSUME\";\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n__name(getProductionDslName2, \"getProductionDslName\");\nfunction buildAdaptivePredictError(path, previous, current) {\n  const nextTransitions = flatMap_default(previous.configs.elements, (e) => e.state.transitions);\n  const nextTokenTypes = uniqBy_default(nextTransitions.filter((e) => e instanceof AtomTransition).map((e) => e.tokenType), (e) => e.tokenTypeIdx);\n  return {\n    actualToken: current,\n    possibleTokenTypes: nextTokenTypes,\n    tokenPath: path\n  };\n}\n__name(buildAdaptivePredictError, \"buildAdaptivePredictError\");\nfunction getExistingTargetState(state, token) {\n  return state.edges[token.tokenTypeIdx];\n}\n__name(getExistingTargetState, \"getExistingTargetState\");\nfunction computeReachSet(configs, token, predicateSet) {\n  const intermediate = new ATNConfigSet();\n  const skippedStopStates = [];\n  for (const c of configs.elements) {\n    if (predicateSet.is(c.alt) === false) {\n      continue;\n    }\n    if (c.state.type === ATN_RULE_STOP) {\n      skippedStopStates.push(c);\n      continue;\n    }\n    const transitionLength = c.state.transitions.length;\n    for (let i = 0; i < transitionLength; i++) {\n      const transition = c.state.transitions[i];\n      const target = getReachableTarget(transition, token);\n      if (target !== void 0) {\n        intermediate.add({\n          state: target,\n          alt: c.alt,\n          stack: c.stack\n        });\n      }\n    }\n  }\n  let reach;\n  if (skippedStopStates.length === 0 && intermediate.size === 1) {\n    reach = intermediate;\n  }\n  if (reach === void 0) {\n    reach = new ATNConfigSet();\n    for (const c of intermediate.elements) {\n      closure(c, reach);\n    }\n  }\n  if (skippedStopStates.length > 0 && !hasConfigInRuleStopState(reach)) {\n    for (const c of skippedStopStates) {\n      reach.add(c);\n    }\n  }\n  return reach;\n}\n__name(computeReachSet, \"computeReachSet\");\nfunction getReachableTarget(transition, token) {\n  if (transition instanceof AtomTransition && tokenMatcher(token, transition.tokenType)) {\n    return transition.target;\n  }\n  return void 0;\n}\n__name(getReachableTarget, \"getReachableTarget\");\nfunction getUniqueAlt(configs, predicateSet) {\n  let alt;\n  for (const c of configs.elements) {\n    if (predicateSet.is(c.alt) === true) {\n      if (alt === void 0) {\n        alt = c.alt;\n      } else if (alt !== c.alt) {\n        return void 0;\n      }\n    }\n  }\n  return alt;\n}\n__name(getUniqueAlt, \"getUniqueAlt\");\nfunction newDFAState(closure2) {\n  return {\n    configs: closure2,\n    edges: {},\n    isAcceptState: false,\n    prediction: -1\n  };\n}\n__name(newDFAState, \"newDFAState\");\nfunction addDFAEdge(dfa, from, token, to) {\n  to = addDFAState(dfa, to);\n  from.edges[token.tokenTypeIdx] = to;\n  return to;\n}\n__name(addDFAEdge, \"addDFAEdge\");\nfunction addDFAState(dfa, state) {\n  if (state === DFA_ERROR) {\n    return state;\n  }\n  const mapKey = state.configs.key;\n  const existing = dfa.states[mapKey];\n  if (existing !== void 0) {\n    return existing;\n  }\n  state.configs.finalize();\n  dfa.states[mapKey] = state;\n  return state;\n}\n__name(addDFAState, \"addDFAState\");\nfunction computeStartState(atnState) {\n  const configs = new ATNConfigSet();\n  const numberOfTransitions = atnState.transitions.length;\n  for (let i = 0; i < numberOfTransitions; i++) {\n    const target = atnState.transitions[i].target;\n    const config = {\n      state: target,\n      alt: i,\n      stack: []\n    };\n    closure(config, configs);\n  }\n  return configs;\n}\n__name(computeStartState, \"computeStartState\");\nfunction closure(config, configs) {\n  const p = config.state;\n  if (p.type === ATN_RULE_STOP) {\n    if (config.stack.length > 0) {\n      const atnStack = [...config.stack];\n      const followState = atnStack.pop();\n      const followConfig = {\n        state: followState,\n        alt: config.alt,\n        stack: atnStack\n      };\n      closure(followConfig, configs);\n    } else {\n      configs.add(config);\n    }\n    return;\n  }\n  if (!p.epsilonOnlyTransitions) {\n    configs.add(config);\n  }\n  const transitionLength = p.transitions.length;\n  for (let i = 0; i < transitionLength; i++) {\n    const transition = p.transitions[i];\n    const c = getEpsilonTarget(config, transition);\n    if (c !== void 0) {\n      closure(c, configs);\n    }\n  }\n}\n__name(closure, \"closure\");\nfunction getEpsilonTarget(config, transition) {\n  if (transition instanceof EpsilonTransition) {\n    return {\n      state: transition.target,\n      alt: config.alt,\n      stack: config.stack\n    };\n  } else if (transition instanceof RuleTransition) {\n    const stack = [...config.stack, transition.followState];\n    return {\n      state: transition.target,\n      alt: config.alt,\n      stack\n    };\n  }\n  return void 0;\n}\n__name(getEpsilonTarget, \"getEpsilonTarget\");\nfunction hasConfigInRuleStopState(configs) {\n  for (const c of configs.elements) {\n    if (c.state.type === ATN_RULE_STOP) {\n      return true;\n    }\n  }\n  return false;\n}\n__name(hasConfigInRuleStopState, \"hasConfigInRuleStopState\");\nfunction allConfigsInRuleStopStates(configs) {\n  for (const c of configs.elements) {\n    if (c.state.type !== ATN_RULE_STOP) {\n      return false;\n    }\n  }\n  return true;\n}\n__name(allConfigsInRuleStopStates, \"allConfigsInRuleStopStates\");\nfunction hasConflictTerminatingPrediction(configs) {\n  if (allConfigsInRuleStopStates(configs)) {\n    return true;\n  }\n  const altSets = getConflictingAltSets(configs.elements);\n  const heuristic = hasConflictingAltSet(altSets) && !hasStateAssociatedWithOneAlt(altSets);\n  return heuristic;\n}\n__name(hasConflictTerminatingPrediction, \"hasConflictTerminatingPrediction\");\nfunction getConflictingAltSets(configs) {\n  const configToAlts = /* @__PURE__ */ new Map();\n  for (const c of configs) {\n    const key = getATNConfigKey(c, false);\n    let alts = configToAlts.get(key);\n    if (alts === void 0) {\n      alts = {};\n      configToAlts.set(key, alts);\n    }\n    alts[c.alt] = true;\n  }\n  return configToAlts;\n}\n__name(getConflictingAltSets, \"getConflictingAltSets\");\nfunction hasConflictingAltSet(altSets) {\n  for (const value of Array.from(altSets.values())) {\n    if (Object.keys(value).length > 1) {\n      return true;\n    }\n  }\n  return false;\n}\n__name(hasConflictingAltSet, \"hasConflictingAltSet\");\nfunction hasStateAssociatedWithOneAlt(altSets) {\n  for (const value of Array.from(altSets.values())) {\n    if (Object.keys(value).length === 1) {\n      return true;\n    }\n  }\n  return false;\n}\n__name(hasStateAssociatedWithOneAlt, \"hasStateAssociatedWithOneAlt\");\n\n// ../../node_modules/.pnpm/vscode-languageserver-types@3.17.5/node_modules/vscode-languageserver-types/lib/esm/main.js\nvar DocumentUri;\n(function(DocumentUri2) {\n  function is(value) {\n    return typeof value === \"string\";\n  }\n  __name(is, \"is\");\n  DocumentUri2.is = is;\n})(DocumentUri || (DocumentUri = {}));\nvar URI;\n(function(URI3) {\n  function is(value) {\n    return typeof value === \"string\";\n  }\n  __name(is, \"is\");\n  URI3.is = is;\n})(URI || (URI = {}));\nvar integer;\n(function(integer2) {\n  integer2.MIN_VALUE = -2147483648;\n  integer2.MAX_VALUE = 2147483647;\n  function is(value) {\n    return typeof value === \"number\" && integer2.MIN_VALUE <= value && value <= integer2.MAX_VALUE;\n  }\n  __name(is, \"is\");\n  integer2.is = is;\n})(integer || (integer = {}));\nvar uinteger;\n(function(uinteger2) {\n  uinteger2.MIN_VALUE = 0;\n  uinteger2.MAX_VALUE = 2147483647;\n  function is(value) {\n    return typeof value === \"number\" && uinteger2.MIN_VALUE <= value && value <= uinteger2.MAX_VALUE;\n  }\n  __name(is, \"is\");\n  uinteger2.is = is;\n})(uinteger || (uinteger = {}));\nvar Position;\n(function(Position2) {\n  function create(line, character) {\n    if (line === Number.MAX_VALUE) {\n      line = uinteger.MAX_VALUE;\n    }\n    if (character === Number.MAX_VALUE) {\n      character = uinteger.MAX_VALUE;\n    }\n    return { line, character };\n  }\n  __name(create, \"create\");\n  Position2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.objectLiteral(candidate) && Is.uinteger(candidate.line) && Is.uinteger(candidate.character);\n  }\n  __name(is, \"is\");\n  Position2.is = is;\n})(Position || (Position = {}));\nvar Range;\n(function(Range2) {\n  function create(one, two, three, four) {\n    if (Is.uinteger(one) && Is.uinteger(two) && Is.uinteger(three) && Is.uinteger(four)) {\n      return { start: Position.create(one, two), end: Position.create(three, four) };\n    } else if (Position.is(one) && Position.is(two)) {\n      return { start: one, end: two };\n    } else {\n      throw new Error(`Range#create called with invalid arguments[${one}, ${two}, ${three}, ${four}]`);\n    }\n  }\n  __name(create, \"create\");\n  Range2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.objectLiteral(candidate) && Position.is(candidate.start) && Position.is(candidate.end);\n  }\n  __name(is, \"is\");\n  Range2.is = is;\n})(Range || (Range = {}));\nvar Location;\n(function(Location2) {\n  function create(uri, range) {\n    return { uri, range };\n  }\n  __name(create, \"create\");\n  Location2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.objectLiteral(candidate) && Range.is(candidate.range) && (Is.string(candidate.uri) || Is.undefined(candidate.uri));\n  }\n  __name(is, \"is\");\n  Location2.is = is;\n})(Location || (Location = {}));\nvar LocationLink;\n(function(LocationLink2) {\n  function create(targetUri, targetRange, targetSelectionRange, originSelectionRange) {\n    return { targetUri, targetRange, targetSelectionRange, originSelectionRange };\n  }\n  __name(create, \"create\");\n  LocationLink2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.objectLiteral(candidate) && Range.is(candidate.targetRange) && Is.string(candidate.targetUri) && Range.is(candidate.targetSelectionRange) && (Range.is(candidate.originSelectionRange) || Is.undefined(candidate.originSelectionRange));\n  }\n  __name(is, \"is\");\n  LocationLink2.is = is;\n})(LocationLink || (LocationLink = {}));\nvar Color;\n(function(Color2) {\n  function create(red, green, blue, alpha) {\n    return {\n      red,\n      green,\n      blue,\n      alpha\n    };\n  }\n  __name(create, \"create\");\n  Color2.create = create;\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && Is.numberRange(candidate.red, 0, 1) && Is.numberRange(candidate.green, 0, 1) && Is.numberRange(candidate.blue, 0, 1) && Is.numberRange(candidate.alpha, 0, 1);\n  }\n  __name(is, \"is\");\n  Color2.is = is;\n})(Color || (Color = {}));\nvar ColorInformation;\n(function(ColorInformation2) {\n  function create(range, color) {\n    return {\n      range,\n      color\n    };\n  }\n  __name(create, \"create\");\n  ColorInformation2.create = create;\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && Range.is(candidate.range) && Color.is(candidate.color);\n  }\n  __name(is, \"is\");\n  ColorInformation2.is = is;\n})(ColorInformation || (ColorInformation = {}));\nvar ColorPresentation;\n(function(ColorPresentation2) {\n  function create(label, textEdit, additionalTextEdits) {\n    return {\n      label,\n      textEdit,\n      additionalTextEdits\n    };\n  }\n  __name(create, \"create\");\n  ColorPresentation2.create = create;\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && Is.string(candidate.label) && (Is.undefined(candidate.textEdit) || TextEdit.is(candidate)) && (Is.undefined(candidate.additionalTextEdits) || Is.typedArray(candidate.additionalTextEdits, TextEdit.is));\n  }\n  __name(is, \"is\");\n  ColorPresentation2.is = is;\n})(ColorPresentation || (ColorPresentation = {}));\nvar FoldingRangeKind;\n(function(FoldingRangeKind2) {\n  FoldingRangeKind2.Comment = \"comment\";\n  FoldingRangeKind2.Imports = \"imports\";\n  FoldingRangeKind2.Region = \"region\";\n})(FoldingRangeKind || (FoldingRangeKind = {}));\nvar FoldingRange;\n(function(FoldingRange2) {\n  function create(startLine, endLine, startCharacter, endCharacter, kind, collapsedText) {\n    const result = {\n      startLine,\n      endLine\n    };\n    if (Is.defined(startCharacter)) {\n      result.startCharacter = startCharacter;\n    }\n    if (Is.defined(endCharacter)) {\n      result.endCharacter = endCharacter;\n    }\n    if (Is.defined(kind)) {\n      result.kind = kind;\n    }\n    if (Is.defined(collapsedText)) {\n      result.collapsedText = collapsedText;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  FoldingRange2.create = create;\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && Is.uinteger(candidate.startLine) && Is.uinteger(candidate.startLine) && (Is.undefined(candidate.startCharacter) || Is.uinteger(candidate.startCharacter)) && (Is.undefined(candidate.endCharacter) || Is.uinteger(candidate.endCharacter)) && (Is.undefined(candidate.kind) || Is.string(candidate.kind));\n  }\n  __name(is, \"is\");\n  FoldingRange2.is = is;\n})(FoldingRange || (FoldingRange = {}));\nvar DiagnosticRelatedInformation;\n(function(DiagnosticRelatedInformation2) {\n  function create(location, message) {\n    return {\n      location,\n      message\n    };\n  }\n  __name(create, \"create\");\n  DiagnosticRelatedInformation2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Location.is(candidate.location) && Is.string(candidate.message);\n  }\n  __name(is, \"is\");\n  DiagnosticRelatedInformation2.is = is;\n})(DiagnosticRelatedInformation || (DiagnosticRelatedInformation = {}));\nvar DiagnosticSeverity;\n(function(DiagnosticSeverity2) {\n  DiagnosticSeverity2.Error = 1;\n  DiagnosticSeverity2.Warning = 2;\n  DiagnosticSeverity2.Information = 3;\n  DiagnosticSeverity2.Hint = 4;\n})(DiagnosticSeverity || (DiagnosticSeverity = {}));\nvar DiagnosticTag;\n(function(DiagnosticTag2) {\n  DiagnosticTag2.Unnecessary = 1;\n  DiagnosticTag2.Deprecated = 2;\n})(DiagnosticTag || (DiagnosticTag = {}));\nvar CodeDescription;\n(function(CodeDescription2) {\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && Is.string(candidate.href);\n  }\n  __name(is, \"is\");\n  CodeDescription2.is = is;\n})(CodeDescription || (CodeDescription = {}));\nvar Diagnostic;\n(function(Diagnostic2) {\n  function create(range, message, severity, code, source, relatedInformation) {\n    let result = { range, message };\n    if (Is.defined(severity)) {\n      result.severity = severity;\n    }\n    if (Is.defined(code)) {\n      result.code = code;\n    }\n    if (Is.defined(source)) {\n      result.source = source;\n    }\n    if (Is.defined(relatedInformation)) {\n      result.relatedInformation = relatedInformation;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  Diagnostic2.create = create;\n  function is(value) {\n    var _a;\n    let candidate = value;\n    return Is.defined(candidate) && Range.is(candidate.range) && Is.string(candidate.message) && (Is.number(candidate.severity) || Is.undefined(candidate.severity)) && (Is.integer(candidate.code) || Is.string(candidate.code) || Is.undefined(candidate.code)) && (Is.undefined(candidate.codeDescription) || Is.string((_a = candidate.codeDescription) === null || _a === void 0 ? void 0 : _a.href)) && (Is.string(candidate.source) || Is.undefined(candidate.source)) && (Is.undefined(candidate.relatedInformation) || Is.typedArray(candidate.relatedInformation, DiagnosticRelatedInformation.is));\n  }\n  __name(is, \"is\");\n  Diagnostic2.is = is;\n})(Diagnostic || (Diagnostic = {}));\nvar Command;\n(function(Command2) {\n  function create(title, command, ...args) {\n    let result = { title, command };\n    if (Is.defined(args) && args.length > 0) {\n      result.arguments = args;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  Command2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Is.string(candidate.title) && Is.string(candidate.command);\n  }\n  __name(is, \"is\");\n  Command2.is = is;\n})(Command || (Command = {}));\nvar TextEdit;\n(function(TextEdit2) {\n  function replace(range, newText) {\n    return { range, newText };\n  }\n  __name(replace, \"replace\");\n  TextEdit2.replace = replace;\n  function insert(position, newText) {\n    return { range: { start: position, end: position }, newText };\n  }\n  __name(insert, \"insert\");\n  TextEdit2.insert = insert;\n  function del(range) {\n    return { range, newText: \"\" };\n  }\n  __name(del, \"del\");\n  TextEdit2.del = del;\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && Is.string(candidate.newText) && Range.is(candidate.range);\n  }\n  __name(is, \"is\");\n  TextEdit2.is = is;\n})(TextEdit || (TextEdit = {}));\nvar ChangeAnnotation;\n(function(ChangeAnnotation2) {\n  function create(label, needsConfirmation, description) {\n    const result = { label };\n    if (needsConfirmation !== void 0) {\n      result.needsConfirmation = needsConfirmation;\n    }\n    if (description !== void 0) {\n      result.description = description;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  ChangeAnnotation2.create = create;\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && Is.string(candidate.label) && (Is.boolean(candidate.needsConfirmation) || candidate.needsConfirmation === void 0) && (Is.string(candidate.description) || candidate.description === void 0);\n  }\n  __name(is, \"is\");\n  ChangeAnnotation2.is = is;\n})(ChangeAnnotation || (ChangeAnnotation = {}));\nvar ChangeAnnotationIdentifier;\n(function(ChangeAnnotationIdentifier2) {\n  function is(value) {\n    const candidate = value;\n    return Is.string(candidate);\n  }\n  __name(is, \"is\");\n  ChangeAnnotationIdentifier2.is = is;\n})(ChangeAnnotationIdentifier || (ChangeAnnotationIdentifier = {}));\nvar AnnotatedTextEdit;\n(function(AnnotatedTextEdit2) {\n  function replace(range, newText, annotation) {\n    return { range, newText, annotationId: annotation };\n  }\n  __name(replace, \"replace\");\n  AnnotatedTextEdit2.replace = replace;\n  function insert(position, newText, annotation) {\n    return { range: { start: position, end: position }, newText, annotationId: annotation };\n  }\n  __name(insert, \"insert\");\n  AnnotatedTextEdit2.insert = insert;\n  function del(range, annotation) {\n    return { range, newText: \"\", annotationId: annotation };\n  }\n  __name(del, \"del\");\n  AnnotatedTextEdit2.del = del;\n  function is(value) {\n    const candidate = value;\n    return TextEdit.is(candidate) && (ChangeAnnotation.is(candidate.annotationId) || ChangeAnnotationIdentifier.is(candidate.annotationId));\n  }\n  __name(is, \"is\");\n  AnnotatedTextEdit2.is = is;\n})(AnnotatedTextEdit || (AnnotatedTextEdit = {}));\nvar TextDocumentEdit;\n(function(TextDocumentEdit2) {\n  function create(textDocument, edits) {\n    return { textDocument, edits };\n  }\n  __name(create, \"create\");\n  TextDocumentEdit2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && OptionalVersionedTextDocumentIdentifier.is(candidate.textDocument) && Array.isArray(candidate.edits);\n  }\n  __name(is, \"is\");\n  TextDocumentEdit2.is = is;\n})(TextDocumentEdit || (TextDocumentEdit = {}));\nvar CreateFile;\n(function(CreateFile2) {\n  function create(uri, options, annotation) {\n    let result = {\n      kind: \"create\",\n      uri\n    };\n    if (options !== void 0 && (options.overwrite !== void 0 || options.ignoreIfExists !== void 0)) {\n      result.options = options;\n    }\n    if (annotation !== void 0) {\n      result.annotationId = annotation;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  CreateFile2.create = create;\n  function is(value) {\n    let candidate = value;\n    return candidate && candidate.kind === \"create\" && Is.string(candidate.uri) && (candidate.options === void 0 || (candidate.options.overwrite === void 0 || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === void 0 || Is.boolean(candidate.options.ignoreIfExists))) && (candidate.annotationId === void 0 || ChangeAnnotationIdentifier.is(candidate.annotationId));\n  }\n  __name(is, \"is\");\n  CreateFile2.is = is;\n})(CreateFile || (CreateFile = {}));\nvar RenameFile;\n(function(RenameFile2) {\n  function create(oldUri, newUri, options, annotation) {\n    let result = {\n      kind: \"rename\",\n      oldUri,\n      newUri\n    };\n    if (options !== void 0 && (options.overwrite !== void 0 || options.ignoreIfExists !== void 0)) {\n      result.options = options;\n    }\n    if (annotation !== void 0) {\n      result.annotationId = annotation;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  RenameFile2.create = create;\n  function is(value) {\n    let candidate = value;\n    return candidate && candidate.kind === \"rename\" && Is.string(candidate.oldUri) && Is.string(candidate.newUri) && (candidate.options === void 0 || (candidate.options.overwrite === void 0 || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === void 0 || Is.boolean(candidate.options.ignoreIfExists))) && (candidate.annotationId === void 0 || ChangeAnnotationIdentifier.is(candidate.annotationId));\n  }\n  __name(is, \"is\");\n  RenameFile2.is = is;\n})(RenameFile || (RenameFile = {}));\nvar DeleteFile;\n(function(DeleteFile2) {\n  function create(uri, options, annotation) {\n    let result = {\n      kind: \"delete\",\n      uri\n    };\n    if (options !== void 0 && (options.recursive !== void 0 || options.ignoreIfNotExists !== void 0)) {\n      result.options = options;\n    }\n    if (annotation !== void 0) {\n      result.annotationId = annotation;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  DeleteFile2.create = create;\n  function is(value) {\n    let candidate = value;\n    return candidate && candidate.kind === \"delete\" && Is.string(candidate.uri) && (candidate.options === void 0 || (candidate.options.recursive === void 0 || Is.boolean(candidate.options.recursive)) && (candidate.options.ignoreIfNotExists === void 0 || Is.boolean(candidate.options.ignoreIfNotExists))) && (candidate.annotationId === void 0 || ChangeAnnotationIdentifier.is(candidate.annotationId));\n  }\n  __name(is, \"is\");\n  DeleteFile2.is = is;\n})(DeleteFile || (DeleteFile = {}));\nvar WorkspaceEdit;\n(function(WorkspaceEdit2) {\n  function is(value) {\n    let candidate = value;\n    return candidate && (candidate.changes !== void 0 || candidate.documentChanges !== void 0) && (candidate.documentChanges === void 0 || candidate.documentChanges.every((change) => {\n      if (Is.string(change.kind)) {\n        return CreateFile.is(change) || RenameFile.is(change) || DeleteFile.is(change);\n      } else {\n        return TextDocumentEdit.is(change);\n      }\n    }));\n  }\n  __name(is, \"is\");\n  WorkspaceEdit2.is = is;\n})(WorkspaceEdit || (WorkspaceEdit = {}));\nvar TextDocumentIdentifier;\n(function(TextDocumentIdentifier2) {\n  function create(uri) {\n    return { uri };\n  }\n  __name(create, \"create\");\n  TextDocumentIdentifier2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Is.string(candidate.uri);\n  }\n  __name(is, \"is\");\n  TextDocumentIdentifier2.is = is;\n})(TextDocumentIdentifier || (TextDocumentIdentifier = {}));\nvar VersionedTextDocumentIdentifier;\n(function(VersionedTextDocumentIdentifier2) {\n  function create(uri, version) {\n    return { uri, version };\n  }\n  __name(create, \"create\");\n  VersionedTextDocumentIdentifier2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Is.string(candidate.uri) && Is.integer(candidate.version);\n  }\n  __name(is, \"is\");\n  VersionedTextDocumentIdentifier2.is = is;\n})(VersionedTextDocumentIdentifier || (VersionedTextDocumentIdentifier = {}));\nvar OptionalVersionedTextDocumentIdentifier;\n(function(OptionalVersionedTextDocumentIdentifier2) {\n  function create(uri, version) {\n    return { uri, version };\n  }\n  __name(create, \"create\");\n  OptionalVersionedTextDocumentIdentifier2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Is.string(candidate.uri) && (candidate.version === null || Is.integer(candidate.version));\n  }\n  __name(is, \"is\");\n  OptionalVersionedTextDocumentIdentifier2.is = is;\n})(OptionalVersionedTextDocumentIdentifier || (OptionalVersionedTextDocumentIdentifier = {}));\nvar TextDocumentItem;\n(function(TextDocumentItem2) {\n  function create(uri, languageId, version, text) {\n    return { uri, languageId, version, text };\n  }\n  __name(create, \"create\");\n  TextDocumentItem2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Is.string(candidate.uri) && Is.string(candidate.languageId) && Is.integer(candidate.version) && Is.string(candidate.text);\n  }\n  __name(is, \"is\");\n  TextDocumentItem2.is = is;\n})(TextDocumentItem || (TextDocumentItem = {}));\nvar MarkupKind;\n(function(MarkupKind2) {\n  MarkupKind2.PlainText = \"plaintext\";\n  MarkupKind2.Markdown = \"markdown\";\n  function is(value) {\n    const candidate = value;\n    return candidate === MarkupKind2.PlainText || candidate === MarkupKind2.Markdown;\n  }\n  __name(is, \"is\");\n  MarkupKind2.is = is;\n})(MarkupKind || (MarkupKind = {}));\nvar MarkupContent;\n(function(MarkupContent2) {\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(value) && MarkupKind.is(candidate.kind) && Is.string(candidate.value);\n  }\n  __name(is, \"is\");\n  MarkupContent2.is = is;\n})(MarkupContent || (MarkupContent = {}));\nvar CompletionItemKind;\n(function(CompletionItemKind2) {\n  CompletionItemKind2.Text = 1;\n  CompletionItemKind2.Method = 2;\n  CompletionItemKind2.Function = 3;\n  CompletionItemKind2.Constructor = 4;\n  CompletionItemKind2.Field = 5;\n  CompletionItemKind2.Variable = 6;\n  CompletionItemKind2.Class = 7;\n  CompletionItemKind2.Interface = 8;\n  CompletionItemKind2.Module = 9;\n  CompletionItemKind2.Property = 10;\n  CompletionItemKind2.Unit = 11;\n  CompletionItemKind2.Value = 12;\n  CompletionItemKind2.Enum = 13;\n  CompletionItemKind2.Keyword = 14;\n  CompletionItemKind2.Snippet = 15;\n  CompletionItemKind2.Color = 16;\n  CompletionItemKind2.File = 17;\n  CompletionItemKind2.Reference = 18;\n  CompletionItemKind2.Folder = 19;\n  CompletionItemKind2.EnumMember = 20;\n  CompletionItemKind2.Constant = 21;\n  CompletionItemKind2.Struct = 22;\n  CompletionItemKind2.Event = 23;\n  CompletionItemKind2.Operator = 24;\n  CompletionItemKind2.TypeParameter = 25;\n})(CompletionItemKind || (CompletionItemKind = {}));\nvar InsertTextFormat;\n(function(InsertTextFormat2) {\n  InsertTextFormat2.PlainText = 1;\n  InsertTextFormat2.Snippet = 2;\n})(InsertTextFormat || (InsertTextFormat = {}));\nvar CompletionItemTag;\n(function(CompletionItemTag2) {\n  CompletionItemTag2.Deprecated = 1;\n})(CompletionItemTag || (CompletionItemTag = {}));\nvar InsertReplaceEdit;\n(function(InsertReplaceEdit2) {\n  function create(newText, insert, replace) {\n    return { newText, insert, replace };\n  }\n  __name(create, \"create\");\n  InsertReplaceEdit2.create = create;\n  function is(value) {\n    const candidate = value;\n    return candidate && Is.string(candidate.newText) && Range.is(candidate.insert) && Range.is(candidate.replace);\n  }\n  __name(is, \"is\");\n  InsertReplaceEdit2.is = is;\n})(InsertReplaceEdit || (InsertReplaceEdit = {}));\nvar InsertTextMode;\n(function(InsertTextMode2) {\n  InsertTextMode2.asIs = 1;\n  InsertTextMode2.adjustIndentation = 2;\n})(InsertTextMode || (InsertTextMode = {}));\nvar CompletionItemLabelDetails;\n(function(CompletionItemLabelDetails2) {\n  function is(value) {\n    const candidate = value;\n    return candidate && (Is.string(candidate.detail) || candidate.detail === void 0) && (Is.string(candidate.description) || candidate.description === void 0);\n  }\n  __name(is, \"is\");\n  CompletionItemLabelDetails2.is = is;\n})(CompletionItemLabelDetails || (CompletionItemLabelDetails = {}));\nvar CompletionItem;\n(function(CompletionItem2) {\n  function create(label) {\n    return { label };\n  }\n  __name(create, \"create\");\n  CompletionItem2.create = create;\n})(CompletionItem || (CompletionItem = {}));\nvar CompletionList;\n(function(CompletionList2) {\n  function create(items, isIncomplete) {\n    return { items: items ? items : [], isIncomplete: !!isIncomplete };\n  }\n  __name(create, \"create\");\n  CompletionList2.create = create;\n})(CompletionList || (CompletionList = {}));\nvar MarkedString;\n(function(MarkedString2) {\n  function fromPlainText(plainText) {\n    return plainText.replace(/[\\\\`*_{}[\\]()#+\\-.!]/g, \"\\\\$&\");\n  }\n  __name(fromPlainText, \"fromPlainText\");\n  MarkedString2.fromPlainText = fromPlainText;\n  function is(value) {\n    const candidate = value;\n    return Is.string(candidate) || Is.objectLiteral(candidate) && Is.string(candidate.language) && Is.string(candidate.value);\n  }\n  __name(is, \"is\");\n  MarkedString2.is = is;\n})(MarkedString || (MarkedString = {}));\nvar Hover;\n(function(Hover2) {\n  function is(value) {\n    let candidate = value;\n    return !!candidate && Is.objectLiteral(candidate) && (MarkupContent.is(candidate.contents) || MarkedString.is(candidate.contents) || Is.typedArray(candidate.contents, MarkedString.is)) && (value.range === void 0 || Range.is(value.range));\n  }\n  __name(is, \"is\");\n  Hover2.is = is;\n})(Hover || (Hover = {}));\nvar ParameterInformation;\n(function(ParameterInformation2) {\n  function create(label, documentation) {\n    return documentation ? { label, documentation } : { label };\n  }\n  __name(create, \"create\");\n  ParameterInformation2.create = create;\n})(ParameterInformation || (ParameterInformation = {}));\nvar SignatureInformation;\n(function(SignatureInformation2) {\n  function create(label, documentation, ...parameters) {\n    let result = { label };\n    if (Is.defined(documentation)) {\n      result.documentation = documentation;\n    }\n    if (Is.defined(parameters)) {\n      result.parameters = parameters;\n    } else {\n      result.parameters = [];\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  SignatureInformation2.create = create;\n})(SignatureInformation || (SignatureInformation = {}));\nvar DocumentHighlightKind;\n(function(DocumentHighlightKind2) {\n  DocumentHighlightKind2.Text = 1;\n  DocumentHighlightKind2.Read = 2;\n  DocumentHighlightKind2.Write = 3;\n})(DocumentHighlightKind || (DocumentHighlightKind = {}));\nvar DocumentHighlight;\n(function(DocumentHighlight2) {\n  function create(range, kind) {\n    let result = { range };\n    if (Is.number(kind)) {\n      result.kind = kind;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  DocumentHighlight2.create = create;\n})(DocumentHighlight || (DocumentHighlight = {}));\nvar SymbolKind;\n(function(SymbolKind2) {\n  SymbolKind2.File = 1;\n  SymbolKind2.Module = 2;\n  SymbolKind2.Namespace = 3;\n  SymbolKind2.Package = 4;\n  SymbolKind2.Class = 5;\n  SymbolKind2.Method = 6;\n  SymbolKind2.Property = 7;\n  SymbolKind2.Field = 8;\n  SymbolKind2.Constructor = 9;\n  SymbolKind2.Enum = 10;\n  SymbolKind2.Interface = 11;\n  SymbolKind2.Function = 12;\n  SymbolKind2.Variable = 13;\n  SymbolKind2.Constant = 14;\n  SymbolKind2.String = 15;\n  SymbolKind2.Number = 16;\n  SymbolKind2.Boolean = 17;\n  SymbolKind2.Array = 18;\n  SymbolKind2.Object = 19;\n  SymbolKind2.Key = 20;\n  SymbolKind2.Null = 21;\n  SymbolKind2.EnumMember = 22;\n  SymbolKind2.Struct = 23;\n  SymbolKind2.Event = 24;\n  SymbolKind2.Operator = 25;\n  SymbolKind2.TypeParameter = 26;\n})(SymbolKind || (SymbolKind = {}));\nvar SymbolTag;\n(function(SymbolTag2) {\n  SymbolTag2.Deprecated = 1;\n})(SymbolTag || (SymbolTag = {}));\nvar SymbolInformation;\n(function(SymbolInformation2) {\n  function create(name, kind, range, uri, containerName) {\n    let result = {\n      name,\n      kind,\n      location: { uri, range }\n    };\n    if (containerName) {\n      result.containerName = containerName;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  SymbolInformation2.create = create;\n})(SymbolInformation || (SymbolInformation = {}));\nvar WorkspaceSymbol;\n(function(WorkspaceSymbol2) {\n  function create(name, kind, uri, range) {\n    return range !== void 0 ? { name, kind, location: { uri, range } } : { name, kind, location: { uri } };\n  }\n  __name(create, \"create\");\n  WorkspaceSymbol2.create = create;\n})(WorkspaceSymbol || (WorkspaceSymbol = {}));\nvar DocumentSymbol;\n(function(DocumentSymbol2) {\n  function create(name, detail, kind, range, selectionRange, children) {\n    let result = {\n      name,\n      detail,\n      kind,\n      range,\n      selectionRange\n    };\n    if (children !== void 0) {\n      result.children = children;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  DocumentSymbol2.create = create;\n  function is(value) {\n    let candidate = value;\n    return candidate && Is.string(candidate.name) && Is.number(candidate.kind) && Range.is(candidate.range) && Range.is(candidate.selectionRange) && (candidate.detail === void 0 || Is.string(candidate.detail)) && (candidate.deprecated === void 0 || Is.boolean(candidate.deprecated)) && (candidate.children === void 0 || Array.isArray(candidate.children)) && (candidate.tags === void 0 || Array.isArray(candidate.tags));\n  }\n  __name(is, \"is\");\n  DocumentSymbol2.is = is;\n})(DocumentSymbol || (DocumentSymbol = {}));\nvar CodeActionKind;\n(function(CodeActionKind2) {\n  CodeActionKind2.Empty = \"\";\n  CodeActionKind2.QuickFix = \"quickfix\";\n  CodeActionKind2.Refactor = \"refactor\";\n  CodeActionKind2.RefactorExtract = \"refactor.extract\";\n  CodeActionKind2.RefactorInline = \"refactor.inline\";\n  CodeActionKind2.RefactorRewrite = \"refactor.rewrite\";\n  CodeActionKind2.Source = \"source\";\n  CodeActionKind2.SourceOrganizeImports = \"source.organizeImports\";\n  CodeActionKind2.SourceFixAll = \"source.fixAll\";\n})(CodeActionKind || (CodeActionKind = {}));\nvar CodeActionTriggerKind;\n(function(CodeActionTriggerKind2) {\n  CodeActionTriggerKind2.Invoked = 1;\n  CodeActionTriggerKind2.Automatic = 2;\n})(CodeActionTriggerKind || (CodeActionTriggerKind = {}));\nvar CodeActionContext;\n(function(CodeActionContext2) {\n  function create(diagnostics, only, triggerKind) {\n    let result = { diagnostics };\n    if (only !== void 0 && only !== null) {\n      result.only = only;\n    }\n    if (triggerKind !== void 0 && triggerKind !== null) {\n      result.triggerKind = triggerKind;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  CodeActionContext2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Is.typedArray(candidate.diagnostics, Diagnostic.is) && (candidate.only === void 0 || Is.typedArray(candidate.only, Is.string)) && (candidate.triggerKind === void 0 || candidate.triggerKind === CodeActionTriggerKind.Invoked || candidate.triggerKind === CodeActionTriggerKind.Automatic);\n  }\n  __name(is, \"is\");\n  CodeActionContext2.is = is;\n})(CodeActionContext || (CodeActionContext = {}));\nvar CodeAction;\n(function(CodeAction2) {\n  function create(title, kindOrCommandOrEdit, kind) {\n    let result = { title };\n    let checkKind = true;\n    if (typeof kindOrCommandOrEdit === \"string\") {\n      checkKind = false;\n      result.kind = kindOrCommandOrEdit;\n    } else if (Command.is(kindOrCommandOrEdit)) {\n      result.command = kindOrCommandOrEdit;\n    } else {\n      result.edit = kindOrCommandOrEdit;\n    }\n    if (checkKind && kind !== void 0) {\n      result.kind = kind;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  CodeAction2.create = create;\n  function is(value) {\n    let candidate = value;\n    return candidate && Is.string(candidate.title) && (candidate.diagnostics === void 0 || Is.typedArray(candidate.diagnostics, Diagnostic.is)) && (candidate.kind === void 0 || Is.string(candidate.kind)) && (candidate.edit !== void 0 || candidate.command !== void 0) && (candidate.command === void 0 || Command.is(candidate.command)) && (candidate.isPreferred === void 0 || Is.boolean(candidate.isPreferred)) && (candidate.edit === void 0 || WorkspaceEdit.is(candidate.edit));\n  }\n  __name(is, \"is\");\n  CodeAction2.is = is;\n})(CodeAction || (CodeAction = {}));\nvar CodeLens;\n(function(CodeLens2) {\n  function create(range, data) {\n    let result = { range };\n    if (Is.defined(data)) {\n      result.data = data;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  CodeLens2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.command) || Command.is(candidate.command));\n  }\n  __name(is, \"is\");\n  CodeLens2.is = is;\n})(CodeLens || (CodeLens = {}));\nvar FormattingOptions;\n(function(FormattingOptions2) {\n  function create(tabSize, insertSpaces) {\n    return { tabSize, insertSpaces };\n  }\n  __name(create, \"create\");\n  FormattingOptions2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Is.uinteger(candidate.tabSize) && Is.boolean(candidate.insertSpaces);\n  }\n  __name(is, \"is\");\n  FormattingOptions2.is = is;\n})(FormattingOptions || (FormattingOptions = {}));\nvar DocumentLink;\n(function(DocumentLink2) {\n  function create(range, target, data) {\n    return { range, target, data };\n  }\n  __name(create, \"create\");\n  DocumentLink2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.target) || Is.string(candidate.target));\n  }\n  __name(is, \"is\");\n  DocumentLink2.is = is;\n})(DocumentLink || (DocumentLink = {}));\nvar SelectionRange;\n(function(SelectionRange2) {\n  function create(range, parent) {\n    return { range, parent };\n  }\n  __name(create, \"create\");\n  SelectionRange2.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.objectLiteral(candidate) && Range.is(candidate.range) && (candidate.parent === void 0 || SelectionRange2.is(candidate.parent));\n  }\n  __name(is, \"is\");\n  SelectionRange2.is = is;\n})(SelectionRange || (SelectionRange = {}));\nvar SemanticTokenTypes;\n(function(SemanticTokenTypes2) {\n  SemanticTokenTypes2[\"namespace\"] = \"namespace\";\n  SemanticTokenTypes2[\"type\"] = \"type\";\n  SemanticTokenTypes2[\"class\"] = \"class\";\n  SemanticTokenTypes2[\"enum\"] = \"enum\";\n  SemanticTokenTypes2[\"interface\"] = \"interface\";\n  SemanticTokenTypes2[\"struct\"] = \"struct\";\n  SemanticTokenTypes2[\"typeParameter\"] = \"typeParameter\";\n  SemanticTokenTypes2[\"parameter\"] = \"parameter\";\n  SemanticTokenTypes2[\"variable\"] = \"variable\";\n  SemanticTokenTypes2[\"property\"] = \"property\";\n  SemanticTokenTypes2[\"enumMember\"] = \"enumMember\";\n  SemanticTokenTypes2[\"event\"] = \"event\";\n  SemanticTokenTypes2[\"function\"] = \"function\";\n  SemanticTokenTypes2[\"method\"] = \"method\";\n  SemanticTokenTypes2[\"macro\"] = \"macro\";\n  SemanticTokenTypes2[\"keyword\"] = \"keyword\";\n  SemanticTokenTypes2[\"modifier\"] = \"modifier\";\n  SemanticTokenTypes2[\"comment\"] = \"comment\";\n  SemanticTokenTypes2[\"string\"] = \"string\";\n  SemanticTokenTypes2[\"number\"] = \"number\";\n  SemanticTokenTypes2[\"regexp\"] = \"regexp\";\n  SemanticTokenTypes2[\"operator\"] = \"operator\";\n  SemanticTokenTypes2[\"decorator\"] = \"decorator\";\n})(SemanticTokenTypes || (SemanticTokenTypes = {}));\nvar SemanticTokenModifiers;\n(function(SemanticTokenModifiers2) {\n  SemanticTokenModifiers2[\"declaration\"] = \"declaration\";\n  SemanticTokenModifiers2[\"definition\"] = \"definition\";\n  SemanticTokenModifiers2[\"readonly\"] = \"readonly\";\n  SemanticTokenModifiers2[\"static\"] = \"static\";\n  SemanticTokenModifiers2[\"deprecated\"] = \"deprecated\";\n  SemanticTokenModifiers2[\"abstract\"] = \"abstract\";\n  SemanticTokenModifiers2[\"async\"] = \"async\";\n  SemanticTokenModifiers2[\"modification\"] = \"modification\";\n  SemanticTokenModifiers2[\"documentation\"] = \"documentation\";\n  SemanticTokenModifiers2[\"defaultLibrary\"] = \"defaultLibrary\";\n})(SemanticTokenModifiers || (SemanticTokenModifiers = {}));\nvar SemanticTokens;\n(function(SemanticTokens2) {\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && (candidate.resultId === void 0 || typeof candidate.resultId === \"string\") && Array.isArray(candidate.data) && (candidate.data.length === 0 || typeof candidate.data[0] === \"number\");\n  }\n  __name(is, \"is\");\n  SemanticTokens2.is = is;\n})(SemanticTokens || (SemanticTokens = {}));\nvar InlineValueText;\n(function(InlineValueText2) {\n  function create(range, text) {\n    return { range, text };\n  }\n  __name(create, \"create\");\n  InlineValueText2.create = create;\n  function is(value) {\n    const candidate = value;\n    return candidate !== void 0 && candidate !== null && Range.is(candidate.range) && Is.string(candidate.text);\n  }\n  __name(is, \"is\");\n  InlineValueText2.is = is;\n})(InlineValueText || (InlineValueText = {}));\nvar InlineValueVariableLookup;\n(function(InlineValueVariableLookup2) {\n  function create(range, variableName, caseSensitiveLookup) {\n    return { range, variableName, caseSensitiveLookup };\n  }\n  __name(create, \"create\");\n  InlineValueVariableLookup2.create = create;\n  function is(value) {\n    const candidate = value;\n    return candidate !== void 0 && candidate !== null && Range.is(candidate.range) && Is.boolean(candidate.caseSensitiveLookup) && (Is.string(candidate.variableName) || candidate.variableName === void 0);\n  }\n  __name(is, \"is\");\n  InlineValueVariableLookup2.is = is;\n})(InlineValueVariableLookup || (InlineValueVariableLookup = {}));\nvar InlineValueEvaluatableExpression;\n(function(InlineValueEvaluatableExpression2) {\n  function create(range, expression) {\n    return { range, expression };\n  }\n  __name(create, \"create\");\n  InlineValueEvaluatableExpression2.create = create;\n  function is(value) {\n    const candidate = value;\n    return candidate !== void 0 && candidate !== null && Range.is(candidate.range) && (Is.string(candidate.expression) || candidate.expression === void 0);\n  }\n  __name(is, \"is\");\n  InlineValueEvaluatableExpression2.is = is;\n})(InlineValueEvaluatableExpression || (InlineValueEvaluatableExpression = {}));\nvar InlineValueContext;\n(function(InlineValueContext2) {\n  function create(frameId, stoppedLocation) {\n    return { frameId, stoppedLocation };\n  }\n  __name(create, \"create\");\n  InlineValueContext2.create = create;\n  function is(value) {\n    const candidate = value;\n    return Is.defined(candidate) && Range.is(value.stoppedLocation);\n  }\n  __name(is, \"is\");\n  InlineValueContext2.is = is;\n})(InlineValueContext || (InlineValueContext = {}));\nvar InlayHintKind;\n(function(InlayHintKind2) {\n  InlayHintKind2.Type = 1;\n  InlayHintKind2.Parameter = 2;\n  function is(value) {\n    return value === 1 || value === 2;\n  }\n  __name(is, \"is\");\n  InlayHintKind2.is = is;\n})(InlayHintKind || (InlayHintKind = {}));\nvar InlayHintLabelPart;\n(function(InlayHintLabelPart2) {\n  function create(value) {\n    return { value };\n  }\n  __name(create, \"create\");\n  InlayHintLabelPart2.create = create;\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && (candidate.tooltip === void 0 || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip)) && (candidate.location === void 0 || Location.is(candidate.location)) && (candidate.command === void 0 || Command.is(candidate.command));\n  }\n  __name(is, \"is\");\n  InlayHintLabelPart2.is = is;\n})(InlayHintLabelPart || (InlayHintLabelPart = {}));\nvar InlayHint;\n(function(InlayHint2) {\n  function create(position, label, kind) {\n    const result = { position, label };\n    if (kind !== void 0) {\n      result.kind = kind;\n    }\n    return result;\n  }\n  __name(create, \"create\");\n  InlayHint2.create = create;\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && Position.is(candidate.position) && (Is.string(candidate.label) || Is.typedArray(candidate.label, InlayHintLabelPart.is)) && (candidate.kind === void 0 || InlayHintKind.is(candidate.kind)) && candidate.textEdits === void 0 || Is.typedArray(candidate.textEdits, TextEdit.is) && (candidate.tooltip === void 0 || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip)) && (candidate.paddingLeft === void 0 || Is.boolean(candidate.paddingLeft)) && (candidate.paddingRight === void 0 || Is.boolean(candidate.paddingRight));\n  }\n  __name(is, \"is\");\n  InlayHint2.is = is;\n})(InlayHint || (InlayHint = {}));\nvar StringValue;\n(function(StringValue2) {\n  function createSnippet(value) {\n    return { kind: \"snippet\", value };\n  }\n  __name(createSnippet, \"createSnippet\");\n  StringValue2.createSnippet = createSnippet;\n})(StringValue || (StringValue = {}));\nvar InlineCompletionItem;\n(function(InlineCompletionItem2) {\n  function create(insertText, filterText, range, command) {\n    return { insertText, filterText, range, command };\n  }\n  __name(create, \"create\");\n  InlineCompletionItem2.create = create;\n})(InlineCompletionItem || (InlineCompletionItem = {}));\nvar InlineCompletionList;\n(function(InlineCompletionList2) {\n  function create(items) {\n    return { items };\n  }\n  __name(create, \"create\");\n  InlineCompletionList2.create = create;\n})(InlineCompletionList || (InlineCompletionList = {}));\nvar InlineCompletionTriggerKind;\n(function(InlineCompletionTriggerKind2) {\n  InlineCompletionTriggerKind2.Invoked = 0;\n  InlineCompletionTriggerKind2.Automatic = 1;\n})(InlineCompletionTriggerKind || (InlineCompletionTriggerKind = {}));\nvar SelectedCompletionInfo;\n(function(SelectedCompletionInfo2) {\n  function create(range, text) {\n    return { range, text };\n  }\n  __name(create, \"create\");\n  SelectedCompletionInfo2.create = create;\n})(SelectedCompletionInfo || (SelectedCompletionInfo = {}));\nvar InlineCompletionContext;\n(function(InlineCompletionContext2) {\n  function create(triggerKind, selectedCompletionInfo) {\n    return { triggerKind, selectedCompletionInfo };\n  }\n  __name(create, \"create\");\n  InlineCompletionContext2.create = create;\n})(InlineCompletionContext || (InlineCompletionContext = {}));\nvar WorkspaceFolder;\n(function(WorkspaceFolder2) {\n  function is(value) {\n    const candidate = value;\n    return Is.objectLiteral(candidate) && URI.is(candidate.uri) && Is.string(candidate.name);\n  }\n  __name(is, \"is\");\n  WorkspaceFolder2.is = is;\n})(WorkspaceFolder || (WorkspaceFolder = {}));\nvar TextDocument;\n(function(TextDocument3) {\n  function create(uri, languageId, version, content) {\n    return new FullTextDocument(uri, languageId, version, content);\n  }\n  __name(create, \"create\");\n  TextDocument3.create = create;\n  function is(value) {\n    let candidate = value;\n    return Is.defined(candidate) && Is.string(candidate.uri) && (Is.undefined(candidate.languageId) || Is.string(candidate.languageId)) && Is.uinteger(candidate.lineCount) && Is.func(candidate.getText) && Is.func(candidate.positionAt) && Is.func(candidate.offsetAt) ? true : false;\n  }\n  __name(is, \"is\");\n  TextDocument3.is = is;\n  function applyEdits(document, edits) {\n    let text = document.getText();\n    let sortedEdits = mergeSort2(edits, (a, b) => {\n      let diff = a.range.start.line - b.range.start.line;\n      if (diff === 0) {\n        return a.range.start.character - b.range.start.character;\n      }\n      return diff;\n    });\n    let lastModifiedOffset = text.length;\n    for (let i = sortedEdits.length - 1; i >= 0; i--) {\n      let e = sortedEdits[i];\n      let startOffset = document.offsetAt(e.range.start);\n      let endOffset = document.offsetAt(e.range.end);\n      if (endOffset <= lastModifiedOffset) {\n        text = text.substring(0, startOffset) + e.newText + text.substring(endOffset, text.length);\n      } else {\n        throw new Error(\"Overlapping edit\");\n      }\n      lastModifiedOffset = startOffset;\n    }\n    return text;\n  }\n  __name(applyEdits, \"applyEdits\");\n  TextDocument3.applyEdits = applyEdits;\n  function mergeSort2(data, compare) {\n    if (data.length <= 1) {\n      return data;\n    }\n    const p = data.length / 2 | 0;\n    const left = data.slice(0, p);\n    const right = data.slice(p);\n    mergeSort2(left, compare);\n    mergeSort2(right, compare);\n    let leftIdx = 0;\n    let rightIdx = 0;\n    let i = 0;\n    while (leftIdx < left.length && rightIdx < right.length) {\n      let ret = compare(left[leftIdx], right[rightIdx]);\n      if (ret <= 0) {\n        data[i++] = left[leftIdx++];\n      } else {\n        data[i++] = right[rightIdx++];\n      }\n    }\n    while (leftIdx < left.length) {\n      data[i++] = left[leftIdx++];\n    }\n    while (rightIdx < right.length) {\n      data[i++] = right[rightIdx++];\n    }\n    return data;\n  }\n  __name(mergeSort2, \"mergeSort\");\n})(TextDocument || (TextDocument = {}));\nvar FullTextDocument = class {\n  static {\n    __name(this, \"FullTextDocument\");\n  }\n  constructor(uri, languageId, version, content) {\n    this._uri = uri;\n    this._languageId = languageId;\n    this._version = version;\n    this._content = content;\n    this._lineOffsets = void 0;\n  }\n  get uri() {\n    return this._uri;\n  }\n  get languageId() {\n    return this._languageId;\n  }\n  get version() {\n    return this._version;\n  }\n  getText(range) {\n    if (range) {\n      let start = this.offsetAt(range.start);\n      let end = this.offsetAt(range.end);\n      return this._content.substring(start, end);\n    }\n    return this._content;\n  }\n  update(event, version) {\n    this._content = event.text;\n    this._version = version;\n    this._lineOffsets = void 0;\n  }\n  getLineOffsets() {\n    if (this._lineOffsets === void 0) {\n      let lineOffsets = [];\n      let text = this._content;\n      let isLineStart = true;\n      for (let i = 0; i < text.length; i++) {\n        if (isLineStart) {\n          lineOffsets.push(i);\n          isLineStart = false;\n        }\n        let ch = text.charAt(i);\n        isLineStart = ch === \"\\r\" || ch === \"\\n\";\n        if (ch === \"\\r\" && i + 1 < text.length && text.charAt(i + 1) === \"\\n\") {\n          i++;\n        }\n      }\n      if (isLineStart && text.length > 0) {\n        lineOffsets.push(text.length);\n      }\n      this._lineOffsets = lineOffsets;\n    }\n    return this._lineOffsets;\n  }\n  positionAt(offset) {\n    offset = Math.max(Math.min(offset, this._content.length), 0);\n    let lineOffsets = this.getLineOffsets();\n    let low = 0, high = lineOffsets.length;\n    if (high === 0) {\n      return Position.create(0, offset);\n    }\n    while (low < high) {\n      let mid = Math.floor((low + high) / 2);\n      if (lineOffsets[mid] > offset) {\n        high = mid;\n      } else {\n        low = mid + 1;\n      }\n    }\n    let line = low - 1;\n    return Position.create(line, offset - lineOffsets[line]);\n  }\n  offsetAt(position) {\n    let lineOffsets = this.getLineOffsets();\n    if (position.line >= lineOffsets.length) {\n      return this._content.length;\n    } else if (position.line < 0) {\n      return 0;\n    }\n    let lineOffset = lineOffsets[position.line];\n    let nextLineOffset = position.line + 1 < lineOffsets.length ? lineOffsets[position.line + 1] : this._content.length;\n    return Math.max(Math.min(lineOffset + position.character, nextLineOffset), lineOffset);\n  }\n  get lineCount() {\n    return this.getLineOffsets().length;\n  }\n};\nvar Is;\n(function(Is2) {\n  const toString2 = Object.prototype.toString;\n  function defined(value) {\n    return typeof value !== \"undefined\";\n  }\n  __name(defined, \"defined\");\n  Is2.defined = defined;\n  function undefined2(value) {\n    return typeof value === \"undefined\";\n  }\n  __name(undefined2, \"undefined\");\n  Is2.undefined = undefined2;\n  function boolean(value) {\n    return value === true || value === false;\n  }\n  __name(boolean, \"boolean\");\n  Is2.boolean = boolean;\n  function string(value) {\n    return toString2.call(value) === \"[object String]\";\n  }\n  __name(string, \"string\");\n  Is2.string = string;\n  function number(value) {\n    return toString2.call(value) === \"[object Number]\";\n  }\n  __name(number, \"number\");\n  Is2.number = number;\n  function numberRange(value, min, max) {\n    return toString2.call(value) === \"[object Number]\" && min <= value && value <= max;\n  }\n  __name(numberRange, \"numberRange\");\n  Is2.numberRange = numberRange;\n  function integer2(value) {\n    return toString2.call(value) === \"[object Number]\" && -2147483648 <= value && value <= 2147483647;\n  }\n  __name(integer2, \"integer\");\n  Is2.integer = integer2;\n  function uinteger2(value) {\n    return toString2.call(value) === \"[object Number]\" && 0 <= value && value <= 2147483647;\n  }\n  __name(uinteger2, \"uinteger\");\n  Is2.uinteger = uinteger2;\n  function func(value) {\n    return toString2.call(value) === \"[object Function]\";\n  }\n  __name(func, \"func\");\n  Is2.func = func;\n  function objectLiteral(value) {\n    return value !== null && typeof value === \"object\";\n  }\n  __name(objectLiteral, \"objectLiteral\");\n  Is2.objectLiteral = objectLiteral;\n  function typedArray(value, check) {\n    return Array.isArray(value) && value.every(check);\n  }\n  __name(typedArray, \"typedArray\");\n  Is2.typedArray = typedArray;\n})(Is || (Is = {}));\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/cst-node-builder.js\nvar CstNodeBuilder = class {\n  static {\n    __name(this, \"CstNodeBuilder\");\n  }\n  constructor() {\n    this.nodeStack = [];\n  }\n  get current() {\n    var _a;\n    return (_a = this.nodeStack[this.nodeStack.length - 1]) !== null && _a !== void 0 ? _a : this.rootNode;\n  }\n  buildRootNode(input) {\n    this.rootNode = new RootCstNodeImpl(input);\n    this.rootNode.root = this.rootNode;\n    this.nodeStack = [this.rootNode];\n    return this.rootNode;\n  }\n  buildCompositeNode(feature) {\n    const compositeNode = new CompositeCstNodeImpl();\n    compositeNode.grammarSource = feature;\n    compositeNode.root = this.rootNode;\n    this.current.content.push(compositeNode);\n    this.nodeStack.push(compositeNode);\n    return compositeNode;\n  }\n  buildLeafNode(token, feature) {\n    const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, !feature);\n    leafNode.grammarSource = feature;\n    leafNode.root = this.rootNode;\n    this.current.content.push(leafNode);\n    return leafNode;\n  }\n  removeNode(node) {\n    const parent = node.container;\n    if (parent) {\n      const index = parent.content.indexOf(node);\n      if (index >= 0) {\n        parent.content.splice(index, 1);\n      }\n    }\n  }\n  addHiddenNodes(tokens) {\n    const nodes = [];\n    for (const token of tokens) {\n      const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, true);\n      leafNode.root = this.rootNode;\n      nodes.push(leafNode);\n    }\n    let current = this.current;\n    let added = false;\n    if (current.content.length > 0) {\n      current.content.push(...nodes);\n      return;\n    }\n    while (current.container) {\n      const index = current.container.content.indexOf(current);\n      if (index > 0) {\n        current.container.content.splice(index, 0, ...nodes);\n        added = true;\n        break;\n      }\n      current = current.container;\n    }\n    if (!added) {\n      this.rootNode.content.unshift(...nodes);\n    }\n  }\n  construct(item) {\n    const current = this.current;\n    if (typeof item.$type === \"string\") {\n      this.current.astNode = item;\n    }\n    item.$cstNode = current;\n    const node = this.nodeStack.pop();\n    if ((node === null || node === void 0 ? void 0 : node.content.length) === 0) {\n      this.removeNode(node);\n    }\n  }\n};\nvar AbstractCstNode = class {\n  static {\n    __name(this, \"AbstractCstNode\");\n  }\n  /** @deprecated use `container` instead. */\n  get parent() {\n    return this.container;\n  }\n  /** @deprecated use `grammarSource` instead. */\n  get feature() {\n    return this.grammarSource;\n  }\n  get hidden() {\n    return false;\n  }\n  get astNode() {\n    var _a, _b;\n    const node = typeof ((_a = this._astNode) === null || _a === void 0 ? void 0 : _a.$type) === \"string\" ? this._astNode : (_b = this.container) === null || _b === void 0 ? void 0 : _b.astNode;\n    if (!node) {\n      throw new Error(\"This node has no associated AST element\");\n    }\n    return node;\n  }\n  set astNode(value) {\n    this._astNode = value;\n  }\n  /** @deprecated use `astNode` instead. */\n  get element() {\n    return this.astNode;\n  }\n  get text() {\n    return this.root.fullText.substring(this.offset, this.end);\n  }\n};\nvar LeafCstNodeImpl = class extends AbstractCstNode {\n  static {\n    __name(this, \"LeafCstNodeImpl\");\n  }\n  get offset() {\n    return this._offset;\n  }\n  get length() {\n    return this._length;\n  }\n  get end() {\n    return this._offset + this._length;\n  }\n  get hidden() {\n    return this._hidden;\n  }\n  get tokenType() {\n    return this._tokenType;\n  }\n  get range() {\n    return this._range;\n  }\n  constructor(offset, length, range, tokenType, hidden = false) {\n    super();\n    this._hidden = hidden;\n    this._offset = offset;\n    this._tokenType = tokenType;\n    this._length = length;\n    this._range = range;\n  }\n};\nvar CompositeCstNodeImpl = class extends AbstractCstNode {\n  static {\n    __name(this, \"CompositeCstNodeImpl\");\n  }\n  constructor() {\n    super(...arguments);\n    this.content = new CstNodeContainer(this);\n  }\n  /** @deprecated use `content` instead. */\n  get children() {\n    return this.content;\n  }\n  get offset() {\n    var _a, _b;\n    return (_b = (_a = this.firstNonHiddenNode) === null || _a === void 0 ? void 0 : _a.offset) !== null && _b !== void 0 ? _b : 0;\n  }\n  get length() {\n    return this.end - this.offset;\n  }\n  get end() {\n    var _a, _b;\n    return (_b = (_a = this.lastNonHiddenNode) === null || _a === void 0 ? void 0 : _a.end) !== null && _b !== void 0 ? _b : 0;\n  }\n  get range() {\n    const firstNode = this.firstNonHiddenNode;\n    const lastNode = this.lastNonHiddenNode;\n    if (firstNode && lastNode) {\n      if (this._rangeCache === void 0) {\n        const { range: firstRange } = firstNode;\n        const { range: lastRange } = lastNode;\n        this._rangeCache = { start: firstRange.start, end: lastRange.end.line < firstRange.start.line ? firstRange.start : lastRange.end };\n      }\n      return this._rangeCache;\n    } else {\n      return { start: Position.create(0, 0), end: Position.create(0, 0) };\n    }\n  }\n  get firstNonHiddenNode() {\n    for (const child of this.content) {\n      if (!child.hidden) {\n        return child;\n      }\n    }\n    return this.content[0];\n  }\n  get lastNonHiddenNode() {\n    for (let i = this.content.length - 1; i >= 0; i--) {\n      const child = this.content[i];\n      if (!child.hidden) {\n        return child;\n      }\n    }\n    return this.content[this.content.length - 1];\n  }\n};\nvar CstNodeContainer = class _CstNodeContainer extends Array {\n  static {\n    __name(this, \"CstNodeContainer\");\n  }\n  constructor(parent) {\n    super();\n    this.parent = parent;\n    Object.setPrototypeOf(this, _CstNodeContainer.prototype);\n  }\n  push(...items) {\n    this.addParents(items);\n    return super.push(...items);\n  }\n  unshift(...items) {\n    this.addParents(items);\n    return super.unshift(...items);\n  }\n  splice(start, count, ...items) {\n    this.addParents(items);\n    return super.splice(start, count, ...items);\n  }\n  addParents(items) {\n    for (const item of items) {\n      item.container = this.parent;\n    }\n  }\n};\nvar RootCstNodeImpl = class extends CompositeCstNodeImpl {\n  static {\n    __name(this, \"RootCstNodeImpl\");\n  }\n  get text() {\n    return this._text.substring(this.offset, this.end);\n  }\n  get fullText() {\n    return this._text;\n  }\n  constructor(input) {\n    super();\n    this._text = \"\";\n    this._text = input !== null && input !== void 0 ? input : \"\";\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/langium-parser.js\nvar DatatypeSymbol = Symbol(\"Datatype\");\nfunction isDataTypeNode(node) {\n  return node.$type === DatatypeSymbol;\n}\n__name(isDataTypeNode, \"isDataTypeNode\");\nvar ruleSuffix = \"\\u200B\";\nvar withRuleSuffix = /* @__PURE__ */ __name((name) => name.endsWith(ruleSuffix) ? name : name + ruleSuffix, \"withRuleSuffix\");\nvar AbstractLangiumParser = class {\n  static {\n    __name(this, \"AbstractLangiumParser\");\n  }\n  constructor(services) {\n    this._unorderedGroups = /* @__PURE__ */ new Map();\n    this.allRules = /* @__PURE__ */ new Map();\n    this.lexer = services.parser.Lexer;\n    const tokens = this.lexer.definition;\n    const production = services.LanguageMetaData.mode === \"production\";\n    this.wrapper = new ChevrotainWrapper(tokens, Object.assign(Object.assign({}, services.parser.ParserConfig), { skipValidations: production, errorMessageProvider: services.parser.ParserErrorMessageProvider }));\n  }\n  alternatives(idx, choices) {\n    this.wrapper.wrapOr(idx, choices);\n  }\n  optional(idx, callback) {\n    this.wrapper.wrapOption(idx, callback);\n  }\n  many(idx, callback) {\n    this.wrapper.wrapMany(idx, callback);\n  }\n  atLeastOne(idx, callback) {\n    this.wrapper.wrapAtLeastOne(idx, callback);\n  }\n  getRule(name) {\n    return this.allRules.get(name);\n  }\n  isRecording() {\n    return this.wrapper.IS_RECORDING;\n  }\n  get unorderedGroups() {\n    return this._unorderedGroups;\n  }\n  getRuleStack() {\n    return this.wrapper.RULE_STACK;\n  }\n  finalize() {\n    this.wrapper.wrapSelfAnalysis();\n  }\n};\nvar LangiumParser = class extends AbstractLangiumParser {\n  static {\n    __name(this, \"LangiumParser\");\n  }\n  get current() {\n    return this.stack[this.stack.length - 1];\n  }\n  constructor(services) {\n    super(services);\n    this.nodeBuilder = new CstNodeBuilder();\n    this.stack = [];\n    this.assignmentMap = /* @__PURE__ */ new Map();\n    this.linker = services.references.Linker;\n    this.converter = services.parser.ValueConverter;\n    this.astReflection = services.shared.AstReflection;\n  }\n  rule(rule, impl) {\n    const type = this.computeRuleType(rule);\n    const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(type, impl).bind(this));\n    this.allRules.set(rule.name, ruleMethod);\n    if (rule.entry) {\n      this.mainRule = ruleMethod;\n    }\n    return ruleMethod;\n  }\n  computeRuleType(rule) {\n    if (rule.fragment) {\n      return void 0;\n    } else if (isDataTypeRule(rule)) {\n      return DatatypeSymbol;\n    } else {\n      const explicit = getExplicitRuleType(rule);\n      return explicit !== null && explicit !== void 0 ? explicit : rule.name;\n    }\n  }\n  parse(input, options = {}) {\n    this.nodeBuilder.buildRootNode(input);\n    const lexerResult = this.lexerResult = this.lexer.tokenize(input);\n    this.wrapper.input = lexerResult.tokens;\n    const ruleMethod = options.rule ? this.allRules.get(options.rule) : this.mainRule;\n    if (!ruleMethod) {\n      throw new Error(options.rule ? `No rule found with name '${options.rule}'` : \"No main rule available.\");\n    }\n    const result = ruleMethod.call(this.wrapper, {});\n    this.nodeBuilder.addHiddenNodes(lexerResult.hidden);\n    this.unorderedGroups.clear();\n    this.lexerResult = void 0;\n    return {\n      value: result,\n      lexerErrors: lexerResult.errors,\n      lexerReport: lexerResult.report,\n      parserErrors: this.wrapper.errors\n    };\n  }\n  startImplementation($type, implementation) {\n    return (args) => {\n      const createNode = !this.isRecording() && $type !== void 0;\n      if (createNode) {\n        const node = { $type };\n        this.stack.push(node);\n        if ($type === DatatypeSymbol) {\n          node.value = \"\";\n        }\n      }\n      let result;\n      try {\n        result = implementation(args);\n      } catch (err) {\n        result = void 0;\n      }\n      if (result === void 0 && createNode) {\n        result = this.construct();\n      }\n      return result;\n    };\n  }\n  extractHiddenTokens(token) {\n    const hiddenTokens = this.lexerResult.hidden;\n    if (!hiddenTokens.length) {\n      return [];\n    }\n    const offset = token.startOffset;\n    for (let i = 0; i < hiddenTokens.length; i++) {\n      const token2 = hiddenTokens[i];\n      if (token2.startOffset > offset) {\n        return hiddenTokens.splice(0, i);\n      }\n    }\n    return hiddenTokens.splice(0, hiddenTokens.length);\n  }\n  consume(idx, tokenType, feature) {\n    const token = this.wrapper.wrapConsume(idx, tokenType);\n    if (!this.isRecording() && this.isValidToken(token)) {\n      const hiddenTokens = this.extractHiddenTokens(token);\n      this.nodeBuilder.addHiddenNodes(hiddenTokens);\n      const leafNode = this.nodeBuilder.buildLeafNode(token, feature);\n      const { assignment, isCrossRef } = this.getAssignment(feature);\n      const current = this.current;\n      if (assignment) {\n        const convertedValue = isKeyword(feature) ? token.image : this.converter.convert(token.image, leafNode);\n        this.assign(assignment.operator, assignment.feature, convertedValue, leafNode, isCrossRef);\n      } else if (isDataTypeNode(current)) {\n        let text = token.image;\n        if (!isKeyword(feature)) {\n          text = this.converter.convert(text, leafNode).toString();\n        }\n        current.value += text;\n      }\n    }\n  }\n  /**\n   * Most consumed parser tokens are valid. However there are two cases in which they are not valid:\n   *\n   * 1. They were inserted during error recovery by the parser. These tokens don't really exist and should not be further processed\n   * 2. They contain invalid token ranges. This might include the special EOF token, or other tokens produced by invalid token builders.\n   */\n  isValidToken(token) {\n    return !token.isInsertedInRecovery && !isNaN(token.startOffset) && typeof token.endOffset === \"number\" && !isNaN(token.endOffset);\n  }\n  subrule(idx, rule, fragment, feature, args) {\n    let cstNode;\n    if (!this.isRecording() && !fragment) {\n      cstNode = this.nodeBuilder.buildCompositeNode(feature);\n    }\n    const subruleResult = this.wrapper.wrapSubrule(idx, rule, args);\n    if (!this.isRecording() && cstNode && cstNode.length > 0) {\n      this.performSubruleAssignment(subruleResult, feature, cstNode);\n    }\n  }\n  performSubruleAssignment(result, feature, cstNode) {\n    const { assignment, isCrossRef } = this.getAssignment(feature);\n    if (assignment) {\n      this.assign(assignment.operator, assignment.feature, result, cstNode, isCrossRef);\n    } else if (!assignment) {\n      const current = this.current;\n      if (isDataTypeNode(current)) {\n        current.value += result.toString();\n      } else if (typeof result === \"object\" && result) {\n        const object = this.assignWithoutOverride(result, current);\n        const newItem = object;\n        this.stack.pop();\n        this.stack.push(newItem);\n      }\n    }\n  }\n  action($type, action) {\n    if (!this.isRecording()) {\n      let last = this.current;\n      if (action.feature && action.operator) {\n        last = this.construct();\n        this.nodeBuilder.removeNode(last.$cstNode);\n        const node = this.nodeBuilder.buildCompositeNode(action);\n        node.content.push(last.$cstNode);\n        const newItem = { $type };\n        this.stack.push(newItem);\n        this.assign(action.operator, action.feature, last, last.$cstNode, false);\n      } else {\n        last.$type = $type;\n      }\n    }\n  }\n  construct() {\n    if (this.isRecording()) {\n      return void 0;\n    }\n    const obj = this.current;\n    linkContentToContainer(obj);\n    this.nodeBuilder.construct(obj);\n    this.stack.pop();\n    if (isDataTypeNode(obj)) {\n      return this.converter.convert(obj.value, obj.$cstNode);\n    } else {\n      assignMandatoryProperties(this.astReflection, obj);\n    }\n    return obj;\n  }\n  getAssignment(feature) {\n    if (!this.assignmentMap.has(feature)) {\n      const assignment = getContainerOfType(feature, isAssignment);\n      this.assignmentMap.set(feature, {\n        assignment,\n        isCrossRef: assignment ? isCrossReference(assignment.terminal) : false\n      });\n    }\n    return this.assignmentMap.get(feature);\n  }\n  assign(operator, feature, value, cstNode, isCrossRef) {\n    const obj = this.current;\n    let item;\n    if (isCrossRef && typeof value === \"string\") {\n      item = this.linker.buildReference(obj, feature, cstNode, value);\n    } else {\n      item = value;\n    }\n    switch (operator) {\n      case \"=\": {\n        obj[feature] = item;\n        break;\n      }\n      case \"?=\": {\n        obj[feature] = true;\n        break;\n      }\n      case \"+=\": {\n        if (!Array.isArray(obj[feature])) {\n          obj[feature] = [];\n        }\n        obj[feature].push(item);\n      }\n    }\n  }\n  assignWithoutOverride(target, source) {\n    for (const [name, existingValue] of Object.entries(source)) {\n      const newValue = target[name];\n      if (newValue === void 0) {\n        target[name] = existingValue;\n      } else if (Array.isArray(newValue) && Array.isArray(existingValue)) {\n        existingValue.push(...newValue);\n        target[name] = existingValue;\n      }\n    }\n    const targetCstNode = target.$cstNode;\n    if (targetCstNode) {\n      targetCstNode.astNode = void 0;\n      target.$cstNode = void 0;\n    }\n    return target;\n  }\n  get definitionErrors() {\n    return this.wrapper.definitionErrors;\n  }\n};\nvar AbstractParserErrorMessageProvider = class {\n  static {\n    __name(this, \"AbstractParserErrorMessageProvider\");\n  }\n  buildMismatchTokenMessage(options) {\n    return defaultParserErrorProvider.buildMismatchTokenMessage(options);\n  }\n  buildNotAllInputParsedMessage(options) {\n    return defaultParserErrorProvider.buildNotAllInputParsedMessage(options);\n  }\n  buildNoViableAltMessage(options) {\n    return defaultParserErrorProvider.buildNoViableAltMessage(options);\n  }\n  buildEarlyExitMessage(options) {\n    return defaultParserErrorProvider.buildEarlyExitMessage(options);\n  }\n};\nvar LangiumParserErrorMessageProvider = class extends AbstractParserErrorMessageProvider {\n  static {\n    __name(this, \"LangiumParserErrorMessageProvider\");\n  }\n  buildMismatchTokenMessage({ expected, actual }) {\n    const expectedMsg = expected.LABEL ? \"`\" + expected.LABEL + \"`\" : expected.name.endsWith(\":KW\") ? `keyword '${expected.name.substring(0, expected.name.length - 3)}'` : `token of type '${expected.name}'`;\n    return `Expecting ${expectedMsg} but found \\`${actual.image}\\`.`;\n  }\n  buildNotAllInputParsedMessage({ firstRedundant }) {\n    return `Expecting end of file but found \\`${firstRedundant.image}\\`.`;\n  }\n};\nvar LangiumCompletionParser = class extends AbstractLangiumParser {\n  static {\n    __name(this, \"LangiumCompletionParser\");\n  }\n  constructor() {\n    super(...arguments);\n    this.tokens = [];\n    this.elementStack = [];\n    this.lastElementStack = [];\n    this.nextTokenIndex = 0;\n    this.stackSize = 0;\n  }\n  action() {\n  }\n  construct() {\n    return void 0;\n  }\n  parse(input) {\n    this.resetState();\n    const tokens = this.lexer.tokenize(input, { mode: \"partial\" });\n    this.tokens = tokens.tokens;\n    this.wrapper.input = [...this.tokens];\n    this.mainRule.call(this.wrapper, {});\n    this.unorderedGroups.clear();\n    return {\n      tokens: this.tokens,\n      elementStack: [...this.lastElementStack],\n      tokenIndex: this.nextTokenIndex\n    };\n  }\n  rule(rule, impl) {\n    const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(impl).bind(this));\n    this.allRules.set(rule.name, ruleMethod);\n    if (rule.entry) {\n      this.mainRule = ruleMethod;\n    }\n    return ruleMethod;\n  }\n  resetState() {\n    this.elementStack = [];\n    this.lastElementStack = [];\n    this.nextTokenIndex = 0;\n    this.stackSize = 0;\n  }\n  startImplementation(implementation) {\n    return (args) => {\n      const size = this.keepStackSize();\n      try {\n        implementation(args);\n      } finally {\n        this.resetStackSize(size);\n      }\n    };\n  }\n  removeUnexpectedElements() {\n    this.elementStack.splice(this.stackSize);\n  }\n  keepStackSize() {\n    const size = this.elementStack.length;\n    this.stackSize = size;\n    return size;\n  }\n  resetStackSize(size) {\n    this.removeUnexpectedElements();\n    this.stackSize = size;\n  }\n  consume(idx, tokenType, feature) {\n    this.wrapper.wrapConsume(idx, tokenType);\n    if (!this.isRecording()) {\n      this.lastElementStack = [...this.elementStack, feature];\n      this.nextTokenIndex = this.currIdx + 1;\n    }\n  }\n  subrule(idx, rule, fragment, feature, args) {\n    this.before(feature);\n    this.wrapper.wrapSubrule(idx, rule, args);\n    this.after(feature);\n  }\n  before(element) {\n    if (!this.isRecording()) {\n      this.elementStack.push(element);\n    }\n  }\n  after(element) {\n    if (!this.isRecording()) {\n      const index = this.elementStack.lastIndexOf(element);\n      if (index >= 0) {\n        this.elementStack.splice(index);\n      }\n    }\n  }\n  get currIdx() {\n    return this.wrapper.currIdx;\n  }\n};\nvar defaultConfig = {\n  recoveryEnabled: true,\n  nodeLocationTracking: \"full\",\n  skipValidations: true,\n  errorMessageProvider: new LangiumParserErrorMessageProvider()\n};\nvar ChevrotainWrapper = class extends EmbeddedActionsParser {\n  static {\n    __name(this, \"ChevrotainWrapper\");\n  }\n  constructor(tokens, config) {\n    const useDefaultLookahead = config && \"maxLookahead\" in config;\n    super(tokens, Object.assign(Object.assign(Object.assign({}, defaultConfig), { lookaheadStrategy: useDefaultLookahead ? new LLkLookaheadStrategy({ maxLookahead: config.maxLookahead }) : new LLStarLookaheadStrategy({\n      // If validations are skipped, don't log the lookahead warnings\n      logging: config.skipValidations ? () => {\n      } : void 0\n    }) }), config));\n  }\n  get IS_RECORDING() {\n    return this.RECORDING_PHASE;\n  }\n  DEFINE_RULE(name, impl) {\n    return this.RULE(name, impl);\n  }\n  wrapSelfAnalysis() {\n    this.performSelfAnalysis();\n  }\n  wrapConsume(idx, tokenType) {\n    return this.consume(idx, tokenType);\n  }\n  wrapSubrule(idx, rule, args) {\n    return this.subrule(idx, rule, {\n      ARGS: [args]\n    });\n  }\n  wrapOr(idx, choices) {\n    this.or(idx, choices);\n  }\n  wrapOption(idx, callback) {\n    this.option(idx, callback);\n  }\n  wrapMany(idx, callback) {\n    this.many(idx, callback);\n  }\n  wrapAtLeastOne(idx, callback) {\n    this.atLeastOne(idx, callback);\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/parser-builder-base.js\nfunction createParser(grammar, parser, tokens) {\n  const parserContext = {\n    parser,\n    tokens,\n    ruleNames: /* @__PURE__ */ new Map()\n  };\n  buildRules(parserContext, grammar);\n  return parser;\n}\n__name(createParser, \"createParser\");\nfunction buildRules(parserContext, grammar) {\n  const reachable = getAllReachableRules(grammar, false);\n  const parserRules = stream(grammar.rules).filter(isParserRule).filter((rule) => reachable.has(rule));\n  for (const rule of parserRules) {\n    const ctx = Object.assign(Object.assign({}, parserContext), { consume: 1, optional: 1, subrule: 1, many: 1, or: 1 });\n    parserContext.parser.rule(rule, buildElement(ctx, rule.definition));\n  }\n}\n__name(buildRules, \"buildRules\");\nfunction buildElement(ctx, element, ignoreGuard = false) {\n  let method;\n  if (isKeyword(element)) {\n    method = buildKeyword(ctx, element);\n  } else if (isAction(element)) {\n    method = buildAction(ctx, element);\n  } else if (isAssignment(element)) {\n    method = buildElement(ctx, element.terminal);\n  } else if (isCrossReference(element)) {\n    method = buildCrossReference(ctx, element);\n  } else if (isRuleCall(element)) {\n    method = buildRuleCall(ctx, element);\n  } else if (isAlternatives(element)) {\n    method = buildAlternatives(ctx, element);\n  } else if (isUnorderedGroup(element)) {\n    method = buildUnorderedGroup(ctx, element);\n  } else if (isGroup(element)) {\n    method = buildGroup(ctx, element);\n  } else if (isEndOfFile(element)) {\n    const idx = ctx.consume++;\n    method = /* @__PURE__ */ __name(() => ctx.parser.consume(idx, EOF, element), \"method\");\n  } else {\n    throw new ErrorWithLocation(element.$cstNode, `Unexpected element type: ${element.$type}`);\n  }\n  return wrap(ctx, ignoreGuard ? void 0 : getGuardCondition(element), method, element.cardinality);\n}\n__name(buildElement, \"buildElement\");\nfunction buildAction(ctx, action) {\n  const actionType = getTypeName(action);\n  return () => ctx.parser.action(actionType, action);\n}\n__name(buildAction, \"buildAction\");\nfunction buildRuleCall(ctx, ruleCall) {\n  const rule = ruleCall.rule.ref;\n  if (isParserRule(rule)) {\n    const idx = ctx.subrule++;\n    const fragment = rule.fragment;\n    const predicate = ruleCall.arguments.length > 0 ? buildRuleCallPredicate(rule, ruleCall.arguments) : () => ({});\n    return (args) => ctx.parser.subrule(idx, getRule(ctx, rule), fragment, ruleCall, predicate(args));\n  } else if (isTerminalRule(rule)) {\n    const idx = ctx.consume++;\n    const method = getToken(ctx, rule.name);\n    return () => ctx.parser.consume(idx, method, ruleCall);\n  } else if (!rule) {\n    throw new ErrorWithLocation(ruleCall.$cstNode, `Undefined rule: ${ruleCall.rule.$refText}`);\n  } else {\n    assertUnreachable(rule);\n  }\n}\n__name(buildRuleCall, \"buildRuleCall\");\nfunction buildRuleCallPredicate(rule, namedArgs) {\n  const predicates = namedArgs.map((e) => buildPredicate(e.value));\n  return (args) => {\n    const ruleArgs = {};\n    for (let i = 0; i < predicates.length; i++) {\n      const ruleTarget = rule.parameters[i];\n      const predicate = predicates[i];\n      ruleArgs[ruleTarget.name] = predicate(args);\n    }\n    return ruleArgs;\n  };\n}\n__name(buildRuleCallPredicate, \"buildRuleCallPredicate\");\nfunction buildPredicate(condition) {\n  if (isDisjunction(condition)) {\n    const left = buildPredicate(condition.left);\n    const right = buildPredicate(condition.right);\n    return (args) => left(args) || right(args);\n  } else if (isConjunction(condition)) {\n    const left = buildPredicate(condition.left);\n    const right = buildPredicate(condition.right);\n    return (args) => left(args) && right(args);\n  } else if (isNegation(condition)) {\n    const value = buildPredicate(condition.value);\n    return (args) => !value(args);\n  } else if (isParameterReference(condition)) {\n    const name = condition.parameter.ref.name;\n    return (args) => args !== void 0 && args[name] === true;\n  } else if (isBooleanLiteral(condition)) {\n    const value = Boolean(condition.true);\n    return () => value;\n  }\n  assertUnreachable(condition);\n}\n__name(buildPredicate, \"buildPredicate\");\nfunction buildAlternatives(ctx, alternatives) {\n  if (alternatives.elements.length === 1) {\n    return buildElement(ctx, alternatives.elements[0]);\n  } else {\n    const methods = [];\n    for (const element of alternatives.elements) {\n      const predicatedMethod = {\n        // Since we handle the guard condition in the alternative already\n        // We can ignore the group guard condition inside\n        ALT: buildElement(ctx, element, true)\n      };\n      const guard = getGuardCondition(element);\n      if (guard) {\n        predicatedMethod.GATE = buildPredicate(guard);\n      }\n      methods.push(predicatedMethod);\n    }\n    const idx = ctx.or++;\n    return (args) => ctx.parser.alternatives(idx, methods.map((method) => {\n      const alt = {\n        ALT: /* @__PURE__ */ __name(() => method.ALT(args), \"ALT\")\n      };\n      const gate = method.GATE;\n      if (gate) {\n        alt.GATE = () => gate(args);\n      }\n      return alt;\n    }));\n  }\n}\n__name(buildAlternatives, \"buildAlternatives\");\nfunction buildUnorderedGroup(ctx, group) {\n  if (group.elements.length === 1) {\n    return buildElement(ctx, group.elements[0]);\n  }\n  const methods = [];\n  for (const element of group.elements) {\n    const predicatedMethod = {\n      // Since we handle the guard condition in the alternative already\n      // We can ignore the group guard condition inside\n      ALT: buildElement(ctx, element, true)\n    };\n    const guard = getGuardCondition(element);\n    if (guard) {\n      predicatedMethod.GATE = buildPredicate(guard);\n    }\n    methods.push(predicatedMethod);\n  }\n  const orIdx = ctx.or++;\n  const idFunc = /* @__PURE__ */ __name((groupIdx, lParser) => {\n    const stackId = lParser.getRuleStack().join(\"-\");\n    return `uGroup_${groupIdx}_${stackId}`;\n  }, \"idFunc\");\n  const alternatives = /* @__PURE__ */ __name((args) => ctx.parser.alternatives(orIdx, methods.map((method, idx) => {\n    const alt = { ALT: /* @__PURE__ */ __name(() => true, \"ALT\") };\n    const parser = ctx.parser;\n    alt.ALT = () => {\n      method.ALT(args);\n      if (!parser.isRecording()) {\n        const key = idFunc(orIdx, parser);\n        if (!parser.unorderedGroups.get(key)) {\n          parser.unorderedGroups.set(key, []);\n        }\n        const groupState = parser.unorderedGroups.get(key);\n        if (typeof (groupState === null || groupState === void 0 ? void 0 : groupState[idx]) === \"undefined\") {\n          groupState[idx] = true;\n        }\n      }\n    };\n    const gate = method.GATE;\n    if (gate) {\n      alt.GATE = () => gate(args);\n    } else {\n      alt.GATE = () => {\n        const trackedAlternatives = parser.unorderedGroups.get(idFunc(orIdx, parser));\n        const allow = !(trackedAlternatives === null || trackedAlternatives === void 0 ? void 0 : trackedAlternatives[idx]);\n        return allow;\n      };\n    }\n    return alt;\n  })), \"alternatives\");\n  const wrapped = wrap(ctx, getGuardCondition(group), alternatives, \"*\");\n  return (args) => {\n    wrapped(args);\n    if (!ctx.parser.isRecording()) {\n      ctx.parser.unorderedGroups.delete(idFunc(orIdx, ctx.parser));\n    }\n  };\n}\n__name(buildUnorderedGroup, \"buildUnorderedGroup\");\nfunction buildGroup(ctx, group) {\n  const methods = group.elements.map((e) => buildElement(ctx, e));\n  return (args) => methods.forEach((method) => method(args));\n}\n__name(buildGroup, \"buildGroup\");\nfunction getGuardCondition(element) {\n  if (isGroup(element)) {\n    return element.guardCondition;\n  }\n  return void 0;\n}\n__name(getGuardCondition, \"getGuardCondition\");\nfunction buildCrossReference(ctx, crossRef, terminal = crossRef.terminal) {\n  if (!terminal) {\n    if (!crossRef.type.ref) {\n      throw new Error(\"Could not resolve reference to type: \" + crossRef.type.$refText);\n    }\n    const assignment = findNameAssignment(crossRef.type.ref);\n    const assignTerminal = assignment === null || assignment === void 0 ? void 0 : assignment.terminal;\n    if (!assignTerminal) {\n      throw new Error(\"Could not find name assignment for type: \" + getTypeName(crossRef.type.ref));\n    }\n    return buildCrossReference(ctx, crossRef, assignTerminal);\n  } else if (isRuleCall(terminal) && isParserRule(terminal.rule.ref)) {\n    const rule = terminal.rule.ref;\n    const idx = ctx.subrule++;\n    return (args) => ctx.parser.subrule(idx, getRule(ctx, rule), false, crossRef, args);\n  } else if (isRuleCall(terminal) && isTerminalRule(terminal.rule.ref)) {\n    const idx = ctx.consume++;\n    const terminalRule = getToken(ctx, terminal.rule.ref.name);\n    return () => ctx.parser.consume(idx, terminalRule, crossRef);\n  } else if (isKeyword(terminal)) {\n    const idx = ctx.consume++;\n    const keyword = getToken(ctx, terminal.value);\n    return () => ctx.parser.consume(idx, keyword, crossRef);\n  } else {\n    throw new Error(\"Could not build cross reference parser\");\n  }\n}\n__name(buildCrossReference, \"buildCrossReference\");\nfunction buildKeyword(ctx, keyword) {\n  const idx = ctx.consume++;\n  const token = ctx.tokens[keyword.value];\n  if (!token) {\n    throw new Error(\"Could not find token for keyword: \" + keyword.value);\n  }\n  return () => ctx.parser.consume(idx, token, keyword);\n}\n__name(buildKeyword, \"buildKeyword\");\nfunction wrap(ctx, guard, method, cardinality) {\n  const gate = guard && buildPredicate(guard);\n  if (!cardinality) {\n    if (gate) {\n      const idx = ctx.or++;\n      return (args) => ctx.parser.alternatives(idx, [\n        {\n          ALT: /* @__PURE__ */ __name(() => method(args), \"ALT\"),\n          GATE: /* @__PURE__ */ __name(() => gate(args), \"GATE\")\n        },\n        {\n          ALT: EMPTY_ALT(),\n          GATE: /* @__PURE__ */ __name(() => !gate(args), \"GATE\")\n        }\n      ]);\n    } else {\n      return method;\n    }\n  }\n  if (cardinality === \"*\") {\n    const idx = ctx.many++;\n    return (args) => ctx.parser.many(idx, {\n      DEF: /* @__PURE__ */ __name(() => method(args), \"DEF\"),\n      GATE: gate ? () => gate(args) : void 0\n    });\n  } else if (cardinality === \"+\") {\n    const idx = ctx.many++;\n    if (gate) {\n      const orIdx = ctx.or++;\n      return (args) => ctx.parser.alternatives(orIdx, [\n        {\n          ALT: /* @__PURE__ */ __name(() => ctx.parser.atLeastOne(idx, {\n            DEF: /* @__PURE__ */ __name(() => method(args), \"DEF\")\n          }), \"ALT\"),\n          GATE: /* @__PURE__ */ __name(() => gate(args), \"GATE\")\n        },\n        {\n          ALT: EMPTY_ALT(),\n          GATE: /* @__PURE__ */ __name(() => !gate(args), \"GATE\")\n        }\n      ]);\n    } else {\n      return (args) => ctx.parser.atLeastOne(idx, {\n        DEF: /* @__PURE__ */ __name(() => method(args), \"DEF\")\n      });\n    }\n  } else if (cardinality === \"?\") {\n    const idx = ctx.optional++;\n    return (args) => ctx.parser.optional(idx, {\n      DEF: /* @__PURE__ */ __name(() => method(args), \"DEF\"),\n      GATE: gate ? () => gate(args) : void 0\n    });\n  } else {\n    assertUnreachable(cardinality);\n  }\n}\n__name(wrap, \"wrap\");\nfunction getRule(ctx, element) {\n  const name = getRuleName(ctx, element);\n  const rule = ctx.parser.getRule(name);\n  if (!rule)\n    throw new Error(`Rule \"${name}\" not found.\"`);\n  return rule;\n}\n__name(getRule, \"getRule\");\nfunction getRuleName(ctx, element) {\n  if (isParserRule(element)) {\n    return element.name;\n  } else if (ctx.ruleNames.has(element)) {\n    return ctx.ruleNames.get(element);\n  } else {\n    let item = element;\n    let parent = item.$container;\n    let ruleName = element.$type;\n    while (!isParserRule(parent)) {\n      if (isGroup(parent) || isAlternatives(parent) || isUnorderedGroup(parent)) {\n        const index = parent.elements.indexOf(item);\n        ruleName = index.toString() + \":\" + ruleName;\n      }\n      item = parent;\n      parent = parent.$container;\n    }\n    const rule = parent;\n    ruleName = rule.name + \":\" + ruleName;\n    ctx.ruleNames.set(element, ruleName);\n    return ruleName;\n  }\n}\n__name(getRuleName, \"getRuleName\");\nfunction getToken(ctx, name) {\n  const token = ctx.tokens[name];\n  if (!token)\n    throw new Error(`Token \"${name}\" not found.\"`);\n  return token;\n}\n__name(getToken, \"getToken\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/completion-parser-builder.js\nfunction createCompletionParser(services) {\n  const grammar = services.Grammar;\n  const lexer = services.parser.Lexer;\n  const parser = new LangiumCompletionParser(services);\n  createParser(grammar, parser, lexer.definition);\n  parser.finalize();\n  return parser;\n}\n__name(createCompletionParser, \"createCompletionParser\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/langium-parser-builder.js\nfunction createLangiumParser(services) {\n  const parser = prepareLangiumParser(services);\n  parser.finalize();\n  return parser;\n}\n__name(createLangiumParser, \"createLangiumParser\");\nfunction prepareLangiumParser(services) {\n  const grammar = services.Grammar;\n  const lexer = services.parser.Lexer;\n  const parser = new LangiumParser(services);\n  return createParser(grammar, parser, lexer.definition);\n}\n__name(prepareLangiumParser, \"prepareLangiumParser\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/token-builder.js\nvar DefaultTokenBuilder = class {\n  static {\n    __name(this, \"DefaultTokenBuilder\");\n  }\n  constructor() {\n    this.diagnostics = [];\n  }\n  buildTokens(grammar, options) {\n    const reachableRules = stream(getAllReachableRules(grammar, false));\n    const terminalTokens = this.buildTerminalTokens(reachableRules);\n    const tokens = this.buildKeywordTokens(reachableRules, terminalTokens, options);\n    terminalTokens.forEach((terminalToken) => {\n      const pattern = terminalToken.PATTERN;\n      if (typeof pattern === \"object\" && pattern && \"test\" in pattern && isWhitespace(pattern)) {\n        tokens.unshift(terminalToken);\n      } else {\n        tokens.push(terminalToken);\n      }\n    });\n    return tokens;\n  }\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  flushLexingReport(text) {\n    return { diagnostics: this.popDiagnostics() };\n  }\n  popDiagnostics() {\n    const diagnostics = [...this.diagnostics];\n    this.diagnostics = [];\n    return diagnostics;\n  }\n  buildTerminalTokens(rules) {\n    return rules.filter(isTerminalRule).filter((e) => !e.fragment).map((terminal) => this.buildTerminalToken(terminal)).toArray();\n  }\n  buildTerminalToken(terminal) {\n    const regex = terminalRegex(terminal);\n    const pattern = this.requiresCustomPattern(regex) ? this.regexPatternFunction(regex) : regex;\n    const tokenType = {\n      name: terminal.name,\n      PATTERN: pattern\n    };\n    if (typeof pattern === \"function\") {\n      tokenType.LINE_BREAKS = true;\n    }\n    if (terminal.hidden) {\n      tokenType.GROUP = isWhitespace(regex) ? Lexer.SKIPPED : \"hidden\";\n    }\n    return tokenType;\n  }\n  requiresCustomPattern(regex) {\n    if (regex.flags.includes(\"u\") || regex.flags.includes(\"s\")) {\n      return true;\n    } else if (regex.source.includes(\"?<=\") || regex.source.includes(\"?<!\")) {\n      return true;\n    } else {\n      return false;\n    }\n  }\n  regexPatternFunction(regex) {\n    const stickyRegex = new RegExp(regex, regex.flags + \"y\");\n    return (text, offset) => {\n      stickyRegex.lastIndex = offset;\n      const execResult = stickyRegex.exec(text);\n      return execResult;\n    };\n  }\n  buildKeywordTokens(rules, terminalTokens, options) {\n    return rules.filter(isParserRule).flatMap((rule) => streamAllContents(rule).filter(isKeyword)).distinct((e) => e.value).toArray().sort((a, b) => b.value.length - a.value.length).map((keyword) => this.buildKeywordToken(keyword, terminalTokens, Boolean(options === null || options === void 0 ? void 0 : options.caseInsensitive)));\n  }\n  buildKeywordToken(keyword, terminalTokens, caseInsensitive) {\n    const keywordPattern = this.buildKeywordPattern(keyword, caseInsensitive);\n    const tokenType = {\n      name: keyword.value,\n      PATTERN: keywordPattern,\n      LONGER_ALT: this.findLongerAlt(keyword, terminalTokens)\n    };\n    if (typeof keywordPattern === \"function\") {\n      tokenType.LINE_BREAKS = true;\n    }\n    return tokenType;\n  }\n  buildKeywordPattern(keyword, caseInsensitive) {\n    return caseInsensitive ? new RegExp(getCaseInsensitivePattern(keyword.value)) : keyword.value;\n  }\n  findLongerAlt(keyword, terminalTokens) {\n    return terminalTokens.reduce((longerAlts, token) => {\n      const pattern = token === null || token === void 0 ? void 0 : token.PATTERN;\n      if ((pattern === null || pattern === void 0 ? void 0 : pattern.source) && partialMatches(\"^\" + pattern.source + \"$\", keyword.value)) {\n        longerAlts.push(token);\n      }\n      return longerAlts;\n    }, []);\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/value-converter.js\nvar DefaultValueConverter = class {\n  static {\n    __name(this, \"DefaultValueConverter\");\n  }\n  convert(input, cstNode) {\n    let feature = cstNode.grammarSource;\n    if (isCrossReference(feature)) {\n      feature = getCrossReferenceTerminal(feature);\n    }\n    if (isRuleCall(feature)) {\n      const rule = feature.rule.ref;\n      if (!rule) {\n        throw new Error(\"This cst node was not parsed by a rule.\");\n      }\n      return this.runConverter(rule, input, cstNode);\n    }\n    return input;\n  }\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  runConverter(rule, input, cstNode) {\n    var _a;\n    switch (rule.name.toUpperCase()) {\n      case \"INT\":\n        return ValueConverter.convertInt(input);\n      case \"STRING\":\n        return ValueConverter.convertString(input);\n      case \"ID\":\n        return ValueConverter.convertID(input);\n    }\n    switch ((_a = getRuleType(rule)) === null || _a === void 0 ? void 0 : _a.toLowerCase()) {\n      case \"number\":\n        return ValueConverter.convertNumber(input);\n      case \"boolean\":\n        return ValueConverter.convertBoolean(input);\n      case \"bigint\":\n        return ValueConverter.convertBigint(input);\n      case \"date\":\n        return ValueConverter.convertDate(input);\n      default:\n        return input;\n    }\n  }\n};\nvar ValueConverter;\n(function(ValueConverter2) {\n  function convertString(input) {\n    let result = \"\";\n    for (let i = 1; i < input.length - 1; i++) {\n      const c = input.charAt(i);\n      if (c === \"\\\\\") {\n        const c1 = input.charAt(++i);\n        result += convertEscapeCharacter(c1);\n      } else {\n        result += c;\n      }\n    }\n    return result;\n  }\n  __name(convertString, \"convertString\");\n  ValueConverter2.convertString = convertString;\n  function convertEscapeCharacter(char) {\n    switch (char) {\n      case \"b\":\n        return \"\\b\";\n      case \"f\":\n        return \"\\f\";\n      case \"n\":\n        return \"\\n\";\n      case \"r\":\n        return \"\\r\";\n      case \"t\":\n        return \"\t\";\n      case \"v\":\n        return \"\\v\";\n      case \"0\":\n        return \"\\0\";\n      default:\n        return char;\n    }\n  }\n  __name(convertEscapeCharacter, \"convertEscapeCharacter\");\n  function convertID(input) {\n    if (input.charAt(0) === \"^\") {\n      return input.substring(1);\n    } else {\n      return input;\n    }\n  }\n  __name(convertID, \"convertID\");\n  ValueConverter2.convertID = convertID;\n  function convertInt(input) {\n    return parseInt(input);\n  }\n  __name(convertInt, \"convertInt\");\n  ValueConverter2.convertInt = convertInt;\n  function convertBigint(input) {\n    return BigInt(input);\n  }\n  __name(convertBigint, \"convertBigint\");\n  ValueConverter2.convertBigint = convertBigint;\n  function convertDate(input) {\n    return new Date(input);\n  }\n  __name(convertDate, \"convertDate\");\n  ValueConverter2.convertDate = convertDate;\n  function convertNumber(input) {\n    return Number(input);\n  }\n  __name(convertNumber, \"convertNumber\");\n  ValueConverter2.convertNumber = convertNumber;\n  function convertBoolean(input) {\n    return input.toLowerCase() === \"true\";\n  }\n  __name(convertBoolean, \"convertBoolean\");\n  ValueConverter2.convertBoolean = convertBoolean;\n})(ValueConverter || (ValueConverter = {}));\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/cancellation.js\nvar cancellation_exports = {};\n__reExport(cancellation_exports, __toESM(require_cancellation(), 1));\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/promise-utils.js\nfunction delayNextTick() {\n  return new Promise((resolve) => {\n    if (typeof setImmediate === \"undefined\") {\n      setTimeout(resolve, 0);\n    } else {\n      setImmediate(resolve);\n    }\n  });\n}\n__name(delayNextTick, \"delayNextTick\");\nvar lastTick = 0;\nvar globalInterruptionPeriod = 10;\nfunction startCancelableOperation() {\n  lastTick = performance.now();\n  return new cancellation_exports.CancellationTokenSource();\n}\n__name(startCancelableOperation, \"startCancelableOperation\");\nfunction setInterruptionPeriod(period) {\n  globalInterruptionPeriod = period;\n}\n__name(setInterruptionPeriod, \"setInterruptionPeriod\");\nvar OperationCancelled = Symbol(\"OperationCancelled\");\nfunction isOperationCancelled(err) {\n  return err === OperationCancelled;\n}\n__name(isOperationCancelled, \"isOperationCancelled\");\nasync function interruptAndCheck(token) {\n  if (token === cancellation_exports.CancellationToken.None) {\n    return;\n  }\n  const current = performance.now();\n  if (current - lastTick >= globalInterruptionPeriod) {\n    lastTick = current;\n    await delayNextTick();\n    lastTick = performance.now();\n  }\n  if (token.isCancellationRequested) {\n    throw OperationCancelled;\n  }\n}\n__name(interruptAndCheck, \"interruptAndCheck\");\nvar Deferred = class {\n  static {\n    __name(this, \"Deferred\");\n  }\n  constructor() {\n    this.promise = new Promise((resolve, reject) => {\n      this.resolve = (arg) => {\n        resolve(arg);\n        return this;\n      };\n      this.reject = (err) => {\n        reject(err);\n        return this;\n      };\n    });\n  }\n};\n\n// ../../node_modules/.pnpm/vscode-languageserver-textdocument@1.0.12/node_modules/vscode-languageserver-textdocument/lib/esm/main.js\nvar FullTextDocument2 = class _FullTextDocument {\n  static {\n    __name(this, \"FullTextDocument\");\n  }\n  constructor(uri, languageId, version, content) {\n    this._uri = uri;\n    this._languageId = languageId;\n    this._version = version;\n    this._content = content;\n    this._lineOffsets = void 0;\n  }\n  get uri() {\n    return this._uri;\n  }\n  get languageId() {\n    return this._languageId;\n  }\n  get version() {\n    return this._version;\n  }\n  getText(range) {\n    if (range) {\n      const start = this.offsetAt(range.start);\n      const end = this.offsetAt(range.end);\n      return this._content.substring(start, end);\n    }\n    return this._content;\n  }\n  update(changes, version) {\n    for (const change of changes) {\n      if (_FullTextDocument.isIncremental(change)) {\n        const range = getWellformedRange(change.range);\n        const startOffset = this.offsetAt(range.start);\n        const endOffset = this.offsetAt(range.end);\n        this._content = this._content.substring(0, startOffset) + change.text + this._content.substring(endOffset, this._content.length);\n        const startLine = Math.max(range.start.line, 0);\n        const endLine = Math.max(range.end.line, 0);\n        let lineOffsets = this._lineOffsets;\n        const addedLineOffsets = computeLineOffsets(change.text, false, startOffset);\n        if (endLine - startLine === addedLineOffsets.length) {\n          for (let i = 0, len = addedLineOffsets.length; i < len; i++) {\n            lineOffsets[i + startLine + 1] = addedLineOffsets[i];\n          }\n        } else {\n          if (addedLineOffsets.length < 1e4) {\n            lineOffsets.splice(startLine + 1, endLine - startLine, ...addedLineOffsets);\n          } else {\n            this._lineOffsets = lineOffsets = lineOffsets.slice(0, startLine + 1).concat(addedLineOffsets, lineOffsets.slice(endLine + 1));\n          }\n        }\n        const diff = change.text.length - (endOffset - startOffset);\n        if (diff !== 0) {\n          for (let i = startLine + 1 + addedLineOffsets.length, len = lineOffsets.length; i < len; i++) {\n            lineOffsets[i] = lineOffsets[i] + diff;\n          }\n        }\n      } else if (_FullTextDocument.isFull(change)) {\n        this._content = change.text;\n        this._lineOffsets = void 0;\n      } else {\n        throw new Error(\"Unknown change event received\");\n      }\n    }\n    this._version = version;\n  }\n  getLineOffsets() {\n    if (this._lineOffsets === void 0) {\n      this._lineOffsets = computeLineOffsets(this._content, true);\n    }\n    return this._lineOffsets;\n  }\n  positionAt(offset) {\n    offset = Math.max(Math.min(offset, this._content.length), 0);\n    const lineOffsets = this.getLineOffsets();\n    let low = 0, high = lineOffsets.length;\n    if (high === 0) {\n      return { line: 0, character: offset };\n    }\n    while (low < high) {\n      const mid = Math.floor((low + high) / 2);\n      if (lineOffsets[mid] > offset) {\n        high = mid;\n      } else {\n        low = mid + 1;\n      }\n    }\n    const line = low - 1;\n    offset = this.ensureBeforeEOL(offset, lineOffsets[line]);\n    return { line, character: offset - lineOffsets[line] };\n  }\n  offsetAt(position) {\n    const lineOffsets = this.getLineOffsets();\n    if (position.line >= lineOffsets.length) {\n      return this._content.length;\n    } else if (position.line < 0) {\n      return 0;\n    }\n    const lineOffset = lineOffsets[position.line];\n    if (position.character <= 0) {\n      return lineOffset;\n    }\n    const nextLineOffset = position.line + 1 < lineOffsets.length ? lineOffsets[position.line + 1] : this._content.length;\n    const offset = Math.min(lineOffset + position.character, nextLineOffset);\n    return this.ensureBeforeEOL(offset, lineOffset);\n  }\n  ensureBeforeEOL(offset, lineOffset) {\n    while (offset > lineOffset && isEOL(this._content.charCodeAt(offset - 1))) {\n      offset--;\n    }\n    return offset;\n  }\n  get lineCount() {\n    return this.getLineOffsets().length;\n  }\n  static isIncremental(event) {\n    const candidate = event;\n    return candidate !== void 0 && candidate !== null && typeof candidate.text === \"string\" && candidate.range !== void 0 && (candidate.rangeLength === void 0 || typeof candidate.rangeLength === \"number\");\n  }\n  static isFull(event) {\n    const candidate = event;\n    return candidate !== void 0 && candidate !== null && typeof candidate.text === \"string\" && candidate.range === void 0 && candidate.rangeLength === void 0;\n  }\n};\nvar TextDocument2;\n(function(TextDocument3) {\n  function create(uri, languageId, version, content) {\n    return new FullTextDocument2(uri, languageId, version, content);\n  }\n  __name(create, \"create\");\n  TextDocument3.create = create;\n  function update(document, changes, version) {\n    if (document instanceof FullTextDocument2) {\n      document.update(changes, version);\n      return document;\n    } else {\n      throw new Error(\"TextDocument.update: document must be created by TextDocument.create\");\n    }\n  }\n  __name(update, \"update\");\n  TextDocument3.update = update;\n  function applyEdits(document, edits) {\n    const text = document.getText();\n    const sortedEdits = mergeSort(edits.map(getWellformedEdit), (a, b) => {\n      const diff = a.range.start.line - b.range.start.line;\n      if (diff === 0) {\n        return a.range.start.character - b.range.start.character;\n      }\n      return diff;\n    });\n    let lastModifiedOffset = 0;\n    const spans = [];\n    for (const e of sortedEdits) {\n      const startOffset = document.offsetAt(e.range.start);\n      if (startOffset < lastModifiedOffset) {\n        throw new Error(\"Overlapping edit\");\n      } else if (startOffset > lastModifiedOffset) {\n        spans.push(text.substring(lastModifiedOffset, startOffset));\n      }\n      if (e.newText.length) {\n        spans.push(e.newText);\n      }\n      lastModifiedOffset = document.offsetAt(e.range.end);\n    }\n    spans.push(text.substr(lastModifiedOffset));\n    return spans.join(\"\");\n  }\n  __name(applyEdits, \"applyEdits\");\n  TextDocument3.applyEdits = applyEdits;\n})(TextDocument2 || (TextDocument2 = {}));\nfunction mergeSort(data, compare) {\n  if (data.length <= 1) {\n    return data;\n  }\n  const p = data.length / 2 | 0;\n  const left = data.slice(0, p);\n  const right = data.slice(p);\n  mergeSort(left, compare);\n  mergeSort(right, compare);\n  let leftIdx = 0;\n  let rightIdx = 0;\n  let i = 0;\n  while (leftIdx < left.length && rightIdx < right.length) {\n    const ret = compare(left[leftIdx], right[rightIdx]);\n    if (ret <= 0) {\n      data[i++] = left[leftIdx++];\n    } else {\n      data[i++] = right[rightIdx++];\n    }\n  }\n  while (leftIdx < left.length) {\n    data[i++] = left[leftIdx++];\n  }\n  while (rightIdx < right.length) {\n    data[i++] = right[rightIdx++];\n  }\n  return data;\n}\n__name(mergeSort, \"mergeSort\");\nfunction computeLineOffsets(text, isAtLineStart, textOffset = 0) {\n  const result = isAtLineStart ? [textOffset] : [];\n  for (let i = 0; i < text.length; i++) {\n    const ch = text.charCodeAt(i);\n    if (isEOL(ch)) {\n      if (ch === 13 && i + 1 < text.length && text.charCodeAt(i + 1) === 10) {\n        i++;\n      }\n      result.push(textOffset + i + 1);\n    }\n  }\n  return result;\n}\n__name(computeLineOffsets, \"computeLineOffsets\");\nfunction isEOL(char) {\n  return char === 13 || char === 10;\n}\n__name(isEOL, \"isEOL\");\nfunction getWellformedRange(range) {\n  const start = range.start;\n  const end = range.end;\n  if (start.line > end.line || start.line === end.line && start.character > end.character) {\n    return { start: end, end: start };\n  }\n  return range;\n}\n__name(getWellformedRange, \"getWellformedRange\");\nfunction getWellformedEdit(textEdit) {\n  const range = getWellformedRange(textEdit.range);\n  if (range !== textEdit.range) {\n    return { newText: textEdit.newText, range };\n  }\n  return textEdit;\n}\n__name(getWellformedEdit, \"getWellformedEdit\");\n\n// ../../node_modules/.pnpm/vscode-uri@3.0.8/node_modules/vscode-uri/lib/esm/index.mjs\nvar LIB;\n(() => {\n  \"use strict\";\n  var t = { 470: (t2) => {\n    function e2(t3) {\n      if (\"string\" != typeof t3) throw new TypeError(\"Path must be a string. Received \" + JSON.stringify(t3));\n    }\n    __name(e2, \"e\");\n    function r2(t3, e3) {\n      for (var r3, n3 = \"\", i = 0, o = -1, s = 0, h = 0; h <= t3.length; ++h) {\n        if (h < t3.length) r3 = t3.charCodeAt(h);\n        else {\n          if (47 === r3) break;\n          r3 = 47;\n        }\n        if (47 === r3) {\n          if (o === h - 1 || 1 === s) ;\n          else if (o !== h - 1 && 2 === s) {\n            if (n3.length < 2 || 2 !== i || 46 !== n3.charCodeAt(n3.length - 1) || 46 !== n3.charCodeAt(n3.length - 2)) {\n              if (n3.length > 2) {\n                var a = n3.lastIndexOf(\"/\");\n                if (a !== n3.length - 1) {\n                  -1 === a ? (n3 = \"\", i = 0) : i = (n3 = n3.slice(0, a)).length - 1 - n3.lastIndexOf(\"/\"), o = h, s = 0;\n                  continue;\n                }\n              } else if (2 === n3.length || 1 === n3.length) {\n                n3 = \"\", i = 0, o = h, s = 0;\n                continue;\n              }\n            }\n            e3 && (n3.length > 0 ? n3 += \"/..\" : n3 = \"..\", i = 2);\n          } else n3.length > 0 ? n3 += \"/\" + t3.slice(o + 1, h) : n3 = t3.slice(o + 1, h), i = h - o - 1;\n          o = h, s = 0;\n        } else 46 === r3 && -1 !== s ? ++s : s = -1;\n      }\n      return n3;\n    }\n    __name(r2, \"r\");\n    var n2 = { resolve: /* @__PURE__ */ __name(function() {\n      for (var t3, n3 = \"\", i = false, o = arguments.length - 1; o >= -1 && !i; o--) {\n        var s;\n        o >= 0 ? s = arguments[o] : (void 0 === t3 && (t3 = process.cwd()), s = t3), e2(s), 0 !== s.length && (n3 = s + \"/\" + n3, i = 47 === s.charCodeAt(0));\n      }\n      return n3 = r2(n3, !i), i ? n3.length > 0 ? \"/\" + n3 : \"/\" : n3.length > 0 ? n3 : \".\";\n    }, \"resolve\"), normalize: /* @__PURE__ */ __name(function(t3) {\n      if (e2(t3), 0 === t3.length) return \".\";\n      var n3 = 47 === t3.charCodeAt(0), i = 47 === t3.charCodeAt(t3.length - 1);\n      return 0 !== (t3 = r2(t3, !n3)).length || n3 || (t3 = \".\"), t3.length > 0 && i && (t3 += \"/\"), n3 ? \"/\" + t3 : t3;\n    }, \"normalize\"), isAbsolute: /* @__PURE__ */ __name(function(t3) {\n      return e2(t3), t3.length > 0 && 47 === t3.charCodeAt(0);\n    }, \"isAbsolute\"), join: /* @__PURE__ */ __name(function() {\n      if (0 === arguments.length) return \".\";\n      for (var t3, r3 = 0; r3 < arguments.length; ++r3) {\n        var i = arguments[r3];\n        e2(i), i.length > 0 && (void 0 === t3 ? t3 = i : t3 += \"/\" + i);\n      }\n      return void 0 === t3 ? \".\" : n2.normalize(t3);\n    }, \"join\"), relative: /* @__PURE__ */ __name(function(t3, r3) {\n      if (e2(t3), e2(r3), t3 === r3) return \"\";\n      if ((t3 = n2.resolve(t3)) === (r3 = n2.resolve(r3))) return \"\";\n      for (var i = 1; i < t3.length && 47 === t3.charCodeAt(i); ++i) ;\n      for (var o = t3.length, s = o - i, h = 1; h < r3.length && 47 === r3.charCodeAt(h); ++h) ;\n      for (var a = r3.length - h, c = s < a ? s : a, f = -1, u = 0; u <= c; ++u) {\n        if (u === c) {\n          if (a > c) {\n            if (47 === r3.charCodeAt(h + u)) return r3.slice(h + u + 1);\n            if (0 === u) return r3.slice(h + u);\n          } else s > c && (47 === t3.charCodeAt(i + u) ? f = u : 0 === u && (f = 0));\n          break;\n        }\n        var l = t3.charCodeAt(i + u);\n        if (l !== r3.charCodeAt(h + u)) break;\n        47 === l && (f = u);\n      }\n      var g = \"\";\n      for (u = i + f + 1; u <= o; ++u) u !== o && 47 !== t3.charCodeAt(u) || (0 === g.length ? g += \"..\" : g += \"/..\");\n      return g.length > 0 ? g + r3.slice(h + f) : (h += f, 47 === r3.charCodeAt(h) && ++h, r3.slice(h));\n    }, \"relative\"), _makeLong: /* @__PURE__ */ __name(function(t3) {\n      return t3;\n    }, \"_makeLong\"), dirname: /* @__PURE__ */ __name(function(t3) {\n      if (e2(t3), 0 === t3.length) return \".\";\n      for (var r3 = t3.charCodeAt(0), n3 = 47 === r3, i = -1, o = true, s = t3.length - 1; s >= 1; --s) if (47 === (r3 = t3.charCodeAt(s))) {\n        if (!o) {\n          i = s;\n          break;\n        }\n      } else o = false;\n      return -1 === i ? n3 ? \"/\" : \".\" : n3 && 1 === i ? \"//\" : t3.slice(0, i);\n    }, \"dirname\"), basename: /* @__PURE__ */ __name(function(t3, r3) {\n      if (void 0 !== r3 && \"string\" != typeof r3) throw new TypeError('\"ext\" argument must be a string');\n      e2(t3);\n      var n3, i = 0, o = -1, s = true;\n      if (void 0 !== r3 && r3.length > 0 && r3.length <= t3.length) {\n        if (r3.length === t3.length && r3 === t3) return \"\";\n        var h = r3.length - 1, a = -1;\n        for (n3 = t3.length - 1; n3 >= 0; --n3) {\n          var c = t3.charCodeAt(n3);\n          if (47 === c) {\n            if (!s) {\n              i = n3 + 1;\n              break;\n            }\n          } else -1 === a && (s = false, a = n3 + 1), h >= 0 && (c === r3.charCodeAt(h) ? -1 == --h && (o = n3) : (h = -1, o = a));\n        }\n        return i === o ? o = a : -1 === o && (o = t3.length), t3.slice(i, o);\n      }\n      for (n3 = t3.length - 1; n3 >= 0; --n3) if (47 === t3.charCodeAt(n3)) {\n        if (!s) {\n          i = n3 + 1;\n          break;\n        }\n      } else -1 === o && (s = false, o = n3 + 1);\n      return -1 === o ? \"\" : t3.slice(i, o);\n    }, \"basename\"), extname: /* @__PURE__ */ __name(function(t3) {\n      e2(t3);\n      for (var r3 = -1, n3 = 0, i = -1, o = true, s = 0, h = t3.length - 1; h >= 0; --h) {\n        var a = t3.charCodeAt(h);\n        if (47 !== a) -1 === i && (o = false, i = h + 1), 46 === a ? -1 === r3 ? r3 = h : 1 !== s && (s = 1) : -1 !== r3 && (s = -1);\n        else if (!o) {\n          n3 = h + 1;\n          break;\n        }\n      }\n      return -1 === r3 || -1 === i || 0 === s || 1 === s && r3 === i - 1 && r3 === n3 + 1 ? \"\" : t3.slice(r3, i);\n    }, \"extname\"), format: /* @__PURE__ */ __name(function(t3) {\n      if (null === t3 || \"object\" != typeof t3) throw new TypeError('The \"pathObject\" argument must be of type Object. Received type ' + typeof t3);\n      return function(t4, e3) {\n        var r3 = e3.dir || e3.root, n3 = e3.base || (e3.name || \"\") + (e3.ext || \"\");\n        return r3 ? r3 === e3.root ? r3 + n3 : r3 + \"/\" + n3 : n3;\n      }(0, t3);\n    }, \"format\"), parse: /* @__PURE__ */ __name(function(t3) {\n      e2(t3);\n      var r3 = { root: \"\", dir: \"\", base: \"\", ext: \"\", name: \"\" };\n      if (0 === t3.length) return r3;\n      var n3, i = t3.charCodeAt(0), o = 47 === i;\n      o ? (r3.root = \"/\", n3 = 1) : n3 = 0;\n      for (var s = -1, h = 0, a = -1, c = true, f = t3.length - 1, u = 0; f >= n3; --f) if (47 !== (i = t3.charCodeAt(f))) -1 === a && (c = false, a = f + 1), 46 === i ? -1 === s ? s = f : 1 !== u && (u = 1) : -1 !== s && (u = -1);\n      else if (!c) {\n        h = f + 1;\n        break;\n      }\n      return -1 === s || -1 === a || 0 === u || 1 === u && s === a - 1 && s === h + 1 ? -1 !== a && (r3.base = r3.name = 0 === h && o ? t3.slice(1, a) : t3.slice(h, a)) : (0 === h && o ? (r3.name = t3.slice(1, s), r3.base = t3.slice(1, a)) : (r3.name = t3.slice(h, s), r3.base = t3.slice(h, a)), r3.ext = t3.slice(s, a)), h > 0 ? r3.dir = t3.slice(0, h - 1) : o && (r3.dir = \"/\"), r3;\n    }, \"parse\"), sep: \"/\", delimiter: \":\", win32: null, posix: null };\n    n2.posix = n2, t2.exports = n2;\n  } }, e = {};\n  function r(n2) {\n    var i = e[n2];\n    if (void 0 !== i) return i.exports;\n    var o = e[n2] = { exports: {} };\n    return t[n2](o, o.exports, r), o.exports;\n  }\n  __name(r, \"r\");\n  r.d = (t2, e2) => {\n    for (var n2 in e2) r.o(e2, n2) && !r.o(t2, n2) && Object.defineProperty(t2, n2, { enumerable: true, get: e2[n2] });\n  }, r.o = (t2, e2) => Object.prototype.hasOwnProperty.call(t2, e2), r.r = (t2) => {\n    \"undefined\" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(t2, Symbol.toStringTag, { value: \"Module\" }), Object.defineProperty(t2, \"__esModule\", { value: true });\n  };\n  var n = {};\n  (() => {\n    let t2;\n    if (r.r(n), r.d(n, { URI: /* @__PURE__ */ __name(() => f, \"URI\"), Utils: /* @__PURE__ */ __name(() => P, \"Utils\") }), \"object\" == typeof process) t2 = \"win32\" === process.platform;\n    else if (\"object\" == typeof navigator) {\n      let e3 = navigator.userAgent;\n      t2 = e3.indexOf(\"Windows\") >= 0;\n    }\n    const e2 = /^\\w[\\w\\d+.-]*$/, i = /^\\//, o = /^\\/\\//;\n    function s(t3, r2) {\n      if (!t3.scheme && r2) throw new Error(`[UriError]: Scheme is missing: {scheme: \"\", authority: \"${t3.authority}\", path: \"${t3.path}\", query: \"${t3.query}\", fragment: \"${t3.fragment}\"}`);\n      if (t3.scheme && !e2.test(t3.scheme)) throw new Error(\"[UriError]: Scheme contains illegal characters.\");\n      if (t3.path) {\n        if (t3.authority) {\n          if (!i.test(t3.path)) throw new Error('[UriError]: If a URI contains an authority component, then the path component must either be empty or begin with a slash (\"/\") character');\n        } else if (o.test(t3.path)) throw new Error('[UriError]: If a URI does not contain an authority component, then the path cannot begin with two slash characters (\"//\")');\n      }\n    }\n    __name(s, \"s\");\n    const h = \"\", a = \"/\", c = /^(([^:/?#]+?):)?(\\/\\/([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?/;\n    class f {\n      static {\n        __name(this, \"f\");\n      }\n      static isUri(t3) {\n        return t3 instanceof f || !!t3 && \"string\" == typeof t3.authority && \"string\" == typeof t3.fragment && \"string\" == typeof t3.path && \"string\" == typeof t3.query && \"string\" == typeof t3.scheme && \"string\" == typeof t3.fsPath && \"function\" == typeof t3.with && \"function\" == typeof t3.toString;\n      }\n      scheme;\n      authority;\n      path;\n      query;\n      fragment;\n      constructor(t3, e3, r2, n2, i2, o2 = false) {\n        \"object\" == typeof t3 ? (this.scheme = t3.scheme || h, this.authority = t3.authority || h, this.path = t3.path || h, this.query = t3.query || h, this.fragment = t3.fragment || h) : (this.scheme = /* @__PURE__ */ function(t4, e4) {\n          return t4 || e4 ? t4 : \"file\";\n        }(t3, o2), this.authority = e3 || h, this.path = function(t4, e4) {\n          switch (t4) {\n            case \"https\":\n            case \"http\":\n            case \"file\":\n              e4 ? e4[0] !== a && (e4 = a + e4) : e4 = a;\n          }\n          return e4;\n        }(this.scheme, r2 || h), this.query = n2 || h, this.fragment = i2 || h, s(this, o2));\n      }\n      get fsPath() {\n        return m(this, false);\n      }\n      with(t3) {\n        if (!t3) return this;\n        let { scheme: e3, authority: r2, path: n2, query: i2, fragment: o2 } = t3;\n        return void 0 === e3 ? e3 = this.scheme : null === e3 && (e3 = h), void 0 === r2 ? r2 = this.authority : null === r2 && (r2 = h), void 0 === n2 ? n2 = this.path : null === n2 && (n2 = h), void 0 === i2 ? i2 = this.query : null === i2 && (i2 = h), void 0 === o2 ? o2 = this.fragment : null === o2 && (o2 = h), e3 === this.scheme && r2 === this.authority && n2 === this.path && i2 === this.query && o2 === this.fragment ? this : new l(e3, r2, n2, i2, o2);\n      }\n      static parse(t3, e3 = false) {\n        const r2 = c.exec(t3);\n        return r2 ? new l(r2[2] || h, C(r2[4] || h), C(r2[5] || h), C(r2[7] || h), C(r2[9] || h), e3) : new l(h, h, h, h, h);\n      }\n      static file(e3) {\n        let r2 = h;\n        if (t2 && (e3 = e3.replace(/\\\\/g, a)), e3[0] === a && e3[1] === a) {\n          const t3 = e3.indexOf(a, 2);\n          -1 === t3 ? (r2 = e3.substring(2), e3 = a) : (r2 = e3.substring(2, t3), e3 = e3.substring(t3) || a);\n        }\n        return new l(\"file\", r2, e3, h, h);\n      }\n      static from(t3) {\n        const e3 = new l(t3.scheme, t3.authority, t3.path, t3.query, t3.fragment);\n        return s(e3, true), e3;\n      }\n      toString(t3 = false) {\n        return y(this, t3);\n      }\n      toJSON() {\n        return this;\n      }\n      static revive(t3) {\n        if (t3) {\n          if (t3 instanceof f) return t3;\n          {\n            const e3 = new l(t3);\n            return e3._formatted = t3.external, e3._fsPath = t3._sep === u ? t3.fsPath : null, e3;\n          }\n        }\n        return t3;\n      }\n    }\n    const u = t2 ? 1 : void 0;\n    class l extends f {\n      static {\n        __name(this, \"l\");\n      }\n      _formatted = null;\n      _fsPath = null;\n      get fsPath() {\n        return this._fsPath || (this._fsPath = m(this, false)), this._fsPath;\n      }\n      toString(t3 = false) {\n        return t3 ? y(this, true) : (this._formatted || (this._formatted = y(this, false)), this._formatted);\n      }\n      toJSON() {\n        const t3 = { $mid: 1 };\n        return this._fsPath && (t3.fsPath = this._fsPath, t3._sep = u), this._formatted && (t3.external = this._formatted), this.path && (t3.path = this.path), this.scheme && (t3.scheme = this.scheme), this.authority && (t3.authority = this.authority), this.query && (t3.query = this.query), this.fragment && (t3.fragment = this.fragment), t3;\n      }\n    }\n    const g = { 58: \"%3A\", 47: \"%2F\", 63: \"%3F\", 35: \"%23\", 91: \"%5B\", 93: \"%5D\", 64: \"%40\", 33: \"%21\", 36: \"%24\", 38: \"%26\", 39: \"%27\", 40: \"%28\", 41: \"%29\", 42: \"%2A\", 43: \"%2B\", 44: \"%2C\", 59: \"%3B\", 61: \"%3D\", 32: \"%20\" };\n    function d(t3, e3, r2) {\n      let n2, i2 = -1;\n      for (let o2 = 0; o2 < t3.length; o2++) {\n        const s2 = t3.charCodeAt(o2);\n        if (s2 >= 97 && s2 <= 122 || s2 >= 65 && s2 <= 90 || s2 >= 48 && s2 <= 57 || 45 === s2 || 46 === s2 || 95 === s2 || 126 === s2 || e3 && 47 === s2 || r2 && 91 === s2 || r2 && 93 === s2 || r2 && 58 === s2) -1 !== i2 && (n2 += encodeURIComponent(t3.substring(i2, o2)), i2 = -1), void 0 !== n2 && (n2 += t3.charAt(o2));\n        else {\n          void 0 === n2 && (n2 = t3.substr(0, o2));\n          const e4 = g[s2];\n          void 0 !== e4 ? (-1 !== i2 && (n2 += encodeURIComponent(t3.substring(i2, o2)), i2 = -1), n2 += e4) : -1 === i2 && (i2 = o2);\n        }\n      }\n      return -1 !== i2 && (n2 += encodeURIComponent(t3.substring(i2))), void 0 !== n2 ? n2 : t3;\n    }\n    __name(d, \"d\");\n    function p(t3) {\n      let e3;\n      for (let r2 = 0; r2 < t3.length; r2++) {\n        const n2 = t3.charCodeAt(r2);\n        35 === n2 || 63 === n2 ? (void 0 === e3 && (e3 = t3.substr(0, r2)), e3 += g[n2]) : void 0 !== e3 && (e3 += t3[r2]);\n      }\n      return void 0 !== e3 ? e3 : t3;\n    }\n    __name(p, \"p\");\n    function m(e3, r2) {\n      let n2;\n      return n2 = e3.authority && e3.path.length > 1 && \"file\" === e3.scheme ? `//${e3.authority}${e3.path}` : 47 === e3.path.charCodeAt(0) && (e3.path.charCodeAt(1) >= 65 && e3.path.charCodeAt(1) <= 90 || e3.path.charCodeAt(1) >= 97 && e3.path.charCodeAt(1) <= 122) && 58 === e3.path.charCodeAt(2) ? r2 ? e3.path.substr(1) : e3.path[1].toLowerCase() + e3.path.substr(2) : e3.path, t2 && (n2 = n2.replace(/\\//g, \"\\\\\")), n2;\n    }\n    __name(m, \"m\");\n    function y(t3, e3) {\n      const r2 = e3 ? p : d;\n      let n2 = \"\", { scheme: i2, authority: o2, path: s2, query: h2, fragment: c2 } = t3;\n      if (i2 && (n2 += i2, n2 += \":\"), (o2 || \"file\" === i2) && (n2 += a, n2 += a), o2) {\n        let t4 = o2.indexOf(\"@\");\n        if (-1 !== t4) {\n          const e4 = o2.substr(0, t4);\n          o2 = o2.substr(t4 + 1), t4 = e4.lastIndexOf(\":\"), -1 === t4 ? n2 += r2(e4, false, false) : (n2 += r2(e4.substr(0, t4), false, false), n2 += \":\", n2 += r2(e4.substr(t4 + 1), false, true)), n2 += \"@\";\n        }\n        o2 = o2.toLowerCase(), t4 = o2.lastIndexOf(\":\"), -1 === t4 ? n2 += r2(o2, false, true) : (n2 += r2(o2.substr(0, t4), false, true), n2 += o2.substr(t4));\n      }\n      if (s2) {\n        if (s2.length >= 3 && 47 === s2.charCodeAt(0) && 58 === s2.charCodeAt(2)) {\n          const t4 = s2.charCodeAt(1);\n          t4 >= 65 && t4 <= 90 && (s2 = `/${String.fromCharCode(t4 + 32)}:${s2.substr(3)}`);\n        } else if (s2.length >= 2 && 58 === s2.charCodeAt(1)) {\n          const t4 = s2.charCodeAt(0);\n          t4 >= 65 && t4 <= 90 && (s2 = `${String.fromCharCode(t4 + 32)}:${s2.substr(2)}`);\n        }\n        n2 += r2(s2, true, false);\n      }\n      return h2 && (n2 += \"?\", n2 += r2(h2, false, false)), c2 && (n2 += \"#\", n2 += e3 ? c2 : d(c2, false, false)), n2;\n    }\n    __name(y, \"y\");\n    function v(t3) {\n      try {\n        return decodeURIComponent(t3);\n      } catch {\n        return t3.length > 3 ? t3.substr(0, 3) + v(t3.substr(3)) : t3;\n      }\n    }\n    __name(v, \"v\");\n    const b = /(%[0-9A-Za-z][0-9A-Za-z])+/g;\n    function C(t3) {\n      return t3.match(b) ? t3.replace(b, (t4) => v(t4)) : t3;\n    }\n    __name(C, \"C\");\n    var A = r(470);\n    const w = A.posix || A, x = \"/\";\n    var P;\n    !function(t3) {\n      t3.joinPath = function(t4, ...e3) {\n        return t4.with({ path: w.join(t4.path, ...e3) });\n      }, t3.resolvePath = function(t4, ...e3) {\n        let r2 = t4.path, n2 = false;\n        r2[0] !== x && (r2 = x + r2, n2 = true);\n        let i2 = w.resolve(r2, ...e3);\n        return n2 && i2[0] === x && !t4.authority && (i2 = i2.substring(1)), t4.with({ path: i2 });\n      }, t3.dirname = function(t4) {\n        if (0 === t4.path.length || t4.path === x) return t4;\n        let e3 = w.dirname(t4.path);\n        return 1 === e3.length && 46 === e3.charCodeAt(0) && (e3 = \"\"), t4.with({ path: e3 });\n      }, t3.basename = function(t4) {\n        return w.basename(t4.path);\n      }, t3.extname = function(t4) {\n        return w.extname(t4.path);\n      };\n    }(P || (P = {}));\n  })(), LIB = n;\n})();\nvar { URI: URI2, Utils } = LIB;\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/uri-utils.js\nvar UriUtils;\n(function(UriUtils2) {\n  UriUtils2.basename = Utils.basename;\n  UriUtils2.dirname = Utils.dirname;\n  UriUtils2.extname = Utils.extname;\n  UriUtils2.joinPath = Utils.joinPath;\n  UriUtils2.resolvePath = Utils.resolvePath;\n  function equals(a, b) {\n    return (a === null || a === void 0 ? void 0 : a.toString()) === (b === null || b === void 0 ? void 0 : b.toString());\n  }\n  __name(equals, \"equals\");\n  UriUtils2.equals = equals;\n  function relative(from, to) {\n    const fromPath = typeof from === \"string\" ? from : from.path;\n    const toPath = typeof to === \"string\" ? to : to.path;\n    const fromParts = fromPath.split(\"/\").filter((e) => e.length > 0);\n    const toParts = toPath.split(\"/\").filter((e) => e.length > 0);\n    let i = 0;\n    for (; i < fromParts.length; i++) {\n      if (fromParts[i] !== toParts[i]) {\n        break;\n      }\n    }\n    const backPart = \"../\".repeat(fromParts.length - i);\n    const toPart = toParts.slice(i).join(\"/\");\n    return backPart + toPart;\n  }\n  __name(relative, \"relative\");\n  UriUtils2.relative = relative;\n  function normalize(uri) {\n    return URI2.parse(uri.toString()).toString();\n  }\n  __name(normalize, \"normalize\");\n  UriUtils2.normalize = normalize;\n})(UriUtils || (UriUtils = {}));\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/workspace/documents.js\nvar DocumentState;\n(function(DocumentState2) {\n  DocumentState2[DocumentState2[\"Changed\"] = 0] = \"Changed\";\n  DocumentState2[DocumentState2[\"Parsed\"] = 1] = \"Parsed\";\n  DocumentState2[DocumentState2[\"IndexedContent\"] = 2] = \"IndexedContent\";\n  DocumentState2[DocumentState2[\"ComputedScopes\"] = 3] = \"ComputedScopes\";\n  DocumentState2[DocumentState2[\"Linked\"] = 4] = \"Linked\";\n  DocumentState2[DocumentState2[\"IndexedReferences\"] = 5] = \"IndexedReferences\";\n  DocumentState2[DocumentState2[\"Validated\"] = 6] = \"Validated\";\n})(DocumentState || (DocumentState = {}));\nvar DefaultLangiumDocumentFactory = class {\n  static {\n    __name(this, \"DefaultLangiumDocumentFactory\");\n  }\n  constructor(services) {\n    this.serviceRegistry = services.ServiceRegistry;\n    this.textDocuments = services.workspace.TextDocuments;\n    this.fileSystemProvider = services.workspace.FileSystemProvider;\n  }\n  async fromUri(uri, cancellationToken = cancellation_exports.CancellationToken.None) {\n    const content = await this.fileSystemProvider.readFile(uri);\n    return this.createAsync(uri, content, cancellationToken);\n  }\n  fromTextDocument(textDocument, uri, token) {\n    uri = uri !== null && uri !== void 0 ? uri : URI2.parse(textDocument.uri);\n    if (cancellation_exports.CancellationToken.is(token)) {\n      return this.createAsync(uri, textDocument, token);\n    } else {\n      return this.create(uri, textDocument, token);\n    }\n  }\n  fromString(text, uri, token) {\n    if (cancellation_exports.CancellationToken.is(token)) {\n      return this.createAsync(uri, text, token);\n    } else {\n      return this.create(uri, text, token);\n    }\n  }\n  fromModel(model, uri) {\n    return this.create(uri, { $model: model });\n  }\n  create(uri, content, options) {\n    if (typeof content === \"string\") {\n      const parseResult = this.parse(uri, content, options);\n      return this.createLangiumDocument(parseResult, uri, void 0, content);\n    } else if (\"$model\" in content) {\n      const parseResult = { value: content.$model, parserErrors: [], lexerErrors: [] };\n      return this.createLangiumDocument(parseResult, uri);\n    } else {\n      const parseResult = this.parse(uri, content.getText(), options);\n      return this.createLangiumDocument(parseResult, uri, content);\n    }\n  }\n  async createAsync(uri, content, cancelToken) {\n    if (typeof content === \"string\") {\n      const parseResult = await this.parseAsync(uri, content, cancelToken);\n      return this.createLangiumDocument(parseResult, uri, void 0, content);\n    } else {\n      const parseResult = await this.parseAsync(uri, content.getText(), cancelToken);\n      return this.createLangiumDocument(parseResult, uri, content);\n    }\n  }\n  /**\n   * Create a LangiumDocument from a given parse result.\n   *\n   * A TextDocument is created on demand if it is not provided as argument here. Usually this\n   * should not be necessary because the main purpose of the TextDocument is to convert between\n   * text ranges and offsets, which is done solely in LSP request handling.\n   *\n   * With the introduction of {@link update} below this method is supposed to be mainly called\n   * during workspace initialization and on addition/recognition of new files, while changes in\n   * existing documents are processed via {@link update}.\n   */\n  createLangiumDocument(parseResult, uri, textDocument, text) {\n    let document;\n    if (textDocument) {\n      document = {\n        parseResult,\n        uri,\n        state: DocumentState.Parsed,\n        references: [],\n        textDocument\n      };\n    } else {\n      const textDocumentGetter = this.createTextDocumentGetter(uri, text);\n      document = {\n        parseResult,\n        uri,\n        state: DocumentState.Parsed,\n        references: [],\n        get textDocument() {\n          return textDocumentGetter();\n        }\n      };\n    }\n    parseResult.value.$document = document;\n    return document;\n  }\n  async update(document, cancellationToken) {\n    var _a, _b;\n    const oldText = (_a = document.parseResult.value.$cstNode) === null || _a === void 0 ? void 0 : _a.root.fullText;\n    const textDocument = (_b = this.textDocuments) === null || _b === void 0 ? void 0 : _b.get(document.uri.toString());\n    const text = textDocument ? textDocument.getText() : await this.fileSystemProvider.readFile(document.uri);\n    if (textDocument) {\n      Object.defineProperty(document, \"textDocument\", {\n        value: textDocument\n      });\n    } else {\n      const textDocumentGetter = this.createTextDocumentGetter(document.uri, text);\n      Object.defineProperty(document, \"textDocument\", {\n        get: textDocumentGetter\n      });\n    }\n    if (oldText !== text) {\n      document.parseResult = await this.parseAsync(document.uri, text, cancellationToken);\n      document.parseResult.value.$document = document;\n    }\n    document.state = DocumentState.Parsed;\n    return document;\n  }\n  parse(uri, text, options) {\n    const services = this.serviceRegistry.getServices(uri);\n    return services.parser.LangiumParser.parse(text, options);\n  }\n  parseAsync(uri, text, cancellationToken) {\n    const services = this.serviceRegistry.getServices(uri);\n    return services.parser.AsyncParser.parse(text, cancellationToken);\n  }\n  createTextDocumentGetter(uri, text) {\n    const serviceRegistry = this.serviceRegistry;\n    let textDoc = void 0;\n    return () => {\n      return textDoc !== null && textDoc !== void 0 ? textDoc : textDoc = TextDocument2.create(uri.toString(), serviceRegistry.getServices(uri).LanguageMetaData.languageId, 0, text !== null && text !== void 0 ? text : \"\");\n    };\n  }\n};\nvar DefaultLangiumDocuments = class {\n  static {\n    __name(this, \"DefaultLangiumDocuments\");\n  }\n  constructor(services) {\n    this.documentMap = /* @__PURE__ */ new Map();\n    this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\n    this.serviceRegistry = services.ServiceRegistry;\n  }\n  get all() {\n    return stream(this.documentMap.values());\n  }\n  addDocument(document) {\n    const uriString = document.uri.toString();\n    if (this.documentMap.has(uriString)) {\n      throw new Error(`A document with the URI '${uriString}' is already present.`);\n    }\n    this.documentMap.set(uriString, document);\n  }\n  getDocument(uri) {\n    const uriString = uri.toString();\n    return this.documentMap.get(uriString);\n  }\n  async getOrCreateDocument(uri, cancellationToken) {\n    let document = this.getDocument(uri);\n    if (document) {\n      return document;\n    }\n    document = await this.langiumDocumentFactory.fromUri(uri, cancellationToken);\n    this.addDocument(document);\n    return document;\n  }\n  createDocument(uri, text, cancellationToken) {\n    if (cancellationToken) {\n      return this.langiumDocumentFactory.fromString(text, uri, cancellationToken).then((document) => {\n        this.addDocument(document);\n        return document;\n      });\n    } else {\n      const document = this.langiumDocumentFactory.fromString(text, uri);\n      this.addDocument(document);\n      return document;\n    }\n  }\n  hasDocument(uri) {\n    return this.documentMap.has(uri.toString());\n  }\n  invalidateDocument(uri) {\n    const uriString = uri.toString();\n    const langiumDoc = this.documentMap.get(uriString);\n    if (langiumDoc) {\n      const linker = this.serviceRegistry.getServices(uri).references.Linker;\n      linker.unlink(langiumDoc);\n      langiumDoc.state = DocumentState.Changed;\n      langiumDoc.precomputedScopes = void 0;\n      langiumDoc.diagnostics = void 0;\n    }\n    return langiumDoc;\n  }\n  deleteDocument(uri) {\n    const uriString = uri.toString();\n    const langiumDoc = this.documentMap.get(uriString);\n    if (langiumDoc) {\n      langiumDoc.state = DocumentState.Changed;\n      this.documentMap.delete(uriString);\n    }\n    return langiumDoc;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/references/linker.js\nvar ref_resolving = Symbol(\"ref_resolving\");\nvar DefaultLinker = class {\n  static {\n    __name(this, \"DefaultLinker\");\n  }\n  constructor(services) {\n    this.reflection = services.shared.AstReflection;\n    this.langiumDocuments = () => services.shared.workspace.LangiumDocuments;\n    this.scopeProvider = services.references.ScopeProvider;\n    this.astNodeLocator = services.workspace.AstNodeLocator;\n  }\n  async link(document, cancelToken = cancellation_exports.CancellationToken.None) {\n    for (const node of streamAst(document.parseResult.value)) {\n      await interruptAndCheck(cancelToken);\n      streamReferences(node).forEach((ref) => this.doLink(ref, document));\n    }\n  }\n  doLink(refInfo, document) {\n    var _a;\n    const ref = refInfo.reference;\n    if (ref._ref === void 0) {\n      ref._ref = ref_resolving;\n      try {\n        const description = this.getCandidate(refInfo);\n        if (isLinkingError(description)) {\n          ref._ref = description;\n        } else {\n          ref._nodeDescription = description;\n          if (this.langiumDocuments().hasDocument(description.documentUri)) {\n            const linkedNode = this.loadAstNode(description);\n            ref._ref = linkedNode !== null && linkedNode !== void 0 ? linkedNode : this.createLinkingError(refInfo, description);\n          } else {\n            ref._ref = void 0;\n          }\n        }\n      } catch (err) {\n        console.error(`An error occurred while resolving reference to '${ref.$refText}':`, err);\n        const errorMessage = (_a = err.message) !== null && _a !== void 0 ? _a : String(err);\n        ref._ref = Object.assign(Object.assign({}, refInfo), { message: `An error occurred while resolving reference to '${ref.$refText}': ${errorMessage}` });\n      }\n      document.references.push(ref);\n    }\n  }\n  unlink(document) {\n    for (const ref of document.references) {\n      delete ref._ref;\n      delete ref._nodeDescription;\n    }\n    document.references = [];\n  }\n  getCandidate(refInfo) {\n    const scope = this.scopeProvider.getScope(refInfo);\n    const description = scope.getElement(refInfo.reference.$refText);\n    return description !== null && description !== void 0 ? description : this.createLinkingError(refInfo);\n  }\n  buildReference(node, property, refNode, refText) {\n    const linker = this;\n    const reference = {\n      $refNode: refNode,\n      $refText: refText,\n      get ref() {\n        var _a;\n        if (isAstNode(this._ref)) {\n          return this._ref;\n        } else if (isAstNodeDescription(this._nodeDescription)) {\n          const linkedNode = linker.loadAstNode(this._nodeDescription);\n          this._ref = linkedNode !== null && linkedNode !== void 0 ? linkedNode : linker.createLinkingError({ reference, container: node, property }, this._nodeDescription);\n        } else if (this._ref === void 0) {\n          this._ref = ref_resolving;\n          const document = findRootNode(node).$document;\n          const refData = linker.getLinkedNode({ reference, container: node, property });\n          if (refData.error && document && document.state < DocumentState.ComputedScopes) {\n            return this._ref = void 0;\n          }\n          this._ref = (_a = refData.node) !== null && _a !== void 0 ? _a : refData.error;\n          this._nodeDescription = refData.descr;\n          document === null || document === void 0 ? void 0 : document.references.push(this);\n        } else if (this._ref === ref_resolving) {\n          throw new Error(`Cyclic reference resolution detected: ${linker.astNodeLocator.getAstNodePath(node)}/${property} (symbol '${refText}')`);\n        }\n        return isAstNode(this._ref) ? this._ref : void 0;\n      },\n      get $nodeDescription() {\n        return this._nodeDescription;\n      },\n      get error() {\n        return isLinkingError(this._ref) ? this._ref : void 0;\n      }\n    };\n    return reference;\n  }\n  getLinkedNode(refInfo) {\n    var _a;\n    try {\n      const description = this.getCandidate(refInfo);\n      if (isLinkingError(description)) {\n        return { error: description };\n      }\n      const linkedNode = this.loadAstNode(description);\n      if (linkedNode) {\n        return { node: linkedNode, descr: description };\n      } else {\n        return {\n          descr: description,\n          error: this.createLinkingError(refInfo, description)\n        };\n      }\n    } catch (err) {\n      console.error(`An error occurred while resolving reference to '${refInfo.reference.$refText}':`, err);\n      const errorMessage = (_a = err.message) !== null && _a !== void 0 ? _a : String(err);\n      return {\n        error: Object.assign(Object.assign({}, refInfo), { message: `An error occurred while resolving reference to '${refInfo.reference.$refText}': ${errorMessage}` })\n      };\n    }\n  }\n  loadAstNode(nodeDescription) {\n    if (nodeDescription.node) {\n      return nodeDescription.node;\n    }\n    const doc = this.langiumDocuments().getDocument(nodeDescription.documentUri);\n    if (!doc) {\n      return void 0;\n    }\n    return this.astNodeLocator.getAstNode(doc.parseResult.value, nodeDescription.path);\n  }\n  createLinkingError(refInfo, targetDescription) {\n    const document = findRootNode(refInfo.container).$document;\n    if (document && document.state < DocumentState.ComputedScopes) {\n      console.warn(`Attempted reference resolution before document reached ComputedScopes state (${document.uri}).`);\n    }\n    const referenceType = this.reflection.getReferenceType(refInfo);\n    return Object.assign(Object.assign({}, refInfo), { message: `Could not resolve reference to ${referenceType} named '${refInfo.reference.$refText}'.`, targetDescription });\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/references/name-provider.js\nfunction isNamed(node) {\n  return typeof node.name === \"string\";\n}\n__name(isNamed, \"isNamed\");\nvar DefaultNameProvider = class {\n  static {\n    __name(this, \"DefaultNameProvider\");\n  }\n  getName(node) {\n    if (isNamed(node)) {\n      return node.name;\n    }\n    return void 0;\n  }\n  getNameNode(node) {\n    return findNodeForProperty(node.$cstNode, \"name\");\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/references/references.js\nvar DefaultReferences = class {\n  static {\n    __name(this, \"DefaultReferences\");\n  }\n  constructor(services) {\n    this.nameProvider = services.references.NameProvider;\n    this.index = services.shared.workspace.IndexManager;\n    this.nodeLocator = services.workspace.AstNodeLocator;\n  }\n  findDeclaration(sourceCstNode) {\n    if (sourceCstNode) {\n      const assignment = findAssignment(sourceCstNode);\n      const nodeElem = sourceCstNode.astNode;\n      if (assignment && nodeElem) {\n        const reference = nodeElem[assignment.feature];\n        if (isReference(reference)) {\n          return reference.ref;\n        } else if (Array.isArray(reference)) {\n          for (const ref of reference) {\n            if (isReference(ref) && ref.$refNode && ref.$refNode.offset <= sourceCstNode.offset && ref.$refNode.end >= sourceCstNode.end) {\n              return ref.ref;\n            }\n          }\n        }\n      }\n      if (nodeElem) {\n        const nameNode = this.nameProvider.getNameNode(nodeElem);\n        if (nameNode && (nameNode === sourceCstNode || isChildNode(sourceCstNode, nameNode))) {\n          return nodeElem;\n        }\n      }\n    }\n    return void 0;\n  }\n  findDeclarationNode(sourceCstNode) {\n    const astNode = this.findDeclaration(sourceCstNode);\n    if (astNode === null || astNode === void 0 ? void 0 : astNode.$cstNode) {\n      const targetNode = this.nameProvider.getNameNode(astNode);\n      return targetNode !== null && targetNode !== void 0 ? targetNode : astNode.$cstNode;\n    }\n    return void 0;\n  }\n  findReferences(targetNode, options) {\n    const refs = [];\n    if (options.includeDeclaration) {\n      const ref = this.getReferenceToSelf(targetNode);\n      if (ref) {\n        refs.push(ref);\n      }\n    }\n    let indexReferences = this.index.findAllReferences(targetNode, this.nodeLocator.getAstNodePath(targetNode));\n    if (options.documentUri) {\n      indexReferences = indexReferences.filter((ref) => UriUtils.equals(ref.sourceUri, options.documentUri));\n    }\n    refs.push(...indexReferences);\n    return stream(refs);\n  }\n  getReferenceToSelf(targetNode) {\n    const nameNode = this.nameProvider.getNameNode(targetNode);\n    if (nameNode) {\n      const doc = getDocument(targetNode);\n      const path = this.nodeLocator.getAstNodePath(targetNode);\n      return {\n        sourceUri: doc.uri,\n        sourcePath: path,\n        targetUri: doc.uri,\n        targetPath: path,\n        segment: toDocumentSegment(nameNode),\n        local: true\n      };\n    }\n    return void 0;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/collections.js\nvar MultiMap = class {\n  static {\n    __name(this, \"MultiMap\");\n  }\n  constructor(elements) {\n    this.map = /* @__PURE__ */ new Map();\n    if (elements) {\n      for (const [key, value] of elements) {\n        this.add(key, value);\n      }\n    }\n  }\n  /**\n   * The total number of values in the multimap.\n   */\n  get size() {\n    return Reduction.sum(stream(this.map.values()).map((a) => a.length));\n  }\n  /**\n   * Clear all entries in the multimap.\n   */\n  clear() {\n    this.map.clear();\n  }\n  /**\n   * Operates differently depending on whether a `value` is given:\n   *  * With a value, this method deletes the specific key / value pair from the multimap.\n   *  * Without a value, all values associated with the given key are deleted.\n   *\n   * @returns `true` if a value existed and has been removed, or `false` if the specified\n   *     key / value does not exist.\n   */\n  delete(key, value) {\n    if (value === void 0) {\n      return this.map.delete(key);\n    } else {\n      const values = this.map.get(key);\n      if (values) {\n        const index = values.indexOf(value);\n        if (index >= 0) {\n          if (values.length === 1) {\n            this.map.delete(key);\n          } else {\n            values.splice(index, 1);\n          }\n          return true;\n        }\n      }\n      return false;\n    }\n  }\n  /**\n   * Returns an array of all values associated with the given key. If no value exists,\n   * an empty array is returned.\n   *\n   * _Note:_ The returned array is assumed not to be modified. Use the `set` method to add a\n   * value and `delete` to remove a value from the multimap.\n   */\n  get(key) {\n    var _a;\n    return (_a = this.map.get(key)) !== null && _a !== void 0 ? _a : [];\n  }\n  /**\n   * Operates differently depending on whether a `value` is given:\n   *  * With a value, this method returns `true` if the specific key / value pair is present in the multimap.\n   *  * Without a value, this method returns `true` if the given key is present in the multimap.\n   */\n  has(key, value) {\n    if (value === void 0) {\n      return this.map.has(key);\n    } else {\n      const values = this.map.get(key);\n      if (values) {\n        return values.indexOf(value) >= 0;\n      }\n      return false;\n    }\n  }\n  /**\n   * Add the given key / value pair to the multimap.\n   */\n  add(key, value) {\n    if (this.map.has(key)) {\n      this.map.get(key).push(value);\n    } else {\n      this.map.set(key, [value]);\n    }\n    return this;\n  }\n  /**\n   * Add the given set of key / value pairs to the multimap.\n   */\n  addAll(key, values) {\n    if (this.map.has(key)) {\n      this.map.get(key).push(...values);\n    } else {\n      this.map.set(key, Array.from(values));\n    }\n    return this;\n  }\n  /**\n   * Invokes the given callback function for every key / value pair in the multimap.\n   */\n  forEach(callbackfn) {\n    this.map.forEach((array, key) => array.forEach((value) => callbackfn(value, key, this)));\n  }\n  /**\n   * Returns an iterator of key, value pairs for every entry in the map.\n   */\n  [Symbol.iterator]() {\n    return this.entries().iterator();\n  }\n  /**\n   * Returns a stream of key, value pairs for every entry in the map.\n   */\n  entries() {\n    return stream(this.map.entries()).flatMap(([key, array]) => array.map((value) => [key, value]));\n  }\n  /**\n   * Returns a stream of keys in the map.\n   */\n  keys() {\n    return stream(this.map.keys());\n  }\n  /**\n   * Returns a stream of values in the map.\n   */\n  values() {\n    return stream(this.map.values()).flat();\n  }\n  /**\n   * Returns a stream of key, value set pairs for every key in the map.\n   */\n  entriesGroupedByKey() {\n    return stream(this.map.entries());\n  }\n};\nvar BiMap = class {\n  static {\n    __name(this, \"BiMap\");\n  }\n  get size() {\n    return this.map.size;\n  }\n  constructor(elements) {\n    this.map = /* @__PURE__ */ new Map();\n    this.inverse = /* @__PURE__ */ new Map();\n    if (elements) {\n      for (const [key, value] of elements) {\n        this.set(key, value);\n      }\n    }\n  }\n  clear() {\n    this.map.clear();\n    this.inverse.clear();\n  }\n  set(key, value) {\n    this.map.set(key, value);\n    this.inverse.set(value, key);\n    return this;\n  }\n  get(key) {\n    return this.map.get(key);\n  }\n  getKey(value) {\n    return this.inverse.get(value);\n  }\n  delete(key) {\n    const value = this.map.get(key);\n    if (value !== void 0) {\n      this.map.delete(key);\n      this.inverse.delete(value);\n      return true;\n    }\n    return false;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/references/scope-computation.js\nvar DefaultScopeComputation = class {\n  static {\n    __name(this, \"DefaultScopeComputation\");\n  }\n  constructor(services) {\n    this.nameProvider = services.references.NameProvider;\n    this.descriptions = services.workspace.AstNodeDescriptionProvider;\n  }\n  async computeExports(document, cancelToken = cancellation_exports.CancellationToken.None) {\n    return this.computeExportsForNode(document.parseResult.value, document, void 0, cancelToken);\n  }\n  /**\n   * Creates {@link AstNodeDescription AstNodeDescriptions} for the given {@link AstNode parentNode} and its children.\n   * The list of children to be considered is determined by the function parameter {@link children}.\n   * By default only the direct children of {@link parentNode} are visited, nested nodes are not exported.\n   *\n   * @param parentNode AST node to be exported, i.e., of which an {@link AstNodeDescription} shall be added to the returned list.\n   * @param document The document containing the AST node to be exported.\n   * @param children A function called with {@link parentNode} as single argument and returning an {@link Iterable} supplying the children to be visited, which must be directly or transitively contained in {@link parentNode}.\n   * @param cancelToken Indicates when to cancel the current operation.\n   * @throws `OperationCancelled` if a user action occurs during execution.\n   * @returns A list of {@link AstNodeDescription AstNodeDescriptions} to be published to index.\n   */\n  async computeExportsForNode(parentNode, document, children = streamContents, cancelToken = cancellation_exports.CancellationToken.None) {\n    const exports = [];\n    this.exportNode(parentNode, exports, document);\n    for (const node of children(parentNode)) {\n      await interruptAndCheck(cancelToken);\n      this.exportNode(node, exports, document);\n    }\n    return exports;\n  }\n  /**\n   * Add a single node to the list of exports if it has a name. Override this method to change how\n   * symbols are exported, e.g. by modifying their exported name.\n   */\n  exportNode(node, exports, document) {\n    const name = this.nameProvider.getName(node);\n    if (name) {\n      exports.push(this.descriptions.createDescription(node, name, document));\n    }\n  }\n  async computeLocalScopes(document, cancelToken = cancellation_exports.CancellationToken.None) {\n    const rootNode = document.parseResult.value;\n    const scopes = new MultiMap();\n    for (const node of streamAllContents(rootNode)) {\n      await interruptAndCheck(cancelToken);\n      this.processNode(node, document, scopes);\n    }\n    return scopes;\n  }\n  /**\n   * Process a single node during scopes computation. The default implementation makes the node visible\n   * in the subtree of its container (if the node has a name). Override this method to change this,\n   * e.g. by increasing the visibility to a higher level in the AST.\n   */\n  processNode(node, document, scopes) {\n    const container = node.$container;\n    if (container) {\n      const name = this.nameProvider.getName(node);\n      if (name) {\n        scopes.add(container, this.descriptions.createDescription(node, name, document));\n      }\n    }\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/references/scope.js\nvar StreamScope = class {\n  static {\n    __name(this, \"StreamScope\");\n  }\n  constructor(elements, outerScope, options) {\n    var _a;\n    this.elements = elements;\n    this.outerScope = outerScope;\n    this.caseInsensitive = (_a = options === null || options === void 0 ? void 0 : options.caseInsensitive) !== null && _a !== void 0 ? _a : false;\n  }\n  getAllElements() {\n    if (this.outerScope) {\n      return this.elements.concat(this.outerScope.getAllElements());\n    } else {\n      return this.elements;\n    }\n  }\n  getElement(name) {\n    const local = this.caseInsensitive ? this.elements.find((e) => e.name.toLowerCase() === name.toLowerCase()) : this.elements.find((e) => e.name === name);\n    if (local) {\n      return local;\n    }\n    if (this.outerScope) {\n      return this.outerScope.getElement(name);\n    }\n    return void 0;\n  }\n};\nvar MapScope = class {\n  static {\n    __name(this, \"MapScope\");\n  }\n  constructor(elements, outerScope, options) {\n    var _a;\n    this.elements = /* @__PURE__ */ new Map();\n    this.caseInsensitive = (_a = options === null || options === void 0 ? void 0 : options.caseInsensitive) !== null && _a !== void 0 ? _a : false;\n    for (const element of elements) {\n      const name = this.caseInsensitive ? element.name.toLowerCase() : element.name;\n      this.elements.set(name, element);\n    }\n    this.outerScope = outerScope;\n  }\n  getElement(name) {\n    const localName = this.caseInsensitive ? name.toLowerCase() : name;\n    const local = this.elements.get(localName);\n    if (local) {\n      return local;\n    }\n    if (this.outerScope) {\n      return this.outerScope.getElement(name);\n    }\n    return void 0;\n  }\n  getAllElements() {\n    let elementStream = stream(this.elements.values());\n    if (this.outerScope) {\n      elementStream = elementStream.concat(this.outerScope.getAllElements());\n    }\n    return elementStream;\n  }\n};\nvar EMPTY_SCOPE = {\n  getElement() {\n    return void 0;\n  },\n  getAllElements() {\n    return EMPTY_STREAM;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/caching.js\nvar DisposableCache = class {\n  static {\n    __name(this, \"DisposableCache\");\n  }\n  constructor() {\n    this.toDispose = [];\n    this.isDisposed = false;\n  }\n  onDispose(disposable) {\n    this.toDispose.push(disposable);\n  }\n  dispose() {\n    this.throwIfDisposed();\n    this.clear();\n    this.isDisposed = true;\n    this.toDispose.forEach((disposable) => disposable.dispose());\n  }\n  throwIfDisposed() {\n    if (this.isDisposed) {\n      throw new Error(\"This cache has already been disposed\");\n    }\n  }\n};\nvar SimpleCache = class extends DisposableCache {\n  static {\n    __name(this, \"SimpleCache\");\n  }\n  constructor() {\n    super(...arguments);\n    this.cache = /* @__PURE__ */ new Map();\n  }\n  has(key) {\n    this.throwIfDisposed();\n    return this.cache.has(key);\n  }\n  set(key, value) {\n    this.throwIfDisposed();\n    this.cache.set(key, value);\n  }\n  get(key, provider) {\n    this.throwIfDisposed();\n    if (this.cache.has(key)) {\n      return this.cache.get(key);\n    } else if (provider) {\n      const value = provider();\n      this.cache.set(key, value);\n      return value;\n    } else {\n      return void 0;\n    }\n  }\n  delete(key) {\n    this.throwIfDisposed();\n    return this.cache.delete(key);\n  }\n  clear() {\n    this.throwIfDisposed();\n    this.cache.clear();\n  }\n};\nvar ContextCache = class extends DisposableCache {\n  static {\n    __name(this, \"ContextCache\");\n  }\n  constructor(converter) {\n    super();\n    this.cache = /* @__PURE__ */ new Map();\n    this.converter = converter !== null && converter !== void 0 ? converter : (value) => value;\n  }\n  has(contextKey, key) {\n    this.throwIfDisposed();\n    return this.cacheForContext(contextKey).has(key);\n  }\n  set(contextKey, key, value) {\n    this.throwIfDisposed();\n    this.cacheForContext(contextKey).set(key, value);\n  }\n  get(contextKey, key, provider) {\n    this.throwIfDisposed();\n    const contextCache = this.cacheForContext(contextKey);\n    if (contextCache.has(key)) {\n      return contextCache.get(key);\n    } else if (provider) {\n      const value = provider();\n      contextCache.set(key, value);\n      return value;\n    } else {\n      return void 0;\n    }\n  }\n  delete(contextKey, key) {\n    this.throwIfDisposed();\n    return this.cacheForContext(contextKey).delete(key);\n  }\n  clear(contextKey) {\n    this.throwIfDisposed();\n    if (contextKey) {\n      const mapKey = this.converter(contextKey);\n      this.cache.delete(mapKey);\n    } else {\n      this.cache.clear();\n    }\n  }\n  cacheForContext(contextKey) {\n    const mapKey = this.converter(contextKey);\n    let documentCache = this.cache.get(mapKey);\n    if (!documentCache) {\n      documentCache = /* @__PURE__ */ new Map();\n      this.cache.set(mapKey, documentCache);\n    }\n    return documentCache;\n  }\n};\nvar DocumentCache = class extends ContextCache {\n  static {\n    __name(this, \"DocumentCache\");\n  }\n  /**\n   * Creates a new document cache.\n   *\n   * @param sharedServices Service container instance to hook into document lifecycle events.\n   * @param state Optional document state on which the cache should evict.\n   * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\n   * *Deleted* documents are considered in both cases.\n   *\n   * Providing a state here will use `DocumentBuilder#onDocumentPhase` instead,\n   * which triggers on all documents that have been affected by this change, assuming that the\n   * state is `DocumentState.Linked` or a later state.\n   */\n  constructor(sharedServices, state) {\n    super((uri) => uri.toString());\n    if (state) {\n      this.toDispose.push(sharedServices.workspace.DocumentBuilder.onDocumentPhase(state, (document) => {\n        this.clear(document.uri.toString());\n      }));\n      this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\n        for (const uri of deleted) {\n          this.clear(uri);\n        }\n      }));\n    } else {\n      this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((changed, deleted) => {\n        const allUris = changed.concat(deleted);\n        for (const uri of allUris) {\n          this.clear(uri);\n        }\n      }));\n    }\n  }\n};\nvar WorkspaceCache = class extends SimpleCache {\n  static {\n    __name(this, \"WorkspaceCache\");\n  }\n  /**\n   * Creates a new workspace cache.\n   *\n   * @param sharedServices Service container instance to hook into document lifecycle events.\n   * @param state Optional document state on which the cache should evict.\n   * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\n   * *Deleted* documents are considered in both cases.\n   */\n  constructor(sharedServices, state) {\n    super();\n    if (state) {\n      this.toDispose.push(sharedServices.workspace.DocumentBuilder.onBuildPhase(state, () => {\n        this.clear();\n      }));\n      this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\n        if (deleted.length > 0) {\n          this.clear();\n        }\n      }));\n    } else {\n      this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate(() => {\n        this.clear();\n      }));\n    }\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/references/scope-provider.js\nvar DefaultScopeProvider = class {\n  static {\n    __name(this, \"DefaultScopeProvider\");\n  }\n  constructor(services) {\n    this.reflection = services.shared.AstReflection;\n    this.nameProvider = services.references.NameProvider;\n    this.descriptions = services.workspace.AstNodeDescriptionProvider;\n    this.indexManager = services.shared.workspace.IndexManager;\n    this.globalScopeCache = new WorkspaceCache(services.shared);\n  }\n  getScope(context) {\n    const scopes = [];\n    const referenceType = this.reflection.getReferenceType(context);\n    const precomputed = getDocument(context.container).precomputedScopes;\n    if (precomputed) {\n      let currentNode = context.container;\n      do {\n        const allDescriptions = precomputed.get(currentNode);\n        if (allDescriptions.length > 0) {\n          scopes.push(stream(allDescriptions).filter((desc) => this.reflection.isSubtype(desc.type, referenceType)));\n        }\n        currentNode = currentNode.$container;\n      } while (currentNode);\n    }\n    let result = this.getGlobalScope(referenceType, context);\n    for (let i = scopes.length - 1; i >= 0; i--) {\n      result = this.createScope(scopes[i], result);\n    }\n    return result;\n  }\n  /**\n   * Create a scope for the given collection of AST node descriptions.\n   */\n  createScope(elements, outerScope, options) {\n    return new StreamScope(stream(elements), outerScope, options);\n  }\n  /**\n   * Create a scope for the given collection of AST nodes, which need to be transformed into respective\n   * descriptions first. This is done using the `NameProvider` and `AstNodeDescriptionProvider` services.\n   */\n  createScopeForNodes(elements, outerScope, options) {\n    const s = stream(elements).map((e) => {\n      const name = this.nameProvider.getName(e);\n      if (name) {\n        return this.descriptions.createDescription(e, name);\n      }\n      return void 0;\n    }).nonNullable();\n    return new StreamScope(s, outerScope, options);\n  }\n  /**\n   * Create a global scope filtered for the given reference type.\n   */\n  getGlobalScope(referenceType, _context) {\n    return this.globalScopeCache.get(referenceType, () => new MapScope(this.indexManager.allElements(referenceType)));\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/serializer/json-serializer.js\nfunction isAstNodeWithComment(node) {\n  return typeof node.$comment === \"string\";\n}\n__name(isAstNodeWithComment, \"isAstNodeWithComment\");\nfunction isIntermediateReference(obj) {\n  return typeof obj === \"object\" && !!obj && (\"$ref\" in obj || \"$error\" in obj);\n}\n__name(isIntermediateReference, \"isIntermediateReference\");\nvar DefaultJsonSerializer = class {\n  static {\n    __name(this, \"DefaultJsonSerializer\");\n  }\n  constructor(services) {\n    this.ignoreProperties = /* @__PURE__ */ new Set([\"$container\", \"$containerProperty\", \"$containerIndex\", \"$document\", \"$cstNode\"]);\n    this.langiumDocuments = services.shared.workspace.LangiumDocuments;\n    this.astNodeLocator = services.workspace.AstNodeLocator;\n    this.nameProvider = services.references.NameProvider;\n    this.commentProvider = services.documentation.CommentProvider;\n  }\n  serialize(node, options) {\n    const serializeOptions = options !== null && options !== void 0 ? options : {};\n    const specificReplacer = options === null || options === void 0 ? void 0 : options.replacer;\n    const defaultReplacer = /* @__PURE__ */ __name((key, value) => this.replacer(key, value, serializeOptions), \"defaultReplacer\");\n    const replacer = specificReplacer ? (key, value) => specificReplacer(key, value, defaultReplacer) : defaultReplacer;\n    try {\n      this.currentDocument = getDocument(node);\n      return JSON.stringify(node, replacer, options === null || options === void 0 ? void 0 : options.space);\n    } finally {\n      this.currentDocument = void 0;\n    }\n  }\n  deserialize(content, options) {\n    const deserializeOptions = options !== null && options !== void 0 ? options : {};\n    const root = JSON.parse(content);\n    this.linkNode(root, root, deserializeOptions);\n    return root;\n  }\n  replacer(key, value, { refText, sourceText, textRegions, comments, uriConverter }) {\n    var _a, _b, _c, _d;\n    if (this.ignoreProperties.has(key)) {\n      return void 0;\n    } else if (isReference(value)) {\n      const refValue = value.ref;\n      const $refText = refText ? value.$refText : void 0;\n      if (refValue) {\n        const targetDocument = getDocument(refValue);\n        let targetUri = \"\";\n        if (this.currentDocument && this.currentDocument !== targetDocument) {\n          if (uriConverter) {\n            targetUri = uriConverter(targetDocument.uri, value);\n          } else {\n            targetUri = targetDocument.uri.toString();\n          }\n        }\n        const targetPath = this.astNodeLocator.getAstNodePath(refValue);\n        return {\n          $ref: `${targetUri}#${targetPath}`,\n          $refText\n        };\n      } else {\n        return {\n          $error: (_b = (_a = value.error) === null || _a === void 0 ? void 0 : _a.message) !== null && _b !== void 0 ? _b : \"Could not resolve reference\",\n          $refText\n        };\n      }\n    } else if (isAstNode(value)) {\n      let astNode = void 0;\n      if (textRegions) {\n        astNode = this.addAstNodeRegionWithAssignmentsTo(Object.assign({}, value));\n        if ((!key || value.$document) && (astNode === null || astNode === void 0 ? void 0 : astNode.$textRegion)) {\n          astNode.$textRegion.documentURI = (_c = this.currentDocument) === null || _c === void 0 ? void 0 : _c.uri.toString();\n        }\n      }\n      if (sourceText && !key) {\n        astNode !== null && astNode !== void 0 ? astNode : astNode = Object.assign({}, value);\n        astNode.$sourceText = (_d = value.$cstNode) === null || _d === void 0 ? void 0 : _d.text;\n      }\n      if (comments) {\n        astNode !== null && astNode !== void 0 ? astNode : astNode = Object.assign({}, value);\n        const comment = this.commentProvider.getComment(value);\n        if (comment) {\n          astNode.$comment = comment.replace(/\\r/g, \"\");\n        }\n      }\n      return astNode !== null && astNode !== void 0 ? astNode : value;\n    } else {\n      return value;\n    }\n  }\n  addAstNodeRegionWithAssignmentsTo(node) {\n    const createDocumentSegment = /* @__PURE__ */ __name((cstNode) => ({\n      offset: cstNode.offset,\n      end: cstNode.end,\n      length: cstNode.length,\n      range: cstNode.range\n    }), \"createDocumentSegment\");\n    if (node.$cstNode) {\n      const textRegion = node.$textRegion = createDocumentSegment(node.$cstNode);\n      const assignments = textRegion.assignments = {};\n      Object.keys(node).filter((key) => !key.startsWith(\"$\")).forEach((key) => {\n        const propertyAssignments = findNodesForProperty(node.$cstNode, key).map(createDocumentSegment);\n        if (propertyAssignments.length !== 0) {\n          assignments[key] = propertyAssignments;\n        }\n      });\n      return node;\n    }\n    return void 0;\n  }\n  linkNode(node, root, options, container, containerProperty, containerIndex) {\n    for (const [propertyName, item] of Object.entries(node)) {\n      if (Array.isArray(item)) {\n        for (let index = 0; index < item.length; index++) {\n          const element = item[index];\n          if (isIntermediateReference(element)) {\n            item[index] = this.reviveReference(node, propertyName, root, element, options);\n          } else if (isAstNode(element)) {\n            this.linkNode(element, root, options, node, propertyName, index);\n          }\n        }\n      } else if (isIntermediateReference(item)) {\n        node[propertyName] = this.reviveReference(node, propertyName, root, item, options);\n      } else if (isAstNode(item)) {\n        this.linkNode(item, root, options, node, propertyName);\n      }\n    }\n    const mutable = node;\n    mutable.$container = container;\n    mutable.$containerProperty = containerProperty;\n    mutable.$containerIndex = containerIndex;\n  }\n  reviveReference(container, property, root, reference, options) {\n    let refText = reference.$refText;\n    let error = reference.$error;\n    if (reference.$ref) {\n      const ref = this.getRefNode(root, reference.$ref, options.uriConverter);\n      if (isAstNode(ref)) {\n        if (!refText) {\n          refText = this.nameProvider.getName(ref);\n        }\n        return {\n          $refText: refText !== null && refText !== void 0 ? refText : \"\",\n          ref\n        };\n      } else {\n        error = ref;\n      }\n    }\n    if (error) {\n      const ref = {\n        $refText: refText !== null && refText !== void 0 ? refText : \"\"\n      };\n      ref.error = {\n        container,\n        property,\n        message: error,\n        reference: ref\n      };\n      return ref;\n    } else {\n      return void 0;\n    }\n  }\n  getRefNode(root, uri, uriConverter) {\n    try {\n      const fragmentIndex = uri.indexOf(\"#\");\n      if (fragmentIndex === 0) {\n        const node2 = this.astNodeLocator.getAstNode(root, uri.substring(1));\n        if (!node2) {\n          return \"Could not resolve path: \" + uri;\n        }\n        return node2;\n      }\n      if (fragmentIndex < 0) {\n        const documentUri2 = uriConverter ? uriConverter(uri) : URI2.parse(uri);\n        const document2 = this.langiumDocuments.getDocument(documentUri2);\n        if (!document2) {\n          return \"Could not find document for URI: \" + uri;\n        }\n        return document2.parseResult.value;\n      }\n      const documentUri = uriConverter ? uriConverter(uri.substring(0, fragmentIndex)) : URI2.parse(uri.substring(0, fragmentIndex));\n      const document = this.langiumDocuments.getDocument(documentUri);\n      if (!document) {\n        return \"Could not find document for URI: \" + uri;\n      }\n      if (fragmentIndex === uri.length - 1) {\n        return document.parseResult.value;\n      }\n      const node = this.astNodeLocator.getAstNode(document.parseResult.value, uri.substring(fragmentIndex + 1));\n      if (!node) {\n        return \"Could not resolve URI: \" + uri;\n      }\n      return node;\n    } catch (err) {\n      return String(err);\n    }\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/service-registry.js\nvar DefaultServiceRegistry = class {\n  static {\n    __name(this, \"DefaultServiceRegistry\");\n  }\n  /**\n   * @deprecated Use the new `fileExtensionMap` (or `languageIdMap`) property instead.\n   */\n  get map() {\n    return this.fileExtensionMap;\n  }\n  constructor(services) {\n    this.languageIdMap = /* @__PURE__ */ new Map();\n    this.fileExtensionMap = /* @__PURE__ */ new Map();\n    this.textDocuments = services === null || services === void 0 ? void 0 : services.workspace.TextDocuments;\n  }\n  register(language) {\n    const data = language.LanguageMetaData;\n    for (const ext of data.fileExtensions) {\n      if (this.fileExtensionMap.has(ext)) {\n        console.warn(`The file extension ${ext} is used by multiple languages. It is now assigned to '${data.languageId}'.`);\n      }\n      this.fileExtensionMap.set(ext, language);\n    }\n    this.languageIdMap.set(data.languageId, language);\n    if (this.languageIdMap.size === 1) {\n      this.singleton = language;\n    } else {\n      this.singleton = void 0;\n    }\n  }\n  getServices(uri) {\n    var _a, _b;\n    if (this.singleton !== void 0) {\n      return this.singleton;\n    }\n    if (this.languageIdMap.size === 0) {\n      throw new Error(\"The service registry is empty. Use `register` to register the services of a language.\");\n    }\n    const languageId = (_b = (_a = this.textDocuments) === null || _a === void 0 ? void 0 : _a.get(uri)) === null || _b === void 0 ? void 0 : _b.languageId;\n    if (languageId !== void 0) {\n      const services2 = this.languageIdMap.get(languageId);\n      if (services2) {\n        return services2;\n      }\n    }\n    const ext = UriUtils.extname(uri);\n    const services = this.fileExtensionMap.get(ext);\n    if (!services) {\n      if (languageId) {\n        throw new Error(`The service registry contains no services for the extension '${ext}' for language '${languageId}'.`);\n      } else {\n        throw new Error(`The service registry contains no services for the extension '${ext}'.`);\n      }\n    }\n    return services;\n  }\n  hasServices(uri) {\n    try {\n      this.getServices(uri);\n      return true;\n    } catch (_a) {\n      return false;\n    }\n  }\n  get all() {\n    return Array.from(this.languageIdMap.values());\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/validation/validation-registry.js\nfunction diagnosticData(code) {\n  return { code };\n}\n__name(diagnosticData, \"diagnosticData\");\nvar ValidationCategory;\n(function(ValidationCategory2) {\n  ValidationCategory2.all = [\"fast\", \"slow\", \"built-in\"];\n})(ValidationCategory || (ValidationCategory = {}));\nvar ValidationRegistry = class {\n  static {\n    __name(this, \"ValidationRegistry\");\n  }\n  constructor(services) {\n    this.entries = new MultiMap();\n    this.entriesBefore = [];\n    this.entriesAfter = [];\n    this.reflection = services.shared.AstReflection;\n  }\n  /**\n   * Register a set of validation checks. Each value in the record can be either a single validation check (i.e. a function)\n   * or an array of validation checks.\n   *\n   * @param checksRecord Set of validation checks to register.\n   * @param category Optional category for the validation checks (defaults to `'fast'`).\n   * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n   */\n  register(checksRecord, thisObj = this, category = \"fast\") {\n    if (category === \"built-in\") {\n      throw new Error(\"The 'built-in' category is reserved for lexer, parser, and linker errors.\");\n    }\n    for (const [type, ch] of Object.entries(checksRecord)) {\n      const callbacks = ch;\n      if (Array.isArray(callbacks)) {\n        for (const check of callbacks) {\n          const entry = {\n            check: this.wrapValidationException(check, thisObj),\n            category\n          };\n          this.addEntry(type, entry);\n        }\n      } else if (typeof callbacks === \"function\") {\n        const entry = {\n          check: this.wrapValidationException(callbacks, thisObj),\n          category\n        };\n        this.addEntry(type, entry);\n      } else {\n        assertUnreachable(callbacks);\n      }\n    }\n  }\n  wrapValidationException(check, thisObj) {\n    return async (node, accept, cancelToken) => {\n      await this.handleException(() => check.call(thisObj, node, accept, cancelToken), \"An error occurred during validation\", accept, node);\n    };\n  }\n  async handleException(functionality, messageContext, accept, node) {\n    try {\n      await functionality();\n    } catch (err) {\n      if (isOperationCancelled(err)) {\n        throw err;\n      }\n      console.error(`${messageContext}:`, err);\n      if (err instanceof Error && err.stack) {\n        console.error(err.stack);\n      }\n      const messageDetails = err instanceof Error ? err.message : String(err);\n      accept(\"error\", `${messageContext}: ${messageDetails}`, { node });\n    }\n  }\n  addEntry(type, entry) {\n    if (type === \"AstNode\") {\n      this.entries.add(\"AstNode\", entry);\n      return;\n    }\n    for (const subtype of this.reflection.getAllSubTypes(type)) {\n      this.entries.add(subtype, entry);\n    }\n  }\n  getChecks(type, categories) {\n    let checks = stream(this.entries.get(type)).concat(this.entries.get(\"AstNode\"));\n    if (categories) {\n      checks = checks.filter((entry) => categories.includes(entry.category));\n    }\n    return checks.map((entry) => entry.check);\n  }\n  /**\n   * Register logic which will be executed once before validating all the nodes of an AST/Langium document.\n   * This helps to prepare or initialize some information which are required or reusable for the following checks on the AstNodes.\n   *\n   * As an example, for validating unique fully-qualified names of nodes in the AST,\n   * here the map for mapping names to nodes could be established.\n   * During the usual checks on the nodes, they are put into this map with their name.\n   *\n   * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\n   * Therefore it is recommended to clear stored information\n   * _before_ validating an AST to validate each AST unaffected from other ASTs\n   * AND _after_ validating the AST to free memory by information which are no longer used.\n   *\n   * @param checkBefore a set-up function which will be called once before actually validating an AST\n   * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n   */\n  registerBeforeDocument(checkBefore, thisObj = this) {\n    this.entriesBefore.push(this.wrapPreparationException(checkBefore, \"An error occurred during set-up of the validation\", thisObj));\n  }\n  /**\n   * Register logic which will be executed once after validating all the nodes of an AST/Langium document.\n   * This helps to finally evaluate information which are collected during the checks on the AstNodes.\n   *\n   * As an example, for validating unique fully-qualified names of nodes in the AST,\n   * here the map with all the collected nodes and their names is checked\n   * and validation hints are created for all nodes with the same name.\n   *\n   * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\n   * Therefore it is recommended to clear stored information\n   * _before_ validating an AST to validate each AST unaffected from other ASTs\n   * AND _after_ validating the AST to free memory by information which are no longer used.\n   *\n   * @param checkBefore a set-up function which will be called once before actually validating an AST\n   * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n   */\n  registerAfterDocument(checkAfter, thisObj = this) {\n    this.entriesAfter.push(this.wrapPreparationException(checkAfter, \"An error occurred during tear-down of the validation\", thisObj));\n  }\n  wrapPreparationException(check, messageContext, thisObj) {\n    return async (rootNode, accept, categories, cancelToken) => {\n      await this.handleException(() => check.call(thisObj, rootNode, accept, categories, cancelToken), messageContext, accept, rootNode);\n    };\n  }\n  get checksBefore() {\n    return this.entriesBefore;\n  }\n  get checksAfter() {\n    return this.entriesAfter;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/validation/document-validator.js\nvar DefaultDocumentValidator = class {\n  static {\n    __name(this, \"DefaultDocumentValidator\");\n  }\n  constructor(services) {\n    this.validationRegistry = services.validation.ValidationRegistry;\n    this.metadata = services.LanguageMetaData;\n  }\n  async validateDocument(document, options = {}, cancelToken = cancellation_exports.CancellationToken.None) {\n    const parseResult = document.parseResult;\n    const diagnostics = [];\n    await interruptAndCheck(cancelToken);\n    if (!options.categories || options.categories.includes(\"built-in\")) {\n      this.processLexingErrors(parseResult, diagnostics, options);\n      if (options.stopAfterLexingErrors && diagnostics.some((d) => {\n        var _a;\n        return ((_a = d.data) === null || _a === void 0 ? void 0 : _a.code) === DocumentValidator.LexingError;\n      })) {\n        return diagnostics;\n      }\n      this.processParsingErrors(parseResult, diagnostics, options);\n      if (options.stopAfterParsingErrors && diagnostics.some((d) => {\n        var _a;\n        return ((_a = d.data) === null || _a === void 0 ? void 0 : _a.code) === DocumentValidator.ParsingError;\n      })) {\n        return diagnostics;\n      }\n      this.processLinkingErrors(document, diagnostics, options);\n      if (options.stopAfterLinkingErrors && diagnostics.some((d) => {\n        var _a;\n        return ((_a = d.data) === null || _a === void 0 ? void 0 : _a.code) === DocumentValidator.LinkingError;\n      })) {\n        return diagnostics;\n      }\n    }\n    try {\n      diagnostics.push(...await this.validateAst(parseResult.value, options, cancelToken));\n    } catch (err) {\n      if (isOperationCancelled(err)) {\n        throw err;\n      }\n      console.error(\"An error occurred during validation:\", err);\n    }\n    await interruptAndCheck(cancelToken);\n    return diagnostics;\n  }\n  processLexingErrors(parseResult, diagnostics, _options) {\n    var _a, _b, _c;\n    const lexerDiagnostics = [...parseResult.lexerErrors, ...(_b = (_a = parseResult.lexerReport) === null || _a === void 0 ? void 0 : _a.diagnostics) !== null && _b !== void 0 ? _b : []];\n    for (const lexerDiagnostic of lexerDiagnostics) {\n      const severity = (_c = lexerDiagnostic.severity) !== null && _c !== void 0 ? _c : \"error\";\n      const diagnostic = {\n        severity: toDiagnosticSeverity(severity),\n        range: {\n          start: {\n            line: lexerDiagnostic.line - 1,\n            character: lexerDiagnostic.column - 1\n          },\n          end: {\n            line: lexerDiagnostic.line - 1,\n            character: lexerDiagnostic.column + lexerDiagnostic.length - 1\n          }\n        },\n        message: lexerDiagnostic.message,\n        data: toDiagnosticData(severity),\n        source: this.getSource()\n      };\n      diagnostics.push(diagnostic);\n    }\n  }\n  processParsingErrors(parseResult, diagnostics, _options) {\n    for (const parserError of parseResult.parserErrors) {\n      let range = void 0;\n      if (isNaN(parserError.token.startOffset)) {\n        if (\"previousToken\" in parserError) {\n          const token = parserError.previousToken;\n          if (!isNaN(token.startOffset)) {\n            const position = { line: token.endLine - 1, character: token.endColumn };\n            range = { start: position, end: position };\n          } else {\n            const position = { line: 0, character: 0 };\n            range = { start: position, end: position };\n          }\n        }\n      } else {\n        range = tokenToRange(parserError.token);\n      }\n      if (range) {\n        const diagnostic = {\n          severity: toDiagnosticSeverity(\"error\"),\n          range,\n          message: parserError.message,\n          data: diagnosticData(DocumentValidator.ParsingError),\n          source: this.getSource()\n        };\n        diagnostics.push(diagnostic);\n      }\n    }\n  }\n  processLinkingErrors(document, diagnostics, _options) {\n    for (const reference of document.references) {\n      const linkingError = reference.error;\n      if (linkingError) {\n        const info = {\n          node: linkingError.container,\n          property: linkingError.property,\n          index: linkingError.index,\n          data: {\n            code: DocumentValidator.LinkingError,\n            containerType: linkingError.container.$type,\n            property: linkingError.property,\n            refText: linkingError.reference.$refText\n          }\n        };\n        diagnostics.push(this.toDiagnostic(\"error\", linkingError.message, info));\n      }\n    }\n  }\n  async validateAst(rootNode, options, cancelToken = cancellation_exports.CancellationToken.None) {\n    const validationItems = [];\n    const acceptor = /* @__PURE__ */ __name((severity, message, info) => {\n      validationItems.push(this.toDiagnostic(severity, message, info));\n    }, \"acceptor\");\n    await this.validateAstBefore(rootNode, options, acceptor, cancelToken);\n    await this.validateAstNodes(rootNode, options, acceptor, cancelToken);\n    await this.validateAstAfter(rootNode, options, acceptor, cancelToken);\n    return validationItems;\n  }\n  async validateAstBefore(rootNode, options, acceptor, cancelToken = cancellation_exports.CancellationToken.None) {\n    var _a;\n    const checksBefore = this.validationRegistry.checksBefore;\n    for (const checkBefore of checksBefore) {\n      await interruptAndCheck(cancelToken);\n      await checkBefore(rootNode, acceptor, (_a = options.categories) !== null && _a !== void 0 ? _a : [], cancelToken);\n    }\n  }\n  async validateAstNodes(rootNode, options, acceptor, cancelToken = cancellation_exports.CancellationToken.None) {\n    await Promise.all(streamAst(rootNode).map(async (node) => {\n      await interruptAndCheck(cancelToken);\n      const checks = this.validationRegistry.getChecks(node.$type, options.categories);\n      for (const check of checks) {\n        await check(node, acceptor, cancelToken);\n      }\n    }));\n  }\n  async validateAstAfter(rootNode, options, acceptor, cancelToken = cancellation_exports.CancellationToken.None) {\n    var _a;\n    const checksAfter = this.validationRegistry.checksAfter;\n    for (const checkAfter of checksAfter) {\n      await interruptAndCheck(cancelToken);\n      await checkAfter(rootNode, acceptor, (_a = options.categories) !== null && _a !== void 0 ? _a : [], cancelToken);\n    }\n  }\n  toDiagnostic(severity, message, info) {\n    return {\n      message,\n      range: getDiagnosticRange(info),\n      severity: toDiagnosticSeverity(severity),\n      code: info.code,\n      codeDescription: info.codeDescription,\n      tags: info.tags,\n      relatedInformation: info.relatedInformation,\n      data: info.data,\n      source: this.getSource()\n    };\n  }\n  getSource() {\n    return this.metadata.languageId;\n  }\n};\nfunction getDiagnosticRange(info) {\n  if (info.range) {\n    return info.range;\n  }\n  let cstNode;\n  if (typeof info.property === \"string\") {\n    cstNode = findNodeForProperty(info.node.$cstNode, info.property, info.index);\n  } else if (typeof info.keyword === \"string\") {\n    cstNode = findNodeForKeyword(info.node.$cstNode, info.keyword, info.index);\n  }\n  cstNode !== null && cstNode !== void 0 ? cstNode : cstNode = info.node.$cstNode;\n  if (!cstNode) {\n    return {\n      start: { line: 0, character: 0 },\n      end: { line: 0, character: 0 }\n    };\n  }\n  return cstNode.range;\n}\n__name(getDiagnosticRange, \"getDiagnosticRange\");\nfunction toDiagnosticSeverity(severity) {\n  switch (severity) {\n    case \"error\":\n      return 1;\n    case \"warning\":\n      return 2;\n    case \"info\":\n      return 3;\n    case \"hint\":\n      return 4;\n    default:\n      throw new Error(\"Invalid diagnostic severity: \" + severity);\n  }\n}\n__name(toDiagnosticSeverity, \"toDiagnosticSeverity\");\nfunction toDiagnosticData(severity) {\n  switch (severity) {\n    case \"error\":\n      return diagnosticData(DocumentValidator.LexingError);\n    case \"warning\":\n      return diagnosticData(DocumentValidator.LexingWarning);\n    case \"info\":\n      return diagnosticData(DocumentValidator.LexingInfo);\n    case \"hint\":\n      return diagnosticData(DocumentValidator.LexingHint);\n    default:\n      throw new Error(\"Invalid diagnostic severity: \" + severity);\n  }\n}\n__name(toDiagnosticData, \"toDiagnosticData\");\nvar DocumentValidator;\n(function(DocumentValidator2) {\n  DocumentValidator2.LexingError = \"lexing-error\";\n  DocumentValidator2.LexingWarning = \"lexing-warning\";\n  DocumentValidator2.LexingInfo = \"lexing-info\";\n  DocumentValidator2.LexingHint = \"lexing-hint\";\n  DocumentValidator2.ParsingError = \"parsing-error\";\n  DocumentValidator2.LinkingError = \"linking-error\";\n})(DocumentValidator || (DocumentValidator = {}));\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/workspace/ast-descriptions.js\nvar DefaultAstNodeDescriptionProvider = class {\n  static {\n    __name(this, \"DefaultAstNodeDescriptionProvider\");\n  }\n  constructor(services) {\n    this.astNodeLocator = services.workspace.AstNodeLocator;\n    this.nameProvider = services.references.NameProvider;\n  }\n  createDescription(node, name, document) {\n    const doc = document !== null && document !== void 0 ? document : getDocument(node);\n    name !== null && name !== void 0 ? name : name = this.nameProvider.getName(node);\n    const path = this.astNodeLocator.getAstNodePath(node);\n    if (!name) {\n      throw new Error(`Node at path ${path} has no name.`);\n    }\n    let nameNodeSegment;\n    const nameSegmentGetter = /* @__PURE__ */ __name(() => {\n      var _a;\n      return nameNodeSegment !== null && nameNodeSegment !== void 0 ? nameNodeSegment : nameNodeSegment = toDocumentSegment((_a = this.nameProvider.getNameNode(node)) !== null && _a !== void 0 ? _a : node.$cstNode);\n    }, \"nameSegmentGetter\");\n    return {\n      node,\n      name,\n      get nameSegment() {\n        return nameSegmentGetter();\n      },\n      selectionSegment: toDocumentSegment(node.$cstNode),\n      type: node.$type,\n      documentUri: doc.uri,\n      path\n    };\n  }\n};\nvar DefaultReferenceDescriptionProvider = class {\n  static {\n    __name(this, \"DefaultReferenceDescriptionProvider\");\n  }\n  constructor(services) {\n    this.nodeLocator = services.workspace.AstNodeLocator;\n  }\n  async createDescriptions(document, cancelToken = cancellation_exports.CancellationToken.None) {\n    const descr = [];\n    const rootNode = document.parseResult.value;\n    for (const astNode of streamAst(rootNode)) {\n      await interruptAndCheck(cancelToken);\n      streamReferences(astNode).filter((refInfo) => !isLinkingError(refInfo)).forEach((refInfo) => {\n        const description = this.createDescription(refInfo);\n        if (description) {\n          descr.push(description);\n        }\n      });\n    }\n    return descr;\n  }\n  createDescription(refInfo) {\n    const targetNodeDescr = refInfo.reference.$nodeDescription;\n    const refCstNode = refInfo.reference.$refNode;\n    if (!targetNodeDescr || !refCstNode) {\n      return void 0;\n    }\n    const docUri = getDocument(refInfo.container).uri;\n    return {\n      sourceUri: docUri,\n      sourcePath: this.nodeLocator.getAstNodePath(refInfo.container),\n      targetUri: targetNodeDescr.documentUri,\n      targetPath: targetNodeDescr.path,\n      segment: toDocumentSegment(refCstNode),\n      local: UriUtils.equals(targetNodeDescr.documentUri, docUri)\n    };\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/workspace/ast-node-locator.js\nvar DefaultAstNodeLocator = class {\n  static {\n    __name(this, \"DefaultAstNodeLocator\");\n  }\n  constructor() {\n    this.segmentSeparator = \"/\";\n    this.indexSeparator = \"@\";\n  }\n  getAstNodePath(node) {\n    if (node.$container) {\n      const containerPath = this.getAstNodePath(node.$container);\n      const newSegment = this.getPathSegment(node);\n      const nodePath = containerPath + this.segmentSeparator + newSegment;\n      return nodePath;\n    }\n    return \"\";\n  }\n  getPathSegment({ $containerProperty, $containerIndex }) {\n    if (!$containerProperty) {\n      throw new Error(\"Missing '$containerProperty' in AST node.\");\n    }\n    if ($containerIndex !== void 0) {\n      return $containerProperty + this.indexSeparator + $containerIndex;\n    }\n    return $containerProperty;\n  }\n  getAstNode(node, path) {\n    const segments = path.split(this.segmentSeparator);\n    return segments.reduce((previousValue, currentValue) => {\n      if (!previousValue || currentValue.length === 0) {\n        return previousValue;\n      }\n      const propertyIndex = currentValue.indexOf(this.indexSeparator);\n      if (propertyIndex > 0) {\n        const property = currentValue.substring(0, propertyIndex);\n        const arrayIndex = parseInt(currentValue.substring(propertyIndex + 1));\n        const array = previousValue[property];\n        return array === null || array === void 0 ? void 0 : array[arrayIndex];\n      }\n      return previousValue[currentValue];\n    }, node);\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/event.js\nvar event_exports = {};\n__reExport(event_exports, __toESM(require_events(), 1));\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/workspace/configuration.js\nvar DefaultConfigurationProvider = class {\n  static {\n    __name(this, \"DefaultConfigurationProvider\");\n  }\n  constructor(services) {\n    this._ready = new Deferred();\n    this.settings = {};\n    this.workspaceConfig = false;\n    this.onConfigurationSectionUpdateEmitter = new event_exports.Emitter();\n    this.serviceRegistry = services.ServiceRegistry;\n  }\n  get ready() {\n    return this._ready.promise;\n  }\n  initialize(params) {\n    var _a, _b;\n    this.workspaceConfig = (_b = (_a = params.capabilities.workspace) === null || _a === void 0 ? void 0 : _a.configuration) !== null && _b !== void 0 ? _b : false;\n  }\n  async initialized(params) {\n    if (this.workspaceConfig) {\n      if (params.register) {\n        const languages = this.serviceRegistry.all;\n        params.register({\n          // Listen to configuration changes for all languages\n          section: languages.map((lang) => this.toSectionName(lang.LanguageMetaData.languageId))\n        });\n      }\n      if (params.fetchConfiguration) {\n        const configToUpdate = this.serviceRegistry.all.map((lang) => ({\n          // Fetch the configuration changes for all languages\n          section: this.toSectionName(lang.LanguageMetaData.languageId)\n        }));\n        const configs = await params.fetchConfiguration(configToUpdate);\n        configToUpdate.forEach((conf, idx) => {\n          this.updateSectionConfiguration(conf.section, configs[idx]);\n        });\n      }\n    }\n    this._ready.resolve();\n  }\n  /**\n   *  Updates the cached configurations using the `change` notification parameters.\n   *\n   * @param change The parameters of a change configuration notification.\n   * `settings` property of the change object could be expressed as `Record<string, Record<string, any>>`\n   */\n  updateConfiguration(change) {\n    if (!change.settings) {\n      return;\n    }\n    Object.keys(change.settings).forEach((section) => {\n      const configuration = change.settings[section];\n      this.updateSectionConfiguration(section, configuration);\n      this.onConfigurationSectionUpdateEmitter.fire({ section, configuration });\n    });\n  }\n  updateSectionConfiguration(section, configuration) {\n    this.settings[section] = configuration;\n  }\n  /**\n  * Returns a configuration value stored for the given language.\n  *\n  * @param language The language id\n  * @param configuration Configuration name\n  */\n  async getConfiguration(language, configuration) {\n    await this.ready;\n    const sectionName = this.toSectionName(language);\n    if (this.settings[sectionName]) {\n      return this.settings[sectionName][configuration];\n    }\n  }\n  toSectionName(languageId) {\n    return `${languageId}`;\n  }\n  get onConfigurationSectionUpdate() {\n    return this.onConfigurationSectionUpdateEmitter.event;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/disposable.js\nvar Disposable;\n(function(Disposable2) {\n  function create(callback) {\n    return {\n      dispose: /* @__PURE__ */ __name(async () => await callback(), \"dispose\")\n    };\n  }\n  __name(create, \"create\");\n  Disposable2.create = create;\n})(Disposable || (Disposable = {}));\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/workspace/document-builder.js\nvar DefaultDocumentBuilder = class {\n  static {\n    __name(this, \"DefaultDocumentBuilder\");\n  }\n  constructor(services) {\n    this.updateBuildOptions = {\n      // Default: run only the built-in validation checks and those in the _fast_ category (includes those without category)\n      validation: {\n        categories: [\"built-in\", \"fast\"]\n      }\n    };\n    this.updateListeners = [];\n    this.buildPhaseListeners = new MultiMap();\n    this.documentPhaseListeners = new MultiMap();\n    this.buildState = /* @__PURE__ */ new Map();\n    this.documentBuildWaiters = /* @__PURE__ */ new Map();\n    this.currentState = DocumentState.Changed;\n    this.langiumDocuments = services.workspace.LangiumDocuments;\n    this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\n    this.textDocuments = services.workspace.TextDocuments;\n    this.indexManager = services.workspace.IndexManager;\n    this.serviceRegistry = services.ServiceRegistry;\n  }\n  async build(documents, options = {}, cancelToken = cancellation_exports.CancellationToken.None) {\n    var _a, _b;\n    for (const document of documents) {\n      const key = document.uri.toString();\n      if (document.state === DocumentState.Validated) {\n        if (typeof options.validation === \"boolean\" && options.validation) {\n          document.state = DocumentState.IndexedReferences;\n          document.diagnostics = void 0;\n          this.buildState.delete(key);\n        } else if (typeof options.validation === \"object\") {\n          const buildState = this.buildState.get(key);\n          const previousCategories = (_a = buildState === null || buildState === void 0 ? void 0 : buildState.result) === null || _a === void 0 ? void 0 : _a.validationChecks;\n          if (previousCategories) {\n            const newCategories = (_b = options.validation.categories) !== null && _b !== void 0 ? _b : ValidationCategory.all;\n            const categories = newCategories.filter((c) => !previousCategories.includes(c));\n            if (categories.length > 0) {\n              this.buildState.set(key, {\n                completed: false,\n                options: {\n                  validation: Object.assign(Object.assign({}, options.validation), { categories })\n                },\n                result: buildState.result\n              });\n              document.state = DocumentState.IndexedReferences;\n            }\n          }\n        }\n      } else {\n        this.buildState.delete(key);\n      }\n    }\n    this.currentState = DocumentState.Changed;\n    await this.emitUpdate(documents.map((e) => e.uri), []);\n    await this.buildDocuments(documents, options, cancelToken);\n  }\n  async update(changed, deleted, cancelToken = cancellation_exports.CancellationToken.None) {\n    this.currentState = DocumentState.Changed;\n    for (const deletedUri of deleted) {\n      this.langiumDocuments.deleteDocument(deletedUri);\n      this.buildState.delete(deletedUri.toString());\n      this.indexManager.remove(deletedUri);\n    }\n    for (const changedUri of changed) {\n      const invalidated = this.langiumDocuments.invalidateDocument(changedUri);\n      if (!invalidated) {\n        const newDocument = this.langiumDocumentFactory.fromModel({ $type: \"INVALID\" }, changedUri);\n        newDocument.state = DocumentState.Changed;\n        this.langiumDocuments.addDocument(newDocument);\n      }\n      this.buildState.delete(changedUri.toString());\n    }\n    const allChangedUris = stream(changed).concat(deleted).map((uri) => uri.toString()).toSet();\n    this.langiumDocuments.all.filter((doc) => !allChangedUris.has(doc.uri.toString()) && this.shouldRelink(doc, allChangedUris)).forEach((doc) => {\n      const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\n      linker.unlink(doc);\n      doc.state = Math.min(doc.state, DocumentState.ComputedScopes);\n      doc.diagnostics = void 0;\n    });\n    await this.emitUpdate(changed, deleted);\n    await interruptAndCheck(cancelToken);\n    const rebuildDocuments = this.sortDocuments(this.langiumDocuments.all.filter((doc) => {\n      var _a;\n      return doc.state < DocumentState.Linked || !((_a = this.buildState.get(doc.uri.toString())) === null || _a === void 0 ? void 0 : _a.completed);\n    }).toArray());\n    await this.buildDocuments(rebuildDocuments, this.updateBuildOptions, cancelToken);\n  }\n  async emitUpdate(changed, deleted) {\n    await Promise.all(this.updateListeners.map((listener) => listener(changed, deleted)));\n  }\n  /**\n   * Sort the given documents by priority. By default, documents with an open text document are prioritized.\n   * This is useful to ensure that visible documents show their diagnostics before all other documents.\n   *\n   * This improves the responsiveness in large workspaces as users usually don't care about diagnostics\n   * in files that are currently not opened in the editor.\n   */\n  sortDocuments(documents) {\n    let left = 0;\n    let right = documents.length - 1;\n    while (left < right) {\n      while (left < documents.length && this.hasTextDocument(documents[left])) {\n        left++;\n      }\n      while (right >= 0 && !this.hasTextDocument(documents[right])) {\n        right--;\n      }\n      if (left < right) {\n        [documents[left], documents[right]] = [documents[right], documents[left]];\n      }\n    }\n    return documents;\n  }\n  hasTextDocument(doc) {\n    var _a;\n    return Boolean((_a = this.textDocuments) === null || _a === void 0 ? void 0 : _a.get(doc.uri));\n  }\n  /**\n   * Check whether the given document should be relinked after changes were found in the given URIs.\n   */\n  shouldRelink(document, changedUris) {\n    if (document.references.some((ref) => ref.error !== void 0)) {\n      return true;\n    }\n    return this.indexManager.isAffected(document, changedUris);\n  }\n  onUpdate(callback) {\n    this.updateListeners.push(callback);\n    return Disposable.create(() => {\n      const index = this.updateListeners.indexOf(callback);\n      if (index >= 0) {\n        this.updateListeners.splice(index, 1);\n      }\n    });\n  }\n  /**\n   * Build the given documents by stepping through all build phases. If a document's state indicates\n   * that a certain build phase is already done, the phase is skipped for that document.\n   *\n   * @param documents The documents to build.\n   * @param options the {@link BuildOptions} to use.\n   * @param cancelToken A cancellation token that can be used to cancel the build.\n   * @returns A promise that resolves when the build is done.\n   */\n  async buildDocuments(documents, options, cancelToken) {\n    this.prepareBuild(documents, options);\n    await this.runCancelable(documents, DocumentState.Parsed, cancelToken, (doc) => this.langiumDocumentFactory.update(doc, cancelToken));\n    await this.runCancelable(documents, DocumentState.IndexedContent, cancelToken, (doc) => this.indexManager.updateContent(doc, cancelToken));\n    await this.runCancelable(documents, DocumentState.ComputedScopes, cancelToken, async (doc) => {\n      const scopeComputation = this.serviceRegistry.getServices(doc.uri).references.ScopeComputation;\n      doc.precomputedScopes = await scopeComputation.computeLocalScopes(doc, cancelToken);\n    });\n    await this.runCancelable(documents, DocumentState.Linked, cancelToken, (doc) => {\n      const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\n      return linker.link(doc, cancelToken);\n    });\n    await this.runCancelable(documents, DocumentState.IndexedReferences, cancelToken, (doc) => this.indexManager.updateReferences(doc, cancelToken));\n    const toBeValidated = documents.filter((doc) => this.shouldValidate(doc));\n    await this.runCancelable(toBeValidated, DocumentState.Validated, cancelToken, (doc) => this.validate(doc, cancelToken));\n    for (const doc of documents) {\n      const state = this.buildState.get(doc.uri.toString());\n      if (state) {\n        state.completed = true;\n      }\n    }\n  }\n  /**\n   * Runs prior to beginning the build process to update the {@link DocumentBuildState} for each document\n   *\n   * @param documents collection of documents to be built\n   * @param options the {@link BuildOptions} to use\n   */\n  prepareBuild(documents, options) {\n    for (const doc of documents) {\n      const key = doc.uri.toString();\n      const state = this.buildState.get(key);\n      if (!state || state.completed) {\n        this.buildState.set(key, {\n          completed: false,\n          options,\n          result: state === null || state === void 0 ? void 0 : state.result\n        });\n      }\n    }\n  }\n  /**\n   * Runs a cancelable operation on a set of documents to bring them to a specified {@link DocumentState}.\n   *\n   * @param documents The array of documents to process.\n   * @param targetState The target {@link DocumentState} to bring the documents to.\n   * @param cancelToken A token that can be used to cancel the operation.\n   * @param callback A function to be called for each document.\n   * @returns A promise that resolves when all documents have been processed or the operation is canceled.\n   * @throws Will throw `OperationCancelled` if the operation is canceled via a `CancellationToken`.\n   */\n  async runCancelable(documents, targetState, cancelToken, callback) {\n    const filtered = documents.filter((doc) => doc.state < targetState);\n    for (const document of filtered) {\n      await interruptAndCheck(cancelToken);\n      await callback(document);\n      document.state = targetState;\n      await this.notifyDocumentPhase(document, targetState, cancelToken);\n    }\n    const targetStateDocs = documents.filter((doc) => doc.state === targetState);\n    await this.notifyBuildPhase(targetStateDocs, targetState, cancelToken);\n    this.currentState = targetState;\n  }\n  onBuildPhase(targetState, callback) {\n    this.buildPhaseListeners.add(targetState, callback);\n    return Disposable.create(() => {\n      this.buildPhaseListeners.delete(targetState, callback);\n    });\n  }\n  onDocumentPhase(targetState, callback) {\n    this.documentPhaseListeners.add(targetState, callback);\n    return Disposable.create(() => {\n      this.documentPhaseListeners.delete(targetState, callback);\n    });\n  }\n  waitUntil(state, uriOrToken, cancelToken) {\n    let uri = void 0;\n    if (uriOrToken && \"path\" in uriOrToken) {\n      uri = uriOrToken;\n    } else {\n      cancelToken = uriOrToken;\n    }\n    cancelToken !== null && cancelToken !== void 0 ? cancelToken : cancelToken = cancellation_exports.CancellationToken.None;\n    if (uri) {\n      const document = this.langiumDocuments.getDocument(uri);\n      if (document && document.state > state) {\n        return Promise.resolve(uri);\n      }\n    }\n    if (this.currentState >= state) {\n      return Promise.resolve(void 0);\n    } else if (cancelToken.isCancellationRequested) {\n      return Promise.reject(OperationCancelled);\n    }\n    return new Promise((resolve, reject) => {\n      const buildDisposable = this.onBuildPhase(state, () => {\n        buildDisposable.dispose();\n        cancelDisposable.dispose();\n        if (uri) {\n          const document = this.langiumDocuments.getDocument(uri);\n          resolve(document === null || document === void 0 ? void 0 : document.uri);\n        } else {\n          resolve(void 0);\n        }\n      });\n      const cancelDisposable = cancelToken.onCancellationRequested(() => {\n        buildDisposable.dispose();\n        cancelDisposable.dispose();\n        reject(OperationCancelled);\n      });\n    });\n  }\n  async notifyDocumentPhase(document, state, cancelToken) {\n    const listeners = this.documentPhaseListeners.get(state);\n    const listenersCopy = listeners.slice();\n    for (const listener of listenersCopy) {\n      try {\n        await listener(document, cancelToken);\n      } catch (err) {\n        if (!isOperationCancelled(err)) {\n          throw err;\n        }\n      }\n    }\n  }\n  async notifyBuildPhase(documents, state, cancelToken) {\n    if (documents.length === 0) {\n      return;\n    }\n    const listeners = this.buildPhaseListeners.get(state);\n    const listenersCopy = listeners.slice();\n    for (const listener of listenersCopy) {\n      await interruptAndCheck(cancelToken);\n      await listener(documents, cancelToken);\n    }\n  }\n  /**\n   * Determine whether the given document should be validated during a build. The default\n   * implementation checks the `validation` property of the build options. If it's set to `true`\n   * or a `ValidationOptions` object, the document is included in the validation phase.\n   */\n  shouldValidate(document) {\n    return Boolean(this.getBuildOptions(document).validation);\n  }\n  /**\n   * Run validation checks on the given document and store the resulting diagnostics in the document.\n   * If the document already contains diagnostics, the new ones are added to the list.\n   */\n  async validate(document, cancelToken) {\n    var _a, _b;\n    const validator = this.serviceRegistry.getServices(document.uri).validation.DocumentValidator;\n    const validationSetting = this.getBuildOptions(document).validation;\n    const options = typeof validationSetting === \"object\" ? validationSetting : void 0;\n    const diagnostics = await validator.validateDocument(document, options, cancelToken);\n    if (document.diagnostics) {\n      document.diagnostics.push(...diagnostics);\n    } else {\n      document.diagnostics = diagnostics;\n    }\n    const state = this.buildState.get(document.uri.toString());\n    if (state) {\n      (_a = state.result) !== null && _a !== void 0 ? _a : state.result = {};\n      const newCategories = (_b = options === null || options === void 0 ? void 0 : options.categories) !== null && _b !== void 0 ? _b : ValidationCategory.all;\n      if (state.result.validationChecks) {\n        state.result.validationChecks.push(...newCategories);\n      } else {\n        state.result.validationChecks = [...newCategories];\n      }\n    }\n  }\n  getBuildOptions(document) {\n    var _a, _b;\n    return (_b = (_a = this.buildState.get(document.uri.toString())) === null || _a === void 0 ? void 0 : _a.options) !== null && _b !== void 0 ? _b : {};\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/workspace/index-manager.js\nvar DefaultIndexManager = class {\n  static {\n    __name(this, \"DefaultIndexManager\");\n  }\n  constructor(services) {\n    this.symbolIndex = /* @__PURE__ */ new Map();\n    this.symbolByTypeIndex = new ContextCache();\n    this.referenceIndex = /* @__PURE__ */ new Map();\n    this.documents = services.workspace.LangiumDocuments;\n    this.serviceRegistry = services.ServiceRegistry;\n    this.astReflection = services.AstReflection;\n  }\n  findAllReferences(targetNode, astNodePath) {\n    const targetDocUri = getDocument(targetNode).uri;\n    const result = [];\n    this.referenceIndex.forEach((docRefs) => {\n      docRefs.forEach((refDescr) => {\n        if (UriUtils.equals(refDescr.targetUri, targetDocUri) && refDescr.targetPath === astNodePath) {\n          result.push(refDescr);\n        }\n      });\n    });\n    return stream(result);\n  }\n  allElements(nodeType, uris) {\n    let documentUris = stream(this.symbolIndex.keys());\n    if (uris) {\n      documentUris = documentUris.filter((uri) => !uris || uris.has(uri));\n    }\n    return documentUris.map((uri) => this.getFileDescriptions(uri, nodeType)).flat();\n  }\n  getFileDescriptions(uri, nodeType) {\n    var _a;\n    if (!nodeType) {\n      return (_a = this.symbolIndex.get(uri)) !== null && _a !== void 0 ? _a : [];\n    }\n    const descriptions = this.symbolByTypeIndex.get(uri, nodeType, () => {\n      var _a2;\n      const allFileDescriptions = (_a2 = this.symbolIndex.get(uri)) !== null && _a2 !== void 0 ? _a2 : [];\n      return allFileDescriptions.filter((e) => this.astReflection.isSubtype(e.type, nodeType));\n    });\n    return descriptions;\n  }\n  remove(uri) {\n    const uriString = uri.toString();\n    this.symbolIndex.delete(uriString);\n    this.symbolByTypeIndex.clear(uriString);\n    this.referenceIndex.delete(uriString);\n  }\n  async updateContent(document, cancelToken = cancellation_exports.CancellationToken.None) {\n    const services = this.serviceRegistry.getServices(document.uri);\n    const exports = await services.references.ScopeComputation.computeExports(document, cancelToken);\n    const uri = document.uri.toString();\n    this.symbolIndex.set(uri, exports);\n    this.symbolByTypeIndex.clear(uri);\n  }\n  async updateReferences(document, cancelToken = cancellation_exports.CancellationToken.None) {\n    const services = this.serviceRegistry.getServices(document.uri);\n    const indexData = await services.workspace.ReferenceDescriptionProvider.createDescriptions(document, cancelToken);\n    this.referenceIndex.set(document.uri.toString(), indexData);\n  }\n  isAffected(document, changedUris) {\n    const references = this.referenceIndex.get(document.uri.toString());\n    if (!references) {\n      return false;\n    }\n    return references.some((ref) => !ref.local && changedUris.has(ref.targetUri.toString()));\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/workspace/workspace-manager.js\nvar DefaultWorkspaceManager = class {\n  static {\n    __name(this, \"DefaultWorkspaceManager\");\n  }\n  constructor(services) {\n    this.initialBuildOptions = {};\n    this._ready = new Deferred();\n    this.serviceRegistry = services.ServiceRegistry;\n    this.langiumDocuments = services.workspace.LangiumDocuments;\n    this.documentBuilder = services.workspace.DocumentBuilder;\n    this.fileSystemProvider = services.workspace.FileSystemProvider;\n    this.mutex = services.workspace.WorkspaceLock;\n  }\n  get ready() {\n    return this._ready.promise;\n  }\n  get workspaceFolders() {\n    return this.folders;\n  }\n  initialize(params) {\n    var _a;\n    this.folders = (_a = params.workspaceFolders) !== null && _a !== void 0 ? _a : void 0;\n  }\n  initialized(_params) {\n    return this.mutex.write((token) => {\n      var _a;\n      return this.initializeWorkspace((_a = this.folders) !== null && _a !== void 0 ? _a : [], token);\n    });\n  }\n  async initializeWorkspace(folders, cancelToken = cancellation_exports.CancellationToken.None) {\n    const documents = await this.performStartup(folders);\n    await interruptAndCheck(cancelToken);\n    await this.documentBuilder.build(documents, this.initialBuildOptions, cancelToken);\n  }\n  /**\n   * Performs the uninterruptable startup sequence of the workspace manager.\n   * This methods loads all documents in the workspace and other documents and returns them.\n   */\n  async performStartup(folders) {\n    const fileExtensions = this.serviceRegistry.all.flatMap((e) => e.LanguageMetaData.fileExtensions);\n    const documents = [];\n    const collector = /* @__PURE__ */ __name((document) => {\n      documents.push(document);\n      if (!this.langiumDocuments.hasDocument(document.uri)) {\n        this.langiumDocuments.addDocument(document);\n      }\n    }, \"collector\");\n    await this.loadAdditionalDocuments(folders, collector);\n    await Promise.all(folders.map((wf) => [wf, this.getRootFolder(wf)]).map(async (entry) => this.traverseFolder(...entry, fileExtensions, collector)));\n    this._ready.resolve();\n    return documents;\n  }\n  /**\n   * Load all additional documents that shall be visible in the context of the given workspace\n   * folders and add them to the collector. This can be used to include built-in libraries of\n   * your language, which can be either loaded from provided files or constructed in memory.\n   */\n  loadAdditionalDocuments(_folders, _collector) {\n    return Promise.resolve();\n  }\n  /**\n   * Determine the root folder of the source documents in the given workspace folder.\n   * The default implementation returns the URI of the workspace folder, but you can override\n   * this to return a subfolder like `src` instead.\n   */\n  getRootFolder(workspaceFolder) {\n    return URI2.parse(workspaceFolder.uri);\n  }\n  /**\n   * Traverse the file system folder identified by the given URI and its subfolders. All\n   * contained files that match the file extensions are added to the collector.\n   */\n  async traverseFolder(workspaceFolder, folderPath, fileExtensions, collector) {\n    const content = await this.fileSystemProvider.readDirectory(folderPath);\n    await Promise.all(content.map(async (entry) => {\n      if (this.includeEntry(workspaceFolder, entry, fileExtensions)) {\n        if (entry.isDirectory) {\n          await this.traverseFolder(workspaceFolder, entry.uri, fileExtensions, collector);\n        } else if (entry.isFile) {\n          const document = await this.langiumDocuments.getOrCreateDocument(entry.uri);\n          collector(document);\n        }\n      }\n    }));\n  }\n  /**\n   * Determine whether the given folder entry shall be included while indexing the workspace.\n   */\n  includeEntry(_workspaceFolder, entry, fileExtensions) {\n    const name = UriUtils.basename(entry.uri);\n    if (name.startsWith(\".\")) {\n      return false;\n    }\n    if (entry.isDirectory) {\n      return name !== \"node_modules\" && name !== \"out\";\n    } else if (entry.isFile) {\n      const extname = UriUtils.extname(entry.uri);\n      return fileExtensions.includes(extname);\n    }\n    return false;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/lexer.js\nvar DefaultLexerErrorMessageProvider = class {\n  static {\n    __name(this, \"DefaultLexerErrorMessageProvider\");\n  }\n  buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column) {\n    return defaultLexerErrorProvider.buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column);\n  }\n  buildUnableToPopLexerModeMessage(token) {\n    return defaultLexerErrorProvider.buildUnableToPopLexerModeMessage(token);\n  }\n};\nvar DEFAULT_TOKENIZE_OPTIONS = { mode: \"full\" };\nvar DefaultLexer = class {\n  static {\n    __name(this, \"DefaultLexer\");\n  }\n  constructor(services) {\n    this.errorMessageProvider = services.parser.LexerErrorMessageProvider;\n    this.tokenBuilder = services.parser.TokenBuilder;\n    const tokens = this.tokenBuilder.buildTokens(services.Grammar, {\n      caseInsensitive: services.LanguageMetaData.caseInsensitive\n    });\n    this.tokenTypes = this.toTokenTypeDictionary(tokens);\n    const lexerTokens = isTokenTypeDictionary(tokens) ? Object.values(tokens) : tokens;\n    const production = services.LanguageMetaData.mode === \"production\";\n    this.chevrotainLexer = new Lexer(lexerTokens, {\n      positionTracking: \"full\",\n      skipValidations: production,\n      errorMessageProvider: this.errorMessageProvider\n    });\n  }\n  get definition() {\n    return this.tokenTypes;\n  }\n  tokenize(text, _options = DEFAULT_TOKENIZE_OPTIONS) {\n    var _a, _b, _c;\n    const chevrotainResult = this.chevrotainLexer.tokenize(text);\n    return {\n      tokens: chevrotainResult.tokens,\n      errors: chevrotainResult.errors,\n      hidden: (_a = chevrotainResult.groups.hidden) !== null && _a !== void 0 ? _a : [],\n      report: (_c = (_b = this.tokenBuilder).flushLexingReport) === null || _c === void 0 ? void 0 : _c.call(_b, text)\n    };\n  }\n  toTokenTypeDictionary(buildTokens) {\n    if (isTokenTypeDictionary(buildTokens))\n      return buildTokens;\n    const tokens = isIMultiModeLexerDefinition(buildTokens) ? Object.values(buildTokens.modes).flat() : buildTokens;\n    const res = {};\n    tokens.forEach((token) => res[token.name] = token);\n    return res;\n  }\n};\nfunction isTokenTypeArray(tokenVocabulary) {\n  return Array.isArray(tokenVocabulary) && (tokenVocabulary.length === 0 || \"name\" in tokenVocabulary[0]);\n}\n__name(isTokenTypeArray, \"isTokenTypeArray\");\nfunction isIMultiModeLexerDefinition(tokenVocabulary) {\n  return tokenVocabulary && \"modes\" in tokenVocabulary && \"defaultMode\" in tokenVocabulary;\n}\n__name(isIMultiModeLexerDefinition, \"isIMultiModeLexerDefinition\");\nfunction isTokenTypeDictionary(tokenVocabulary) {\n  return !isTokenTypeArray(tokenVocabulary) && !isIMultiModeLexerDefinition(tokenVocabulary);\n}\n__name(isTokenTypeDictionary, \"isTokenTypeDictionary\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/documentation/jsdoc.js\nfunction parseJSDoc(node, start, options) {\n  let opts;\n  let position;\n  if (typeof node === \"string\") {\n    position = start;\n    opts = options;\n  } else {\n    position = node.range.start;\n    opts = start;\n  }\n  if (!position) {\n    position = Position.create(0, 0);\n  }\n  const lines = getLines(node);\n  const normalizedOptions = normalizeOptions(opts);\n  const tokens = tokenize({\n    lines,\n    position,\n    options: normalizedOptions\n  });\n  return parseJSDocComment({\n    index: 0,\n    tokens,\n    position\n  });\n}\n__name(parseJSDoc, \"parseJSDoc\");\nfunction isJSDoc(node, options) {\n  const normalizedOptions = normalizeOptions(options);\n  const lines = getLines(node);\n  if (lines.length === 0) {\n    return false;\n  }\n  const first2 = lines[0];\n  const last = lines[lines.length - 1];\n  const firstRegex = normalizedOptions.start;\n  const lastRegex = normalizedOptions.end;\n  return Boolean(firstRegex === null || firstRegex === void 0 ? void 0 : firstRegex.exec(first2)) && Boolean(lastRegex === null || lastRegex === void 0 ? void 0 : lastRegex.exec(last));\n}\n__name(isJSDoc, \"isJSDoc\");\nfunction getLines(node) {\n  let content = \"\";\n  if (typeof node === \"string\") {\n    content = node;\n  } else {\n    content = node.text;\n  }\n  const lines = content.split(NEWLINE_REGEXP);\n  return lines;\n}\n__name(getLines, \"getLines\");\nvar tagRegex = /\\s*(@([\\p{L}][\\p{L}\\p{N}]*)?)/uy;\nvar inlineTagRegex = /\\{(@[\\p{L}][\\p{L}\\p{N}]*)(\\s*)([^\\r\\n}]+)?\\}/gu;\nfunction tokenize(context) {\n  var _a, _b, _c;\n  const tokens = [];\n  let currentLine = context.position.line;\n  let currentCharacter = context.position.character;\n  for (let i = 0; i < context.lines.length; i++) {\n    const first2 = i === 0;\n    const last = i === context.lines.length - 1;\n    let line = context.lines[i];\n    let index = 0;\n    if (first2 && context.options.start) {\n      const match = (_a = context.options.start) === null || _a === void 0 ? void 0 : _a.exec(line);\n      if (match) {\n        index = match.index + match[0].length;\n      }\n    } else {\n      const match = (_b = context.options.line) === null || _b === void 0 ? void 0 : _b.exec(line);\n      if (match) {\n        index = match.index + match[0].length;\n      }\n    }\n    if (last) {\n      const match = (_c = context.options.end) === null || _c === void 0 ? void 0 : _c.exec(line);\n      if (match) {\n        line = line.substring(0, match.index);\n      }\n    }\n    line = line.substring(0, lastCharacter(line));\n    const whitespaceEnd = skipWhitespace(line, index);\n    if (whitespaceEnd >= line.length) {\n      if (tokens.length > 0) {\n        const position = Position.create(currentLine, currentCharacter);\n        tokens.push({\n          type: \"break\",\n          content: \"\",\n          range: Range.create(position, position)\n        });\n      }\n    } else {\n      tagRegex.lastIndex = index;\n      const tagMatch = tagRegex.exec(line);\n      if (tagMatch) {\n        const fullMatch = tagMatch[0];\n        const value = tagMatch[1];\n        const start = Position.create(currentLine, currentCharacter + index);\n        const end = Position.create(currentLine, currentCharacter + index + fullMatch.length);\n        tokens.push({\n          type: \"tag\",\n          content: value,\n          range: Range.create(start, end)\n        });\n        index += fullMatch.length;\n        index = skipWhitespace(line, index);\n      }\n      if (index < line.length) {\n        const rest = line.substring(index);\n        const inlineTagMatches = Array.from(rest.matchAll(inlineTagRegex));\n        tokens.push(...buildInlineTokens(inlineTagMatches, rest, currentLine, currentCharacter + index));\n      }\n    }\n    currentLine++;\n    currentCharacter = 0;\n  }\n  if (tokens.length > 0 && tokens[tokens.length - 1].type === \"break\") {\n    return tokens.slice(0, -1);\n  }\n  return tokens;\n}\n__name(tokenize, \"tokenize\");\nfunction buildInlineTokens(tags, line, lineIndex, characterIndex) {\n  const tokens = [];\n  if (tags.length === 0) {\n    const start = Position.create(lineIndex, characterIndex);\n    const end = Position.create(lineIndex, characterIndex + line.length);\n    tokens.push({\n      type: \"text\",\n      content: line,\n      range: Range.create(start, end)\n    });\n  } else {\n    let lastIndex = 0;\n    for (const match of tags) {\n      const matchIndex = match.index;\n      const startContent = line.substring(lastIndex, matchIndex);\n      if (startContent.length > 0) {\n        tokens.push({\n          type: \"text\",\n          content: line.substring(lastIndex, matchIndex),\n          range: Range.create(Position.create(lineIndex, lastIndex + characterIndex), Position.create(lineIndex, matchIndex + characterIndex))\n        });\n      }\n      let offset = startContent.length + 1;\n      const tagName = match[1];\n      tokens.push({\n        type: \"inline-tag\",\n        content: tagName,\n        range: Range.create(Position.create(lineIndex, lastIndex + offset + characterIndex), Position.create(lineIndex, lastIndex + offset + tagName.length + characterIndex))\n      });\n      offset += tagName.length;\n      if (match.length === 4) {\n        offset += match[2].length;\n        const value = match[3];\n        tokens.push({\n          type: \"text\",\n          content: value,\n          range: Range.create(Position.create(lineIndex, lastIndex + offset + characterIndex), Position.create(lineIndex, lastIndex + offset + value.length + characterIndex))\n        });\n      } else {\n        tokens.push({\n          type: \"text\",\n          content: \"\",\n          range: Range.create(Position.create(lineIndex, lastIndex + offset + characterIndex), Position.create(lineIndex, lastIndex + offset + characterIndex))\n        });\n      }\n      lastIndex = matchIndex + match[0].length;\n    }\n    const endContent = line.substring(lastIndex);\n    if (endContent.length > 0) {\n      tokens.push({\n        type: \"text\",\n        content: endContent,\n        range: Range.create(Position.create(lineIndex, lastIndex + characterIndex), Position.create(lineIndex, lastIndex + characterIndex + endContent.length))\n      });\n    }\n  }\n  return tokens;\n}\n__name(buildInlineTokens, \"buildInlineTokens\");\nvar nonWhitespaceRegex = /\\S/;\nvar whitespaceEndRegex = /\\s*$/;\nfunction skipWhitespace(line, index) {\n  const match = line.substring(index).match(nonWhitespaceRegex);\n  if (match) {\n    return index + match.index;\n  } else {\n    return line.length;\n  }\n}\n__name(skipWhitespace, \"skipWhitespace\");\nfunction lastCharacter(line) {\n  const match = line.match(whitespaceEndRegex);\n  if (match && typeof match.index === \"number\") {\n    return match.index;\n  }\n  return void 0;\n}\n__name(lastCharacter, \"lastCharacter\");\nfunction parseJSDocComment(context) {\n  var _a, _b, _c, _d;\n  const startPosition = Position.create(context.position.line, context.position.character);\n  if (context.tokens.length === 0) {\n    return new JSDocCommentImpl([], Range.create(startPosition, startPosition));\n  }\n  const elements = [];\n  while (context.index < context.tokens.length) {\n    const element = parseJSDocElement(context, elements[elements.length - 1]);\n    if (element) {\n      elements.push(element);\n    }\n  }\n  const start = (_b = (_a = elements[0]) === null || _a === void 0 ? void 0 : _a.range.start) !== null && _b !== void 0 ? _b : startPosition;\n  const end = (_d = (_c = elements[elements.length - 1]) === null || _c === void 0 ? void 0 : _c.range.end) !== null && _d !== void 0 ? _d : startPosition;\n  return new JSDocCommentImpl(elements, Range.create(start, end));\n}\n__name(parseJSDocComment, \"parseJSDocComment\");\nfunction parseJSDocElement(context, last) {\n  const next = context.tokens[context.index];\n  if (next.type === \"tag\") {\n    return parseJSDocTag(context, false);\n  } else if (next.type === \"text\" || next.type === \"inline-tag\") {\n    return parseJSDocText(context);\n  } else {\n    appendEmptyLine(next, last);\n    context.index++;\n    return void 0;\n  }\n}\n__name(parseJSDocElement, \"parseJSDocElement\");\nfunction appendEmptyLine(token, element) {\n  if (element) {\n    const line = new JSDocLineImpl(\"\", token.range);\n    if (\"inlines\" in element) {\n      element.inlines.push(line);\n    } else {\n      element.content.inlines.push(line);\n    }\n  }\n}\n__name(appendEmptyLine, \"appendEmptyLine\");\nfunction parseJSDocText(context) {\n  let token = context.tokens[context.index];\n  const firstToken = token;\n  let lastToken = token;\n  const lines = [];\n  while (token && token.type !== \"break\" && token.type !== \"tag\") {\n    lines.push(parseJSDocInline(context));\n    lastToken = token;\n    token = context.tokens[context.index];\n  }\n  return new JSDocTextImpl(lines, Range.create(firstToken.range.start, lastToken.range.end));\n}\n__name(parseJSDocText, \"parseJSDocText\");\nfunction parseJSDocInline(context) {\n  const token = context.tokens[context.index];\n  if (token.type === \"inline-tag\") {\n    return parseJSDocTag(context, true);\n  } else {\n    return parseJSDocLine(context);\n  }\n}\n__name(parseJSDocInline, \"parseJSDocInline\");\nfunction parseJSDocTag(context, inline) {\n  const tagToken = context.tokens[context.index++];\n  const name = tagToken.content.substring(1);\n  const nextToken = context.tokens[context.index];\n  if ((nextToken === null || nextToken === void 0 ? void 0 : nextToken.type) === \"text\") {\n    if (inline) {\n      const docLine = parseJSDocLine(context);\n      return new JSDocTagImpl(name, new JSDocTextImpl([docLine], docLine.range), inline, Range.create(tagToken.range.start, docLine.range.end));\n    } else {\n      const textDoc = parseJSDocText(context);\n      return new JSDocTagImpl(name, textDoc, inline, Range.create(tagToken.range.start, textDoc.range.end));\n    }\n  } else {\n    const range = tagToken.range;\n    return new JSDocTagImpl(name, new JSDocTextImpl([], range), inline, range);\n  }\n}\n__name(parseJSDocTag, \"parseJSDocTag\");\nfunction parseJSDocLine(context) {\n  const token = context.tokens[context.index++];\n  return new JSDocLineImpl(token.content, token.range);\n}\n__name(parseJSDocLine, \"parseJSDocLine\");\nfunction normalizeOptions(options) {\n  if (!options) {\n    return normalizeOptions({\n      start: \"/**\",\n      end: \"*/\",\n      line: \"*\"\n    });\n  }\n  const { start, end, line } = options;\n  return {\n    start: normalizeOption(start, true),\n    end: normalizeOption(end, false),\n    line: normalizeOption(line, true)\n  };\n}\n__name(normalizeOptions, \"normalizeOptions\");\nfunction normalizeOption(option2, start) {\n  if (typeof option2 === \"string\" || typeof option2 === \"object\") {\n    const escaped = typeof option2 === \"string\" ? escapeRegExp(option2) : option2.source;\n    if (start) {\n      return new RegExp(`^\\\\s*${escaped}`);\n    } else {\n      return new RegExp(`\\\\s*${escaped}\\\\s*$`);\n    }\n  } else {\n    return option2;\n  }\n}\n__name(normalizeOption, \"normalizeOption\");\nvar JSDocCommentImpl = class {\n  static {\n    __name(this, \"JSDocCommentImpl\");\n  }\n  constructor(elements, range) {\n    this.elements = elements;\n    this.range = range;\n  }\n  getTag(name) {\n    return this.getAllTags().find((e) => e.name === name);\n  }\n  getTags(name) {\n    return this.getAllTags().filter((e) => e.name === name);\n  }\n  getAllTags() {\n    return this.elements.filter((e) => \"name\" in e);\n  }\n  toString() {\n    let value = \"\";\n    for (const element of this.elements) {\n      if (value.length === 0) {\n        value = element.toString();\n      } else {\n        const text = element.toString();\n        value += fillNewlines(value) + text;\n      }\n    }\n    return value.trim();\n  }\n  toMarkdown(options) {\n    let value = \"\";\n    for (const element of this.elements) {\n      if (value.length === 0) {\n        value = element.toMarkdown(options);\n      } else {\n        const text = element.toMarkdown(options);\n        value += fillNewlines(value) + text;\n      }\n    }\n    return value.trim();\n  }\n};\nvar JSDocTagImpl = class {\n  static {\n    __name(this, \"JSDocTagImpl\");\n  }\n  constructor(name, content, inline, range) {\n    this.name = name;\n    this.content = content;\n    this.inline = inline;\n    this.range = range;\n  }\n  toString() {\n    let text = `@${this.name}`;\n    const content = this.content.toString();\n    if (this.content.inlines.length === 1) {\n      text = `${text} ${content}`;\n    } else if (this.content.inlines.length > 1) {\n      text = `${text}\n${content}`;\n    }\n    if (this.inline) {\n      return `{${text}}`;\n    } else {\n      return text;\n    }\n  }\n  toMarkdown(options) {\n    var _a, _b;\n    return (_b = (_a = options === null || options === void 0 ? void 0 : options.renderTag) === null || _a === void 0 ? void 0 : _a.call(options, this)) !== null && _b !== void 0 ? _b : this.toMarkdownDefault(options);\n  }\n  toMarkdownDefault(options) {\n    const content = this.content.toMarkdown(options);\n    if (this.inline) {\n      const rendered = renderInlineTag(this.name, content, options !== null && options !== void 0 ? options : {});\n      if (typeof rendered === \"string\") {\n        return rendered;\n      }\n    }\n    let marker = \"\";\n    if ((options === null || options === void 0 ? void 0 : options.tag) === \"italic\" || (options === null || options === void 0 ? void 0 : options.tag) === void 0) {\n      marker = \"*\";\n    } else if ((options === null || options === void 0 ? void 0 : options.tag) === \"bold\") {\n      marker = \"**\";\n    } else if ((options === null || options === void 0 ? void 0 : options.tag) === \"bold-italic\") {\n      marker = \"***\";\n    }\n    let text = `${marker}@${this.name}${marker}`;\n    if (this.content.inlines.length === 1) {\n      text = `${text} \\u2014 ${content}`;\n    } else if (this.content.inlines.length > 1) {\n      text = `${text}\n${content}`;\n    }\n    if (this.inline) {\n      return `{${text}}`;\n    } else {\n      return text;\n    }\n  }\n};\nfunction renderInlineTag(tag, content, options) {\n  var _a, _b;\n  if (tag === \"linkplain\" || tag === \"linkcode\" || tag === \"link\") {\n    const index = content.indexOf(\" \");\n    let display = content;\n    if (index > 0) {\n      const displayStart = skipWhitespace(content, index);\n      display = content.substring(displayStart);\n      content = content.substring(0, index);\n    }\n    if (tag === \"linkcode\" || tag === \"link\" && options.link === \"code\") {\n      display = `\\`${display}\\``;\n    }\n    const renderedLink = (_b = (_a = options.renderLink) === null || _a === void 0 ? void 0 : _a.call(options, content, display)) !== null && _b !== void 0 ? _b : renderLinkDefault(content, display);\n    return renderedLink;\n  }\n  return void 0;\n}\n__name(renderInlineTag, \"renderInlineTag\");\nfunction renderLinkDefault(content, display) {\n  try {\n    URI2.parse(content, true);\n    return `[${display}](${content})`;\n  } catch (_a) {\n    return content;\n  }\n}\n__name(renderLinkDefault, \"renderLinkDefault\");\nvar JSDocTextImpl = class {\n  static {\n    __name(this, \"JSDocTextImpl\");\n  }\n  constructor(lines, range) {\n    this.inlines = lines;\n    this.range = range;\n  }\n  toString() {\n    let text = \"\";\n    for (let i = 0; i < this.inlines.length; i++) {\n      const inline = this.inlines[i];\n      const next = this.inlines[i + 1];\n      text += inline.toString();\n      if (next && next.range.start.line > inline.range.start.line) {\n        text += \"\\n\";\n      }\n    }\n    return text;\n  }\n  toMarkdown(options) {\n    let text = \"\";\n    for (let i = 0; i < this.inlines.length; i++) {\n      const inline = this.inlines[i];\n      const next = this.inlines[i + 1];\n      text += inline.toMarkdown(options);\n      if (next && next.range.start.line > inline.range.start.line) {\n        text += \"\\n\";\n      }\n    }\n    return text;\n  }\n};\nvar JSDocLineImpl = class {\n  static {\n    __name(this, \"JSDocLineImpl\");\n  }\n  constructor(text, range) {\n    this.text = text;\n    this.range = range;\n  }\n  toString() {\n    return this.text;\n  }\n  toMarkdown() {\n    return this.text;\n  }\n};\nfunction fillNewlines(text) {\n  if (text.endsWith(\"\\n\")) {\n    return \"\\n\";\n  } else {\n    return \"\\n\\n\";\n  }\n}\n__name(fillNewlines, \"fillNewlines\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/documentation/documentation-provider.js\nvar JSDocDocumentationProvider = class {\n  static {\n    __name(this, \"JSDocDocumentationProvider\");\n  }\n  constructor(services) {\n    this.indexManager = services.shared.workspace.IndexManager;\n    this.commentProvider = services.documentation.CommentProvider;\n  }\n  getDocumentation(node) {\n    const comment = this.commentProvider.getComment(node);\n    if (comment && isJSDoc(comment)) {\n      const parsedJSDoc = parseJSDoc(comment);\n      return parsedJSDoc.toMarkdown({\n        renderLink: /* @__PURE__ */ __name((link, display) => {\n          return this.documentationLinkRenderer(node, link, display);\n        }, \"renderLink\"),\n        renderTag: /* @__PURE__ */ __name((tag) => {\n          return this.documentationTagRenderer(node, tag);\n        }, \"renderTag\")\n      });\n    }\n    return void 0;\n  }\n  documentationLinkRenderer(node, name, display) {\n    var _a;\n    const description = (_a = this.findNameInPrecomputedScopes(node, name)) !== null && _a !== void 0 ? _a : this.findNameInGlobalScope(node, name);\n    if (description && description.nameSegment) {\n      const line = description.nameSegment.range.start.line + 1;\n      const character = description.nameSegment.range.start.character + 1;\n      const uri = description.documentUri.with({ fragment: `L${line},${character}` });\n      return `[${display}](${uri.toString()})`;\n    } else {\n      return void 0;\n    }\n  }\n  documentationTagRenderer(_node, _tag) {\n    return void 0;\n  }\n  findNameInPrecomputedScopes(node, name) {\n    const document = getDocument(node);\n    const precomputed = document.precomputedScopes;\n    if (!precomputed) {\n      return void 0;\n    }\n    let currentNode = node;\n    do {\n      const allDescriptions = precomputed.get(currentNode);\n      const description = allDescriptions.find((e) => e.name === name);\n      if (description) {\n        return description;\n      }\n      currentNode = currentNode.$container;\n    } while (currentNode);\n    return void 0;\n  }\n  findNameInGlobalScope(node, name) {\n    const description = this.indexManager.allElements().find((e) => e.name === name);\n    return description;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/documentation/comment-provider.js\nvar DefaultCommentProvider = class {\n  static {\n    __name(this, \"DefaultCommentProvider\");\n  }\n  constructor(services) {\n    this.grammarConfig = () => services.parser.GrammarConfig;\n  }\n  getComment(node) {\n    var _a;\n    if (isAstNodeWithComment(node)) {\n      return node.$comment;\n    }\n    return (_a = findCommentNode(node.$cstNode, this.grammarConfig().multilineCommentRules)) === null || _a === void 0 ? void 0 : _a.text;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/async-parser.js\nvar DefaultAsyncParser = class {\n  static {\n    __name(this, \"DefaultAsyncParser\");\n  }\n  constructor(services) {\n    this.syncParser = services.parser.LangiumParser;\n  }\n  parse(text, _cancelToken) {\n    return Promise.resolve(this.syncParser.parse(text));\n  }\n};\nvar AbstractThreadedAsyncParser = class {\n  static {\n    __name(this, \"AbstractThreadedAsyncParser\");\n  }\n  constructor(services) {\n    this.threadCount = 8;\n    this.terminationDelay = 200;\n    this.workerPool = [];\n    this.queue = [];\n    this.hydrator = services.serializer.Hydrator;\n  }\n  initializeWorkers() {\n    while (this.workerPool.length < this.threadCount) {\n      const worker = this.createWorker();\n      worker.onReady(() => {\n        if (this.queue.length > 0) {\n          const deferred = this.queue.shift();\n          if (deferred) {\n            worker.lock();\n            deferred.resolve(worker);\n          }\n        }\n      });\n      this.workerPool.push(worker);\n    }\n  }\n  async parse(text, cancelToken) {\n    const worker = await this.acquireParserWorker(cancelToken);\n    const deferred = new Deferred();\n    let timeout;\n    const cancellation = cancelToken.onCancellationRequested(() => {\n      timeout = setTimeout(() => {\n        this.terminateWorker(worker);\n      }, this.terminationDelay);\n    });\n    worker.parse(text).then((result) => {\n      const hydrated = this.hydrator.hydrate(result);\n      deferred.resolve(hydrated);\n    }).catch((err) => {\n      deferred.reject(err);\n    }).finally(() => {\n      cancellation.dispose();\n      clearTimeout(timeout);\n    });\n    return deferred.promise;\n  }\n  terminateWorker(worker) {\n    worker.terminate();\n    const index = this.workerPool.indexOf(worker);\n    if (index >= 0) {\n      this.workerPool.splice(index, 1);\n    }\n  }\n  async acquireParserWorker(cancelToken) {\n    this.initializeWorkers();\n    for (const worker of this.workerPool) {\n      if (worker.ready) {\n        worker.lock();\n        return worker;\n      }\n    }\n    const deferred = new Deferred();\n    cancelToken.onCancellationRequested(() => {\n      const index = this.queue.indexOf(deferred);\n      if (index >= 0) {\n        this.queue.splice(index, 1);\n      }\n      deferred.reject(OperationCancelled);\n    });\n    this.queue.push(deferred);\n    return deferred.promise;\n  }\n};\nvar ParserWorker = class {\n  static {\n    __name(this, \"ParserWorker\");\n  }\n  get ready() {\n    return this._ready;\n  }\n  get onReady() {\n    return this.onReadyEmitter.event;\n  }\n  constructor(sendMessage, onMessage, onError, terminate) {\n    this.onReadyEmitter = new event_exports.Emitter();\n    this.deferred = new Deferred();\n    this._ready = true;\n    this._parsing = false;\n    this.sendMessage = sendMessage;\n    this._terminate = terminate;\n    onMessage((result) => {\n      const parseResult = result;\n      this.deferred.resolve(parseResult);\n      this.unlock();\n    });\n    onError((error) => {\n      this.deferred.reject(error);\n      this.unlock();\n    });\n  }\n  terminate() {\n    this.deferred.reject(OperationCancelled);\n    this._terminate();\n  }\n  lock() {\n    this._ready = false;\n  }\n  unlock() {\n    this._parsing = false;\n    this._ready = true;\n    this.onReadyEmitter.fire();\n  }\n  parse(text) {\n    if (this._parsing) {\n      throw new Error(\"Parser worker is busy\");\n    }\n    this._parsing = true;\n    this.deferred = new Deferred();\n    this.sendMessage(text);\n    return this.deferred.promise;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/workspace/workspace-lock.js\nvar DefaultWorkspaceLock = class {\n  static {\n    __name(this, \"DefaultWorkspaceLock\");\n  }\n  constructor() {\n    this.previousTokenSource = new cancellation_exports.CancellationTokenSource();\n    this.writeQueue = [];\n    this.readQueue = [];\n    this.done = true;\n  }\n  write(action) {\n    this.cancelWrite();\n    const tokenSource = startCancelableOperation();\n    this.previousTokenSource = tokenSource;\n    return this.enqueue(this.writeQueue, action, tokenSource.token);\n  }\n  read(action) {\n    return this.enqueue(this.readQueue, action);\n  }\n  enqueue(queue, action, cancellationToken = cancellation_exports.CancellationToken.None) {\n    const deferred = new Deferred();\n    const entry = {\n      action,\n      deferred,\n      cancellationToken\n    };\n    queue.push(entry);\n    this.performNextOperation();\n    return deferred.promise;\n  }\n  async performNextOperation() {\n    if (!this.done) {\n      return;\n    }\n    const entries = [];\n    if (this.writeQueue.length > 0) {\n      entries.push(this.writeQueue.shift());\n    } else if (this.readQueue.length > 0) {\n      entries.push(...this.readQueue.splice(0, this.readQueue.length));\n    } else {\n      return;\n    }\n    this.done = false;\n    await Promise.all(entries.map(async ({ action, deferred, cancellationToken }) => {\n      try {\n        const result = await Promise.resolve().then(() => action(cancellationToken));\n        deferred.resolve(result);\n      } catch (err) {\n        if (isOperationCancelled(err)) {\n          deferred.resolve(void 0);\n        } else {\n          deferred.reject(err);\n        }\n      }\n    }));\n    this.done = true;\n    this.performNextOperation();\n  }\n  cancelWrite() {\n    this.previousTokenSource.cancel();\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/serializer/hydrator.js\nvar DefaultHydrator = class {\n  static {\n    __name(this, \"DefaultHydrator\");\n  }\n  constructor(services) {\n    this.grammarElementIdMap = new BiMap();\n    this.tokenTypeIdMap = new BiMap();\n    this.grammar = services.Grammar;\n    this.lexer = services.parser.Lexer;\n    this.linker = services.references.Linker;\n  }\n  dehydrate(result) {\n    return {\n      lexerErrors: result.lexerErrors,\n      lexerReport: result.lexerReport ? this.dehydrateLexerReport(result.lexerReport) : void 0,\n      // We need to create shallow copies of the errors\n      // The original errors inherit from the `Error` class, which is not transferable across worker threads\n      parserErrors: result.parserErrors.map((e) => Object.assign(Object.assign({}, e), { message: e.message })),\n      value: this.dehydrateAstNode(result.value, this.createDehyrationContext(result.value))\n    };\n  }\n  dehydrateLexerReport(lexerReport) {\n    return lexerReport;\n  }\n  createDehyrationContext(node) {\n    const astNodes = /* @__PURE__ */ new Map();\n    const cstNodes = /* @__PURE__ */ new Map();\n    for (const astNode of streamAst(node)) {\n      astNodes.set(astNode, {});\n    }\n    if (node.$cstNode) {\n      for (const cstNode of streamCst(node.$cstNode)) {\n        cstNodes.set(cstNode, {});\n      }\n    }\n    return {\n      astNodes,\n      cstNodes\n    };\n  }\n  dehydrateAstNode(node, context) {\n    const obj = context.astNodes.get(node);\n    obj.$type = node.$type;\n    obj.$containerIndex = node.$containerIndex;\n    obj.$containerProperty = node.$containerProperty;\n    if (node.$cstNode !== void 0) {\n      obj.$cstNode = this.dehydrateCstNode(node.$cstNode, context);\n    }\n    for (const [name, value] of Object.entries(node)) {\n      if (name.startsWith(\"$\")) {\n        continue;\n      }\n      if (Array.isArray(value)) {\n        const arr = [];\n        obj[name] = arr;\n        for (const item of value) {\n          if (isAstNode(item)) {\n            arr.push(this.dehydrateAstNode(item, context));\n          } else if (isReference(item)) {\n            arr.push(this.dehydrateReference(item, context));\n          } else {\n            arr.push(item);\n          }\n        }\n      } else if (isAstNode(value)) {\n        obj[name] = this.dehydrateAstNode(value, context);\n      } else if (isReference(value)) {\n        obj[name] = this.dehydrateReference(value, context);\n      } else if (value !== void 0) {\n        obj[name] = value;\n      }\n    }\n    return obj;\n  }\n  dehydrateReference(reference, context) {\n    const obj = {};\n    obj.$refText = reference.$refText;\n    if (reference.$refNode) {\n      obj.$refNode = context.cstNodes.get(reference.$refNode);\n    }\n    return obj;\n  }\n  dehydrateCstNode(node, context) {\n    const cstNode = context.cstNodes.get(node);\n    if (isRootCstNode(node)) {\n      cstNode.fullText = node.fullText;\n    } else {\n      cstNode.grammarSource = this.getGrammarElementId(node.grammarSource);\n    }\n    cstNode.hidden = node.hidden;\n    cstNode.astNode = context.astNodes.get(node.astNode);\n    if (isCompositeCstNode(node)) {\n      cstNode.content = node.content.map((child) => this.dehydrateCstNode(child, context));\n    } else if (isLeafCstNode(node)) {\n      cstNode.tokenType = node.tokenType.name;\n      cstNode.offset = node.offset;\n      cstNode.length = node.length;\n      cstNode.startLine = node.range.start.line;\n      cstNode.startColumn = node.range.start.character;\n      cstNode.endLine = node.range.end.line;\n      cstNode.endColumn = node.range.end.character;\n    }\n    return cstNode;\n  }\n  hydrate(result) {\n    const node = result.value;\n    const context = this.createHydrationContext(node);\n    if (\"$cstNode\" in node) {\n      this.hydrateCstNode(node.$cstNode, context);\n    }\n    return {\n      lexerErrors: result.lexerErrors,\n      lexerReport: result.lexerReport,\n      parserErrors: result.parserErrors,\n      value: this.hydrateAstNode(node, context)\n    };\n  }\n  createHydrationContext(node) {\n    const astNodes = /* @__PURE__ */ new Map();\n    const cstNodes = /* @__PURE__ */ new Map();\n    for (const astNode of streamAst(node)) {\n      astNodes.set(astNode, {});\n    }\n    let root;\n    if (node.$cstNode) {\n      for (const cstNode of streamCst(node.$cstNode)) {\n        let cst;\n        if (\"fullText\" in cstNode) {\n          cst = new RootCstNodeImpl(cstNode.fullText);\n          root = cst;\n        } else if (\"content\" in cstNode) {\n          cst = new CompositeCstNodeImpl();\n        } else if (\"tokenType\" in cstNode) {\n          cst = this.hydrateCstLeafNode(cstNode);\n        }\n        if (cst) {\n          cstNodes.set(cstNode, cst);\n          cst.root = root;\n        }\n      }\n    }\n    return {\n      astNodes,\n      cstNodes\n    };\n  }\n  hydrateAstNode(node, context) {\n    const astNode = context.astNodes.get(node);\n    astNode.$type = node.$type;\n    astNode.$containerIndex = node.$containerIndex;\n    astNode.$containerProperty = node.$containerProperty;\n    if (node.$cstNode) {\n      astNode.$cstNode = context.cstNodes.get(node.$cstNode);\n    }\n    for (const [name, value] of Object.entries(node)) {\n      if (name.startsWith(\"$\")) {\n        continue;\n      }\n      if (Array.isArray(value)) {\n        const arr = [];\n        astNode[name] = arr;\n        for (const item of value) {\n          if (isAstNode(item)) {\n            arr.push(this.setParent(this.hydrateAstNode(item, context), astNode));\n          } else if (isReference(item)) {\n            arr.push(this.hydrateReference(item, astNode, name, context));\n          } else {\n            arr.push(item);\n          }\n        }\n      } else if (isAstNode(value)) {\n        astNode[name] = this.setParent(this.hydrateAstNode(value, context), astNode);\n      } else if (isReference(value)) {\n        astNode[name] = this.hydrateReference(value, astNode, name, context);\n      } else if (value !== void 0) {\n        astNode[name] = value;\n      }\n    }\n    return astNode;\n  }\n  setParent(node, parent) {\n    node.$container = parent;\n    return node;\n  }\n  hydrateReference(reference, node, name, context) {\n    return this.linker.buildReference(node, name, context.cstNodes.get(reference.$refNode), reference.$refText);\n  }\n  hydrateCstNode(cstNode, context, num = 0) {\n    const cstNodeObj = context.cstNodes.get(cstNode);\n    if (typeof cstNode.grammarSource === \"number\") {\n      cstNodeObj.grammarSource = this.getGrammarElement(cstNode.grammarSource);\n    }\n    cstNodeObj.astNode = context.astNodes.get(cstNode.astNode);\n    if (isCompositeCstNode(cstNodeObj)) {\n      for (const child of cstNode.content) {\n        const hydrated = this.hydrateCstNode(child, context, num++);\n        cstNodeObj.content.push(hydrated);\n      }\n    }\n    return cstNodeObj;\n  }\n  hydrateCstLeafNode(cstNode) {\n    const tokenType = this.getTokenType(cstNode.tokenType);\n    const offset = cstNode.offset;\n    const length = cstNode.length;\n    const startLine = cstNode.startLine;\n    const startColumn = cstNode.startColumn;\n    const endLine = cstNode.endLine;\n    const endColumn = cstNode.endColumn;\n    const hidden = cstNode.hidden;\n    const node = new LeafCstNodeImpl(offset, length, {\n      start: {\n        line: startLine,\n        character: startColumn\n      },\n      end: {\n        line: endLine,\n        character: endColumn\n      }\n    }, tokenType, hidden);\n    return node;\n  }\n  getTokenType(name) {\n    return this.lexer.definition[name];\n  }\n  getGrammarElementId(node) {\n    if (!node) {\n      return void 0;\n    }\n    if (this.grammarElementIdMap.size === 0) {\n      this.createGrammarElementIdMap();\n    }\n    return this.grammarElementIdMap.get(node);\n  }\n  getGrammarElement(id) {\n    if (this.grammarElementIdMap.size === 0) {\n      this.createGrammarElementIdMap();\n    }\n    const element = this.grammarElementIdMap.getKey(id);\n    return element;\n  }\n  createGrammarElementIdMap() {\n    let id = 0;\n    for (const element of streamAst(this.grammar)) {\n      if (isAbstractElement(element)) {\n        this.grammarElementIdMap.set(element, id++);\n      }\n    }\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/default-module.js\nfunction createDefaultCoreModule(context) {\n  return {\n    documentation: {\n      CommentProvider: /* @__PURE__ */ __name((services) => new DefaultCommentProvider(services), \"CommentProvider\"),\n      DocumentationProvider: /* @__PURE__ */ __name((services) => new JSDocDocumentationProvider(services), \"DocumentationProvider\")\n    },\n    parser: {\n      AsyncParser: /* @__PURE__ */ __name((services) => new DefaultAsyncParser(services), \"AsyncParser\"),\n      GrammarConfig: /* @__PURE__ */ __name((services) => createGrammarConfig(services), \"GrammarConfig\"),\n      LangiumParser: /* @__PURE__ */ __name((services) => createLangiumParser(services), \"LangiumParser\"),\n      CompletionParser: /* @__PURE__ */ __name((services) => createCompletionParser(services), \"CompletionParser\"),\n      ValueConverter: /* @__PURE__ */ __name(() => new DefaultValueConverter(), \"ValueConverter\"),\n      TokenBuilder: /* @__PURE__ */ __name(() => new DefaultTokenBuilder(), \"TokenBuilder\"),\n      Lexer: /* @__PURE__ */ __name((services) => new DefaultLexer(services), \"Lexer\"),\n      ParserErrorMessageProvider: /* @__PURE__ */ __name(() => new LangiumParserErrorMessageProvider(), \"ParserErrorMessageProvider\"),\n      LexerErrorMessageProvider: /* @__PURE__ */ __name(() => new DefaultLexerErrorMessageProvider(), \"LexerErrorMessageProvider\")\n    },\n    workspace: {\n      AstNodeLocator: /* @__PURE__ */ __name(() => new DefaultAstNodeLocator(), \"AstNodeLocator\"),\n      AstNodeDescriptionProvider: /* @__PURE__ */ __name((services) => new DefaultAstNodeDescriptionProvider(services), \"AstNodeDescriptionProvider\"),\n      ReferenceDescriptionProvider: /* @__PURE__ */ __name((services) => new DefaultReferenceDescriptionProvider(services), \"ReferenceDescriptionProvider\")\n    },\n    references: {\n      Linker: /* @__PURE__ */ __name((services) => new DefaultLinker(services), \"Linker\"),\n      NameProvider: /* @__PURE__ */ __name(() => new DefaultNameProvider(), \"NameProvider\"),\n      ScopeProvider: /* @__PURE__ */ __name((services) => new DefaultScopeProvider(services), \"ScopeProvider\"),\n      ScopeComputation: /* @__PURE__ */ __name((services) => new DefaultScopeComputation(services), \"ScopeComputation\"),\n      References: /* @__PURE__ */ __name((services) => new DefaultReferences(services), \"References\")\n    },\n    serializer: {\n      Hydrator: /* @__PURE__ */ __name((services) => new DefaultHydrator(services), \"Hydrator\"),\n      JsonSerializer: /* @__PURE__ */ __name((services) => new DefaultJsonSerializer(services), \"JsonSerializer\")\n    },\n    validation: {\n      DocumentValidator: /* @__PURE__ */ __name((services) => new DefaultDocumentValidator(services), \"DocumentValidator\"),\n      ValidationRegistry: /* @__PURE__ */ __name((services) => new ValidationRegistry(services), \"ValidationRegistry\")\n    },\n    shared: /* @__PURE__ */ __name(() => context.shared, \"shared\")\n  };\n}\n__name(createDefaultCoreModule, \"createDefaultCoreModule\");\nfunction createDefaultSharedCoreModule(context) {\n  return {\n    ServiceRegistry: /* @__PURE__ */ __name((services) => new DefaultServiceRegistry(services), \"ServiceRegistry\"),\n    workspace: {\n      LangiumDocuments: /* @__PURE__ */ __name((services) => new DefaultLangiumDocuments(services), \"LangiumDocuments\"),\n      LangiumDocumentFactory: /* @__PURE__ */ __name((services) => new DefaultLangiumDocumentFactory(services), \"LangiumDocumentFactory\"),\n      DocumentBuilder: /* @__PURE__ */ __name((services) => new DefaultDocumentBuilder(services), \"DocumentBuilder\"),\n      IndexManager: /* @__PURE__ */ __name((services) => new DefaultIndexManager(services), \"IndexManager\"),\n      WorkspaceManager: /* @__PURE__ */ __name((services) => new DefaultWorkspaceManager(services), \"WorkspaceManager\"),\n      FileSystemProvider: /* @__PURE__ */ __name((services) => context.fileSystemProvider(services), \"FileSystemProvider\"),\n      WorkspaceLock: /* @__PURE__ */ __name(() => new DefaultWorkspaceLock(), \"WorkspaceLock\"),\n      ConfigurationProvider: /* @__PURE__ */ __name((services) => new DefaultConfigurationProvider(services), \"ConfigurationProvider\")\n    }\n  };\n}\n__name(createDefaultSharedCoreModule, \"createDefaultSharedCoreModule\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/dependency-injection.js\nvar Module;\n(function(Module2) {\n  Module2.merge = (m1, m2) => _merge(_merge({}, m1), m2);\n})(Module || (Module = {}));\nfunction inject(module1, module2, module3, module4, module5, module6, module7, module8, module9) {\n  const module = [module1, module2, module3, module4, module5, module6, module7, module8, module9].reduce(_merge, {});\n  return _inject(module);\n}\n__name(inject, \"inject\");\nvar isProxy = Symbol(\"isProxy\");\nfunction eagerLoad(item) {\n  if (item && item[isProxy]) {\n    for (const value of Object.values(item)) {\n      eagerLoad(value);\n    }\n  }\n  return item;\n}\n__name(eagerLoad, \"eagerLoad\");\nfunction _inject(module, injector) {\n  const proxy = new Proxy({}, {\n    deleteProperty: /* @__PURE__ */ __name(() => false, \"deleteProperty\"),\n    set: /* @__PURE__ */ __name(() => {\n      throw new Error(\"Cannot set property on injected service container\");\n    }, \"set\"),\n    get: /* @__PURE__ */ __name((obj, prop) => {\n      if (prop === isProxy) {\n        return true;\n      } else {\n        return _resolve(obj, prop, module, injector || proxy);\n      }\n    }, \"get\"),\n    getOwnPropertyDescriptor: /* @__PURE__ */ __name((obj, prop) => (_resolve(obj, prop, module, injector || proxy), Object.getOwnPropertyDescriptor(obj, prop)), \"getOwnPropertyDescriptor\"),\n    // used by for..in\n    has: /* @__PURE__ */ __name((_, prop) => prop in module, \"has\"),\n    // used by ..in..\n    ownKeys: /* @__PURE__ */ __name(() => [...Object.getOwnPropertyNames(module)], \"ownKeys\")\n    // used by for..in\n  });\n  return proxy;\n}\n__name(_inject, \"_inject\");\nvar __requested__ = Symbol();\nfunction _resolve(obj, prop, module, injector) {\n  if (prop in obj) {\n    if (obj[prop] instanceof Error) {\n      throw new Error(\"Construction failure. Please make sure that your dependencies are constructable.\", { cause: obj[prop] });\n    }\n    if (obj[prop] === __requested__) {\n      throw new Error('Cycle detected. Please make \"' + String(prop) + '\" lazy. Visit https://langium.org/docs/reference/configuration-services/#resolving-cyclic-dependencies');\n    }\n    return obj[prop];\n  } else if (prop in module) {\n    const value = module[prop];\n    obj[prop] = __requested__;\n    try {\n      obj[prop] = typeof value === \"function\" ? value(injector) : _inject(value, injector);\n    } catch (error) {\n      obj[prop] = error instanceof Error ? error : void 0;\n      throw error;\n    }\n    return obj[prop];\n  } else {\n    return void 0;\n  }\n}\n__name(_resolve, \"_resolve\");\nfunction _merge(target, source) {\n  if (source) {\n    for (const [key, value2] of Object.entries(source)) {\n      if (value2 !== void 0) {\n        const value1 = target[key];\n        if (value1 !== null && value2 !== null && typeof value1 === \"object\" && typeof value2 === \"object\") {\n          target[key] = _merge(value1, value2);\n        } else {\n          target[key] = value2;\n        }\n      }\n    }\n  }\n  return target;\n}\n__name(_merge, \"_merge\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/parser/indentation-aware.js\nvar indentationBuilderDefaultOptions = {\n  indentTokenName: \"INDENT\",\n  dedentTokenName: \"DEDENT\",\n  whitespaceTokenName: \"WS\",\n  ignoreIndentationDelimiters: []\n};\nvar LexingMode;\n(function(LexingMode2) {\n  LexingMode2[\"REGULAR\"] = \"indentation-sensitive\";\n  LexingMode2[\"IGNORE_INDENTATION\"] = \"ignore-indentation\";\n})(LexingMode || (LexingMode = {}));\nvar IndentationAwareTokenBuilder = class extends DefaultTokenBuilder {\n  static {\n    __name(this, \"IndentationAwareTokenBuilder\");\n  }\n  constructor(options = indentationBuilderDefaultOptions) {\n    super();\n    this.indentationStack = [0];\n    this.whitespaceRegExp = /[ \\t]+/y;\n    this.options = Object.assign(Object.assign({}, indentationBuilderDefaultOptions), options);\n    this.indentTokenType = createToken({\n      name: this.options.indentTokenName,\n      pattern: this.indentMatcher.bind(this),\n      line_breaks: false\n    });\n    this.dedentTokenType = createToken({\n      name: this.options.dedentTokenName,\n      pattern: this.dedentMatcher.bind(this),\n      line_breaks: false\n    });\n  }\n  buildTokens(grammar, options) {\n    const tokenTypes = super.buildTokens(grammar, options);\n    if (!isTokenTypeArray(tokenTypes)) {\n      throw new Error(\"Invalid tokens built by default builder\");\n    }\n    const { indentTokenName, dedentTokenName, whitespaceTokenName, ignoreIndentationDelimiters } = this.options;\n    let dedent;\n    let indent;\n    let ws;\n    const otherTokens = [];\n    for (const tokenType of tokenTypes) {\n      for (const [begin, end] of ignoreIndentationDelimiters) {\n        if (tokenType.name === begin) {\n          tokenType.PUSH_MODE = LexingMode.IGNORE_INDENTATION;\n        } else if (tokenType.name === end) {\n          tokenType.POP_MODE = true;\n        }\n      }\n      if (tokenType.name === dedentTokenName) {\n        dedent = tokenType;\n      } else if (tokenType.name === indentTokenName) {\n        indent = tokenType;\n      } else if (tokenType.name === whitespaceTokenName) {\n        ws = tokenType;\n      } else {\n        otherTokens.push(tokenType);\n      }\n    }\n    if (!dedent || !indent || !ws) {\n      throw new Error(\"Some indentation/whitespace tokens not found!\");\n    }\n    if (ignoreIndentationDelimiters.length > 0) {\n      const multiModeLexerDef = {\n        modes: {\n          [LexingMode.REGULAR]: [dedent, indent, ...otherTokens, ws],\n          [LexingMode.IGNORE_INDENTATION]: [...otherTokens, ws]\n        },\n        defaultMode: LexingMode.REGULAR\n      };\n      return multiModeLexerDef;\n    } else {\n      return [dedent, indent, ws, ...otherTokens];\n    }\n  }\n  flushLexingReport(text) {\n    const result = super.flushLexingReport(text);\n    return Object.assign(Object.assign({}, result), { remainingDedents: this.flushRemainingDedents(text) });\n  }\n  /**\n   * Helper function to check if the current position is the start of a new line.\n   *\n   * @param text The full input string.\n   * @param offset The current position at which to check\n   * @returns Whether the current position is the start of a new line\n   */\n  isStartOfLine(text, offset) {\n    return offset === 0 || \"\\r\\n\".includes(text[offset - 1]);\n  }\n  /**\n   * A helper function used in matching both indents and dedents.\n   *\n   * @param text The full input string.\n   * @param offset The current position at which to attempt a match\n   * @param tokens Previously scanned tokens\n   * @param groups Token Groups\n   * @returns The current and previous indentation levels and the matched whitespace\n   */\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  matchWhitespace(text, offset, tokens, groups) {\n    var _a;\n    this.whitespaceRegExp.lastIndex = offset;\n    const match = this.whitespaceRegExp.exec(text);\n    return {\n      currIndentLevel: (_a = match === null || match === void 0 ? void 0 : match[0].length) !== null && _a !== void 0 ? _a : 0,\n      prevIndentLevel: this.indentationStack.at(-1),\n      match\n    };\n  }\n  /**\n   * Helper function to create an instance of an indentation token.\n   *\n   * @param tokenType Indent or dedent token type\n   * @param text Full input string, used to calculate the line number\n   * @param image The original image of the token (tabs or spaces)\n   * @param offset Current position in the input string\n   * @returns The indentation token instance\n   */\n  createIndentationTokenInstance(tokenType, text, image, offset) {\n    const lineNumber = this.getLineNumber(text, offset);\n    return createTokenInstance(tokenType, image, offset, offset + image.length, lineNumber, lineNumber, 1, image.length);\n  }\n  /**\n   * Helper function to get the line number at a given offset.\n   *\n   * @param text Full input string, used to calculate the line number\n   * @param offset Current position in the input string\n   * @returns The line number at the given offset\n   */\n  getLineNumber(text, offset) {\n    return text.substring(0, offset).split(/\\r\\n|\\r|\\n/).length;\n  }\n  /**\n   * A custom pattern for matching indents\n   *\n   * @param text The full input string.\n   * @param offset The offset at which to attempt a match\n   * @param tokens Previously scanned tokens\n   * @param groups Token Groups\n   */\n  indentMatcher(text, offset, tokens, groups) {\n    if (!this.isStartOfLine(text, offset)) {\n      return null;\n    }\n    const { currIndentLevel, prevIndentLevel, match } = this.matchWhitespace(text, offset, tokens, groups);\n    if (currIndentLevel <= prevIndentLevel) {\n      return null;\n    }\n    this.indentationStack.push(currIndentLevel);\n    return match;\n  }\n  /**\n   * A custom pattern for matching dedents\n   *\n   * @param text The full input string.\n   * @param offset The offset at which to attempt a match\n   * @param tokens Previously scanned tokens\n   * @param groups Token Groups\n   */\n  dedentMatcher(text, offset, tokens, groups) {\n    var _a, _b, _c, _d;\n    if (!this.isStartOfLine(text, offset)) {\n      return null;\n    }\n    const { currIndentLevel, prevIndentLevel, match } = this.matchWhitespace(text, offset, tokens, groups);\n    if (currIndentLevel >= prevIndentLevel) {\n      return null;\n    }\n    const matchIndentIndex = this.indentationStack.lastIndexOf(currIndentLevel);\n    if (matchIndentIndex === -1) {\n      this.diagnostics.push({\n        severity: \"error\",\n        message: `Invalid dedent level ${currIndentLevel} at offset: ${offset}. Current indentation stack: ${this.indentationStack}`,\n        offset,\n        length: (_b = (_a = match === null || match === void 0 ? void 0 : match[0]) === null || _a === void 0 ? void 0 : _a.length) !== null && _b !== void 0 ? _b : 0,\n        line: this.getLineNumber(text, offset),\n        column: 1\n      });\n      return null;\n    }\n    const numberOfDedents = this.indentationStack.length - matchIndentIndex - 1;\n    const newlinesBeforeDedent = (_d = (_c = text.substring(0, offset).match(/[\\r\\n]+$/)) === null || _c === void 0 ? void 0 : _c[0].length) !== null && _d !== void 0 ? _d : 1;\n    for (let i = 0; i < numberOfDedents; i++) {\n      const token = this.createIndentationTokenInstance(\n        this.dedentTokenType,\n        text,\n        \"\",\n        // Dedents are 0-width tokens\n        offset - (newlinesBeforeDedent - 1)\n      );\n      tokens.push(token);\n      this.indentationStack.pop();\n    }\n    return null;\n  }\n  buildTerminalToken(terminal) {\n    const tokenType = super.buildTerminalToken(terminal);\n    const { indentTokenName, dedentTokenName, whitespaceTokenName } = this.options;\n    if (tokenType.name === indentTokenName) {\n      return this.indentTokenType;\n    } else if (tokenType.name === dedentTokenName) {\n      return this.dedentTokenType;\n    } else if (tokenType.name === whitespaceTokenName) {\n      return createToken({\n        name: whitespaceTokenName,\n        pattern: this.whitespaceRegExp,\n        group: Lexer.SKIPPED\n      });\n    }\n    return tokenType;\n  }\n  /**\n   * Resets the indentation stack between different runs of the lexer\n   *\n   * @param text Full text that was tokenized\n   * @returns Remaining dedent tokens to match all previous indents at the end of the file\n   */\n  flushRemainingDedents(text) {\n    const remainingDedents = [];\n    while (this.indentationStack.length > 1) {\n      remainingDedents.push(this.createIndentationTokenInstance(this.dedentTokenType, text, \"\", text.length));\n      this.indentationStack.pop();\n    }\n    this.indentationStack = [0];\n    return remainingDedents;\n  }\n};\nvar IndentationAwareLexer = class extends DefaultLexer {\n  static {\n    __name(this, \"IndentationAwareLexer\");\n  }\n  constructor(services) {\n    super(services);\n    if (services.parser.TokenBuilder instanceof IndentationAwareTokenBuilder) {\n      this.indentationTokenBuilder = services.parser.TokenBuilder;\n    } else {\n      throw new Error(\"IndentationAwareLexer requires an accompanying IndentationAwareTokenBuilder\");\n    }\n  }\n  tokenize(text, options = DEFAULT_TOKENIZE_OPTIONS) {\n    const result = super.tokenize(text);\n    const report = result.report;\n    if ((options === null || options === void 0 ? void 0 : options.mode) === \"full\") {\n      result.tokens.push(...report.remainingDedents);\n    }\n    report.remainingDedents = [];\n    const { indentTokenType, dedentTokenType } = this.indentationTokenBuilder;\n    const indentTokenIdx = indentTokenType.tokenTypeIdx;\n    const dedentTokenIdx = dedentTokenType.tokenTypeIdx;\n    const cleanTokens = [];\n    const length = result.tokens.length - 1;\n    for (let i = 0; i < length; i++) {\n      const token = result.tokens[i];\n      const nextToken = result.tokens[i + 1];\n      if (token.tokenTypeIdx === indentTokenIdx && nextToken.tokenTypeIdx === dedentTokenIdx) {\n        i++;\n        continue;\n      }\n      cleanTokens.push(token);\n    }\n    if (length >= 0) {\n      cleanTokens.push(result.tokens[length]);\n    }\n    result.tokens = cleanTokens;\n    return result;\n  }\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/index.js\nvar utils_exports = {};\n__export(utils_exports, {\n  AstUtils: () => ast_utils_exports,\n  BiMap: () => BiMap,\n  Cancellation: () => cancellation_exports,\n  ContextCache: () => ContextCache,\n  CstUtils: () => cst_utils_exports,\n  DONE_RESULT: () => DONE_RESULT,\n  Deferred: () => Deferred,\n  Disposable: () => Disposable,\n  DisposableCache: () => DisposableCache,\n  DocumentCache: () => DocumentCache,\n  EMPTY_STREAM: () => EMPTY_STREAM,\n  ErrorWithLocation: () => ErrorWithLocation,\n  GrammarUtils: () => grammar_utils_exports,\n  MultiMap: () => MultiMap,\n  OperationCancelled: () => OperationCancelled,\n  Reduction: () => Reduction,\n  RegExpUtils: () => regexp_utils_exports,\n  SimpleCache: () => SimpleCache,\n  StreamImpl: () => StreamImpl,\n  TreeStreamImpl: () => TreeStreamImpl,\n  URI: () => URI2,\n  UriUtils: () => UriUtils,\n  WorkspaceCache: () => WorkspaceCache,\n  assertUnreachable: () => assertUnreachable,\n  delayNextTick: () => delayNextTick,\n  interruptAndCheck: () => interruptAndCheck,\n  isOperationCancelled: () => isOperationCancelled,\n  loadGrammarFromJson: () => loadGrammarFromJson,\n  setInterruptionPeriod: () => setInterruptionPeriod,\n  startCancelableOperation: () => startCancelableOperation,\n  stream: () => stream\n});\n__reExport(utils_exports, event_exports);\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/workspace/file-system-provider.js\nvar EmptyFileSystemProvider = class {\n  static {\n    __name(this, \"EmptyFileSystemProvider\");\n  }\n  readFile() {\n    throw new Error(\"No file system is available.\");\n  }\n  async readDirectory() {\n    return [];\n  }\n};\nvar EmptyFileSystem = {\n  fileSystemProvider: /* @__PURE__ */ __name(() => new EmptyFileSystemProvider(), \"fileSystemProvider\")\n};\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/utils/grammar-loader.js\nvar minimalGrammarModule = {\n  Grammar: /* @__PURE__ */ __name(() => void 0, \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => ({\n    caseInsensitive: false,\n    fileExtensions: [\".langium\"],\n    languageId: \"langium\"\n  }), \"LanguageMetaData\")\n};\nvar minimalSharedGrammarModule = {\n  AstReflection: /* @__PURE__ */ __name(() => new LangiumGrammarAstReflection(), \"AstReflection\")\n};\nfunction createMinimalGrammarServices() {\n  const shared = inject(createDefaultSharedCoreModule(EmptyFileSystem), minimalSharedGrammarModule);\n  const grammar = inject(createDefaultCoreModule({ shared }), minimalGrammarModule);\n  shared.ServiceRegistry.register(grammar);\n  return grammar;\n}\n__name(createMinimalGrammarServices, \"createMinimalGrammarServices\");\nfunction loadGrammarFromJson(json) {\n  var _a;\n  const services = createMinimalGrammarServices();\n  const astNode = services.serializer.JsonSerializer.deserialize(json);\n  services.shared.workspace.LangiumDocumentFactory.fromModel(astNode, URI2.parse(`memory://${(_a = astNode.name) !== null && _a !== void 0 ? _a : \"grammar\"}.langium`));\n  return astNode;\n}\n__name(loadGrammarFromJson, \"loadGrammarFromJson\");\n\n// ../../node_modules/.pnpm/langium@3.3.1/node_modules/langium/lib/index.js\n__reExport(lib_exports, utils_exports);\n\n// ../parser/dist/chunks/mermaid-parser.core/chunk-7PKI6E2E.mjs\nvar __defProp = Object.defineProperty;\nvar __name2 = /* @__PURE__ */ __name((target, value) => __defProp(target, \"name\", { value, configurable: true }), \"__name\");\nvar Statement = \"Statement\";\nvar Architecture = \"Architecture\";\nfunction isArchitecture(item) {\n  return reflection2.isInstance(item, Architecture);\n}\n__name(isArchitecture, \"isArchitecture\");\n__name2(isArchitecture, \"isArchitecture\");\nvar Axis = \"Axis\";\nvar Branch = \"Branch\";\nfunction isBranch(item) {\n  return reflection2.isInstance(item, Branch);\n}\n__name(isBranch, \"isBranch\");\n__name2(isBranch, \"isBranch\");\nvar Checkout = \"Checkout\";\nvar CherryPicking = \"CherryPicking\";\nvar Commit = \"Commit\";\nfunction isCommit(item) {\n  return reflection2.isInstance(item, Commit);\n}\n__name(isCommit, \"isCommit\");\n__name2(isCommit, \"isCommit\");\nvar Common = \"Common\";\nfunction isCommon(item) {\n  return reflection2.isInstance(item, Common);\n}\n__name(isCommon, \"isCommon\");\n__name2(isCommon, \"isCommon\");\nvar Curve = \"Curve\";\nvar Edge = \"Edge\";\nvar Entry = \"Entry\";\nvar GitGraph = \"GitGraph\";\nfunction isGitGraph(item) {\n  return reflection2.isInstance(item, GitGraph);\n}\n__name(isGitGraph, \"isGitGraph\");\n__name2(isGitGraph, \"isGitGraph\");\nvar Group2 = \"Group\";\nvar Info = \"Info\";\nfunction isInfo(item) {\n  return reflection2.isInstance(item, Info);\n}\n__name(isInfo, \"isInfo\");\n__name2(isInfo, \"isInfo\");\nvar Junction = \"Junction\";\nvar Merge = \"Merge\";\nfunction isMerge(item) {\n  return reflection2.isInstance(item, Merge);\n}\n__name(isMerge, \"isMerge\");\n__name2(isMerge, \"isMerge\");\nvar Option2 = \"Option\";\nvar Packet = \"Packet\";\nfunction isPacket(item) {\n  return reflection2.isInstance(item, Packet);\n}\n__name(isPacket, \"isPacket\");\n__name2(isPacket, \"isPacket\");\nvar PacketBlock = \"PacketBlock\";\nfunction isPacketBlock(item) {\n  return reflection2.isInstance(item, PacketBlock);\n}\n__name(isPacketBlock, \"isPacketBlock\");\n__name2(isPacketBlock, \"isPacketBlock\");\nvar Pie = \"Pie\";\nfunction isPie(item) {\n  return reflection2.isInstance(item, Pie);\n}\n__name(isPie, \"isPie\");\n__name2(isPie, \"isPie\");\nvar PieSection = \"PieSection\";\nfunction isPieSection(item) {\n  return reflection2.isInstance(item, PieSection);\n}\n__name(isPieSection, \"isPieSection\");\n__name2(isPieSection, \"isPieSection\");\nvar Radar = \"Radar\";\nvar Service = \"Service\";\nvar Direction = \"Direction\";\nvar MermaidAstReflection = class extends AbstractAstReflection {\n  static {\n    __name(this, \"MermaidAstReflection\");\n  }\n  static {\n    __name2(this, \"MermaidAstReflection\");\n  }\n  getAllTypes() {\n    return [Architecture, Axis, Branch, Checkout, CherryPicking, Commit, Common, Curve, Direction, Edge, Entry, GitGraph, Group2, Info, Junction, Merge, Option2, Packet, PacketBlock, Pie, PieSection, Radar, Service, Statement];\n  }\n  computeIsSubtype(subtype, supertype) {\n    switch (subtype) {\n      case Branch:\n      case Checkout:\n      case CherryPicking:\n      case Commit:\n      case Merge: {\n        return this.isSubtype(Statement, supertype);\n      }\n      case Direction: {\n        return this.isSubtype(GitGraph, supertype);\n      }\n      default: {\n        return false;\n      }\n    }\n  }\n  getReferenceType(refInfo) {\n    const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\n    switch (referenceId) {\n      case \"Entry:axis\": {\n        return Axis;\n      }\n      default: {\n        throw new Error(`${referenceId} is not a valid reference id.`);\n      }\n    }\n  }\n  getTypeMetaData(type) {\n    switch (type) {\n      case Architecture: {\n        return {\n          name: Architecture,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"edges\", defaultValue: [] },\n            { name: \"groups\", defaultValue: [] },\n            { name: \"junctions\", defaultValue: [] },\n            { name: \"services\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Axis: {\n        return {\n          name: Axis,\n          properties: [\n            { name: \"label\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Branch: {\n        return {\n          name: Branch,\n          properties: [\n            { name: \"name\" },\n            { name: \"order\" }\n          ]\n        };\n      }\n      case Checkout: {\n        return {\n          name: Checkout,\n          properties: [\n            { name: \"branch\" }\n          ]\n        };\n      }\n      case CherryPicking: {\n        return {\n          name: CherryPicking,\n          properties: [\n            { name: \"id\" },\n            { name: \"parent\" },\n            { name: \"tags\", defaultValue: [] }\n          ]\n        };\n      }\n      case Commit: {\n        return {\n          name: Commit,\n          properties: [\n            { name: \"id\" },\n            { name: \"message\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Common: {\n        return {\n          name: Common,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Curve: {\n        return {\n          name: Curve,\n          properties: [\n            { name: \"entries\", defaultValue: [] },\n            { name: \"label\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Edge: {\n        return {\n          name: Edge,\n          properties: [\n            { name: \"lhsDir\" },\n            { name: \"lhsGroup\", defaultValue: false },\n            { name: \"lhsId\" },\n            { name: \"lhsInto\", defaultValue: false },\n            { name: \"rhsDir\" },\n            { name: \"rhsGroup\", defaultValue: false },\n            { name: \"rhsId\" },\n            { name: \"rhsInto\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Entry: {\n        return {\n          name: Entry,\n          properties: [\n            { name: \"axis\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case GitGraph: {\n        return {\n          name: GitGraph,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Group2: {\n        return {\n          name: Group2,\n          properties: [\n            { name: \"icon\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Info: {\n        return {\n          name: Info,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Junction: {\n        return {\n          name: Junction,\n          properties: [\n            { name: \"id\" },\n            { name: \"in\" }\n          ]\n        };\n      }\n      case Merge: {\n        return {\n          name: Merge,\n          properties: [\n            { name: \"branch\" },\n            { name: \"id\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Option2: {\n        return {\n          name: Option2,\n          properties: [\n            { name: \"name\" },\n            { name: \"value\", defaultValue: false }\n          ]\n        };\n      }\n      case Packet: {\n        return {\n          name: Packet,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"blocks\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case PacketBlock: {\n        return {\n          name: PacketBlock,\n          properties: [\n            { name: \"end\" },\n            { name: \"label\" },\n            { name: \"start\" }\n          ]\n        };\n      }\n      case Pie: {\n        return {\n          name: Pie,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"sections\", defaultValue: [] },\n            { name: \"showData\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case PieSection: {\n        return {\n          name: PieSection,\n          properties: [\n            { name: \"label\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case Radar: {\n        return {\n          name: Radar,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"axes\", defaultValue: [] },\n            { name: \"curves\", defaultValue: [] },\n            { name: \"options\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Service: {\n        return {\n          name: Service,\n          properties: [\n            { name: \"icon\" },\n            { name: \"iconText\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Direction: {\n        return {\n          name: Direction,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"dir\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      default: {\n        return {\n          name: type,\n          properties: []\n        };\n      }\n    }\n  }\n};\nvar reflection2 = new MermaidAstReflection();\nvar loadedInfoGrammar;\nvar InfoGrammar = /* @__PURE__ */ __name2(() => loadedInfoGrammar ?? (loadedInfoGrammar = loadGrammarFromJson('{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Info\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Info\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"info\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"showInfo\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"*\"}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}')), \"InfoGrammar\");\nvar loadedPacketGrammar;\nvar PacketGrammar = /* @__PURE__ */ __name2(() => loadedPacketGrammar ?? (loadedPacketGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Packet\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Packet\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"packet-beta\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"blocks\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"Assignment\",\"feature\":\"blocks\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"+\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PacketBlock\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"start\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"end\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}`)), \"PacketGrammar\");\nvar loadedPieGrammar;\nvar PieGrammar = /* @__PURE__ */ __name2(() => loadedPieGrammar ?? (loadedPieGrammar = loadGrammarFromJson('{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Pie\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Pie\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"pie\"},{\"$type\":\"Assignment\",\"feature\":\"showData\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showData\"},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"sections\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"Assignment\",\"feature\":\"sections\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"+\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PieSection\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"PIE_SECTION_LABEL\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]+\\\\\"/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"PIE_SECTION_VALUE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/(0|[1-9][0-9]*)(\\\\\\\\.[0-9]+)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}')), \"PieGrammar\");\nvar loadedArchitectureGrammar;\nvar ArchitectureGrammar = /* @__PURE__ */ __name2(() => loadedArchitectureGrammar ?? (loadedArchitectureGrammar = loadGrammarFromJson('{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Architecture\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Architecture\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"architecture-beta\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"*\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"groups\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"services\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"junctions\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"edges\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"LeftPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"lhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"RightPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"rhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Arrow\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"lhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"--\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"-\"}]}]},{\"$type\":\"Assignment\",\"feature\":\"rhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Group\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"group\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Service\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"service\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"iconText\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Junction\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"junction\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Edge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"lhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"lhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"rhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"rhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_DIRECTION\",\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"L\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"R\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"T\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"B\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_ID\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]+/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_TEXT_ICON\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\(\\\\\"[^\\\\\"]+\\\\\"\\\\\\\\)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_ICON\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\([\\\\\\\\w-:]+\\\\\\\\)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\[[\\\\\\\\w ]+\\\\\\\\]/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_GROUP\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\{group\\\\\\\\}/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_INTO\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/<|>/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}')), \"ArchitectureGrammar\");\nvar loadedGitGraphGrammar;\nvar GitGraphGrammar = /* @__PURE__ */ __name2(() => loadedGitGraphGrammar ?? (loadedGitGraphGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"GitGraph\",\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"rules\":[{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false},{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"GitGraph\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Keyword\",\"value\":\":\"}]},{\"$type\":\"Keyword\",\"value\":\"gitGraph:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@0\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"statements\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Direction\",\"definition\":{\"$type\":\"Assignment\",\"feature\":\"dir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"LR\"},{\"$type\":\"Keyword\",\"value\":\"TB\"},{\"$type\":\"Keyword\",\"value\":\"BT\"}]}},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Commit\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"commit\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"msg:\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"message\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Branch\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"branch\"},{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"order:\"},{\"$type\":\"Assignment\",\"feature\":\"order\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Merge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"merge\"},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Checkout\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"checkout\"},{\"$type\":\"Keyword\",\"value\":\"switch\"}]},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"CherryPicking\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"cherry-pick\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"parent:\"},{\"$type\":\"Assignment\",\"feature\":\"parent\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+(?=\\\\\\\\s)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\w([-\\\\\\\\./\\\\\\\\w]*[-\\\\\\\\w])?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"imports\":[],\"types\":[],\"usedGrammars\":[]}`)), \"GitGraphGrammar\");\nvar loadedRadarGrammar;\nvar RadarGrammar = /* @__PURE__ */ __name2(() => loadedRadarGrammar ?? (loadedRadarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Radar\",\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]},{\"$type\":\"Interface\",\"name\":\"Entry\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"axis\",\"isOptional\":true,\"type\":{\"$type\":\"ReferenceType\",\"referenceType\":{\"$type\":\"SimpleType\",\"typeRef\":{\"$ref\":\"#/rules@12\"}}}},{\"$type\":\"TypeAttribute\",\"name\":\"value\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"number\"},\"isOptional\":false}],\"superTypes\":[]}],\"rules\":[{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false},{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Radar\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\"radar-beta:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@0\"},\"arguments\":[]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"axis\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"curve\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Label\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"[\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"]\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Axis\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Curve\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Keyword\",\"value\":\"{\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\"}\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Entries\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"DetailedEntry\",\"returnType\":{\"$ref\":\"#/interfaces@1\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"axis\",\"operator\":\"=\",\"terminal\":{\"$type\":\"CrossReference\",\"type\":{\"$ref\":\"#/rules@12\"},\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]},\"deprecatedSyntax\":false}},{\"$type\":\"Keyword\",\"value\":\":\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"NumberEntry\",\"returnType\":{\"$ref\":\"#/interfaces@1\"},\"definition\":{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Option\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showLegend\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"ticks\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"max\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"min\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"graticule\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/(0|[1-9][0-9]*)(\\\\\\\\.[0-9]+)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"GRATICULE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"circle\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"polygon\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[a-zA-Z_][a-zA-Z0-9\\\\\\\\-_]*/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"imports\":[],\"types\":[],\"usedGrammars\":[]}`)), \"RadarGrammar\");\nvar InfoLanguageMetaData = {\n  languageId: \"info\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PacketLanguageMetaData = {\n  languageId: \"packet\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PieLanguageMetaData = {\n  languageId: \"pie\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar ArchitectureLanguageMetaData = {\n  languageId: \"architecture\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar GitGraphLanguageMetaData = {\n  languageId: \"gitGraph\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar RadarLanguageMetaData = {\n  languageId: \"radar\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar MermaidGeneratedSharedModule = {\n  AstReflection: /* @__PURE__ */ __name2(() => new MermaidAstReflection(), \"AstReflection\")\n};\nvar InfoGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name2(() => InfoGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name2(() => InfoLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PacketGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name2(() => PacketGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name2(() => PacketLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PieGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name2(() => PieGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name2(() => PieLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar ArchitectureGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name2(() => ArchitectureGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name2(() => ArchitectureLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar GitGraphGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name2(() => GitGraphGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name2(() => GitGraphLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar RadarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name2(() => RadarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name2(() => RadarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar accessibilityDescrRegex = /accDescr(?:[\\t ]*:([^\\n\\r]*)|\\s*{([^}]*)})/;\nvar accessibilityTitleRegex = /accTitle[\\t ]*:([^\\n\\r]*)/;\nvar titleRegex = /title([\\t ][^\\n\\r]*|)/;\nvar rulesRegexes = {\n  ACC_DESCR: accessibilityDescrRegex,\n  ACC_TITLE: accessibilityTitleRegex,\n  TITLE: titleRegex\n};\nvar AbstractMermaidValueConverter = class extends DefaultValueConverter {\n  static {\n    __name(this, \"AbstractMermaidValueConverter\");\n  }\n  static {\n    __name2(this, \"AbstractMermaidValueConverter\");\n  }\n  runConverter(rule, input, cstNode) {\n    let value = this.runCommonConverter(rule, input, cstNode);\n    if (value === void 0) {\n      value = this.runCustomConverter(rule, input, cstNode);\n    }\n    if (value === void 0) {\n      return super.runConverter(rule, input, cstNode);\n    }\n    return value;\n  }\n  runCommonConverter(rule, input, _cstNode) {\n    const regex = rulesRegexes[rule.name];\n    if (regex === void 0) {\n      return void 0;\n    }\n    const match = regex.exec(input);\n    if (match === null) {\n      return void 0;\n    }\n    if (match[1] !== void 0) {\n      return match[1].trim().replace(/[\\t ]{2,}/gm, \" \");\n    }\n    if (match[2] !== void 0) {\n      return match[2].replace(/^\\s*/gm, \"\").replace(/\\s+$/gm, \"\").replace(/[\\t ]{2,}/gm, \" \").replace(/[\\n\\r]{2,}/gm, \"\\n\");\n    }\n    return void 0;\n  }\n};\nvar CommonValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"CommonValueConverter\");\n  }\n  static {\n    __name2(this, \"CommonValueConverter\");\n  }\n  runCustomConverter(_rule, _input, _cstNode) {\n    return void 0;\n  }\n};\nvar AbstractMermaidTokenBuilder = class extends DefaultTokenBuilder {\n  static {\n    __name(this, \"AbstractMermaidTokenBuilder\");\n  }\n  static {\n    __name2(this, \"AbstractMermaidTokenBuilder\");\n  }\n  constructor(keywords) {\n    super();\n    this.keywords = new Set(keywords);\n  }\n  buildKeywordTokens(rules, terminalTokens, options) {\n    const tokenTypes = super.buildKeywordTokens(rules, terminalTokens, options);\n    tokenTypes.forEach((tokenType) => {\n      if (this.keywords.has(tokenType.name) && tokenType.PATTERN !== void 0) {\n        tokenType.PATTERN = new RegExp(tokenType.PATTERN.toString() + \"(?:(?=%%)|(?!\\\\S))\");\n      }\n    });\n    return tokenTypes;\n  }\n};\nvar CommonTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"CommonTokenBuilder\");\n  }\n  static {\n    __name2(this, \"CommonTokenBuilder\");\n  }\n};\n\nexport {\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject,\n  EmptyFileSystem,\n  lib_exports,\n  __name2 as __name,\n  MermaidGeneratedSharedModule,\n  InfoGeneratedModule,\n  PacketGeneratedModule,\n  PieGeneratedModule,\n  ArchitectureGeneratedModule,\n  GitGraphGeneratedModule,\n  RadarGeneratedModule,\n  AbstractMermaidValueConverter,\n  CommonValueConverter,\n  AbstractMermaidTokenBuilder\n};\n",
      "start": 1743409709238,
      "end": 1743409709311,
      "sourcemaps": null
    },
    {
      "name": "unplugin-vue-markdown",
      "start": 1743409709311,
      "end": 1743409709311,
      "order": "pre"
    },
    {
      "name": "slidev:flags",
      "start": 1743409709311,
      "end": 1743409709311,
      "order": "pre"
    },
    {
      "name": "unocss:transformers:pre",
      "start": 1743409709311,
      "end": 1743409709313,
      "order": "pre"
    },
    {
      "name": "unocss:global:build:scan",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "pre"
    },
    {
      "name": "vite:css",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "vite:esbuild",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "vite:json",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "vite:worker",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "slidev:layout-wrapper",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "slidev:context-injection",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "vite:vue-jsx",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "vite:vue",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "slidev:hmr-patch",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "unocss:transformers:undefined",
      "start": 1743409709313,
      "end": 1743409709313,
      "order": "normal"
    },
    {
      "name": "vite:define",
      "start": 1743409709313,
      "end": 1743409709314,
      "order": "normal"
    },
    {
      "name": "vite:css-post",
      "start": 1743409709314,
      "end": 1743409709314,
      "order": "normal"
    },
    {
      "name": "vite:build-html",
      "start": 1743409709314,
      "end": 1743409709314,
      "order": "normal"
    },
    {
      "name": "vite:worker-import-meta-url",
      "start": 1743409709314,
      "end": 1743409709315,
      "order": "normal"
    },
    {
      "name": "vite:asset-import-meta-url",
      "start": 1743409709315,
      "end": 1743409709315,
      "order": "normal"
    },
    {
      "name": "vite:dynamic-import-vars",
      "start": 1743409709315,
      "end": 1743409709315,
      "order": "normal"
    },
    {
      "name": "vite:import-glob",
      "start": 1743409709315,
      "end": 1743409709315,
      "order": "normal"
    },
    {
      "name": "unplugin-vue-components",
      "start": 1743409709315,
      "end": 1743409709315,
      "order": "post"
    },
    {
      "name": "unocss:transformers:post",
      "start": 1743409709315,
      "end": 1743409709315,
      "order": "post"
    },
    {
      "name": "vite:build-import-analysis",
      "start": 1743409709315,
      "end": 1743409709316,
      "order": "normal"
    },
    {
      "name": "vite:reporter",
      "start": 1743409709316,
      "end": 1743409709316,
      "order": "normal"
    }
  ]
}
